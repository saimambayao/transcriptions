
Complexity Economics Introduction

Contents
Complexity & Economics
Economic Theory
Standard Economics
The Rise of Economic Complexity
Complexity Economics
Behavioral Economics
Economic Agents
Bounded Rationality
Value Theory
Behavioral Choice Theory
Incentive Theory
Nonlinear Systems
Economic Dynamics
Feedback Loops
Nonlinear Dynamics
Self-Organization
Economic Networks
Network Economic Theory
Network Topology
Degree Distribution
Network Dynamics
Economic Dynamics
Adaptation & Regulation
Economic Resiliency
Economic Fitness Landscape
Evolutionary Economics

Overview
As advanced economies come to the end of the process of industrialization and with the rise of information technology, we are witnessing the birth of a new type of post-industrial economy. It is built on services, fueled by information and knowledge, and it is increasingly integrated through globally financial and supply chain networks. These huge changes in the deep architecture to our economies go far beyond our industrial paradigm and are necessitating a re-imagination of economy theory. General equilibrium models that were derived from classical physics got mathematized during the 20th century.
These models give us a picture of the economy as composed of isolated, purely rational individuals, optimizing over a well defined set of preferences out of which we get a macro level general equilibrium in a somewhat static and timeless economy. It was a paradigm that fitted well with industrial age mechanization. But today, the limitations of general equilibrium theory are becoming more apparent as we build new models – models to individual agents that have bounded rationality driven by a diversity of motives they are interconnected and interdependent. And it is out of these nonlinear interactions that we get the emergence of economic institutions as network structures that are far-from-equilibrium in an economy that is constantly changing from internal drivers as it develops over time through an evolutionary process.
This course is an overview to the new area of complexity economics – the application of models from complexity theory to the domain of economic science. The course is broken down into five main sections. We will start off with an overview to economic theory, discussing our standard approach before going on to give a clear outline to the main ideas coming out of complexity economies.
Next, we will borrow from behavioral economics to build up a more complex model to economics agents as we talk about the idea of bounded rationality, different theories of value, choice theory and incentive systems. In the third section, we will be looking at nonlinear economics as we apply system dynamics to modeling micro economic phenomena. We will be talking about how feedback loops create nonlinearity and the process of self-organization out of which emerges non-equilibrium patterns of organization in the economy.
We will then go on to apply network analysis to modeling macro level economic institutions such as markets. We will introduce you to the basics of network theory and go on to talk about economic networks, their topology, distribution and dynamics. In the final section, will be looking through the lens of complex adaptive systems theory to understand how whole macro economies emerge out of the actions and reactions of many different organizations.
We will use the model of a fitness landscape in order to help us understand the process of economic evolution.
This course is an overview to a broad area. It has been designed to be accessible and we do not go into technical details. But it has been graded as intermediary level, meaning you will need some background in standard economic theory. The course is academic in nature and parts of the course will be theoretically challenging. Some knowledge of complexity theory or nonlinear systems would be of advantage and it is recommended that you are familiar with most of the terms on this screen before taking the course.

Economics Theory
Complexity economics is an alternative economic paradigm and modeling framework. In order to understand how it relates to standard economic theory, it is important to first understand a little about economic theories, science, and paradigms in general. This helps to essentially define the problem space that different economic theories have to try and solve. Because theories and paradigms may be different but they are all using the basic building blocks of science and logic to try and describe economic phenomena.
Firstly we talk about the nature of abstraction and paradigms, discussing how theories are a conceptual form of abstraction. Recognizing that there is no formal definition of economics, we will lay down a working definition based on the conception of economics as the study of individual choice in the allocation of resources towards some valued end, and how these micro-level actions interact giving rise to macro level patterns of economic organization.
From this definition, we go on to outline some of the major considerations involved in the study of economics, including trying to understand the logic behind the decision making of agents, theories of economic value and the idea of intrinsic and extrinsic value. We briefly touch upon different types of interactions between agents in terms of cooperation and competition. We discuss economic institutions with a quick look at their different structures. Lastly, we will talk about economic dynamics, the area of economics that tries to model and understand the behavior of economies over time.

Theories
In order to understand something in a coherent fashion, we need to create a model of it. If we want to try and understand something very complex like a national or even global economy, these models are going to involve a very high level of abstraction. An abstraction is a compact representation of a system that removes successive layers of detail in order to capture the underlying structure and functioning of the system.
Theories are conceptual abstract models. All theories rest upon a set of assumptions. Nobody likes the term assumption, particularly not in science, but the fact is that we can’t question everything all of the time. We can in practice only question some things some of the time, and in order to do this, we need to start from something that we consider self-evident and without question. These assumptions are what are called axioms in mathematics, which is a premise so evident as to be accepted as true without question by the theory. A coherent set of assumptions might be called a paradigm. You cannot question the paradigm from within the theory because the theory is made of the paradigm. You have to go outside of the theory to question the paradigm. Within science, theories may be formalized by encoding them into a formal language. A formal language that most people would be familiar with might be algebra. Algebra is the most common formal language used in standard economic theory, but there are many others. By formalizing theories, it is possible that they may be parsed by machines, meaning we can put them into computer code and harness the power of computation which has many benefits, particularly when we are dealing with very complex systems. So all economic theories are going to use some paradigm, that is, the set of assumptions, in order to build a theory that will describe some empirical phenomena considered part of the domain of economics. If they are successful, they may, or may not, go on to formalize this within a formal language. That would give it a certain rigor and endow it with computability.

Models
We will also note that no theory is going to be perfect, but some will be more internally consistent, have greater rigor, be more efficient and better able to match the data than others. Because models are not perfect they will have a lifecycle, meaning we should always be working on developing better ones and retiring older ones, once we have these new models developed. Of course, this is not an orderly process. It is very messy in practice, but it is necessary for the science to develop and grow.
As an example of this, we might cite the current situation within theoretical physics of what is called the standard model, which is a model of the fundamental particles of matter and their interactions, sometimes called the "theory of almost everything." Although it has many achievements, this nickname is a tribute to its limitations in not being able to fully describe some very important empirical phenomena surrounding gravity and the expanding universe among others. The standard model is both used day in, day out by researchers and recognized as likely being just a stepping stone to a more fundamental and more inclusive model that researchers are at the same time working on under the name of the “theory of everything.” The point here is to recognize when a model is incomplete and to make that explicit.

Data
The enterprise of science involves trying to interpret the world by developing models that have internal logical consistency and matching these to data. If we are engaged in an empirical science, objective empirical data should ultimately have the last say on everything. As long as the data is accurate if the world does not fit into our model, this is not a problem with the world. It is a problem with our model. Science will develop and grow most effectively when we are able to admit the limitations to our models and accept whichever ones work best as the current standard because at the end of the day science performs an important function within society. That function is to stay developing these models, providing society with the best tools to appropriately interpret empirical phenomena. If we can match models to data and everything is working, then we can hand them out to society with the appropriate warning signs on the side of the tin. Now that we have given some definition to the term theory and the general enterprise of science, we will begin to define what we mean when we refer to the domain of economics.

Definitions
There is no widely accepted formal definition for the domain of economics. One of the most quoted definitions to economics is from the English economist Lionel Robbins who defined economics as “the science which studies human behavior as a relationship between (given) ends and scarce means which have alternative uses.” On this most basic level economics is defined as the study of how people use efficient means to achieve valued ends.
From this perspective, economics is about how we choose to spend any available resource (such as our time or effort) in trying to achieve other things that we value more highly. This is of course not just on the micro level of the individual but also on the macro level, that is to say, how organizations and society at large use scarce resources to produce valuable commodities and distribute them among people.
To flesh out our definition a bit further we might say: Economics is the study of individual choices in the allocation of resources and how these micro-level actions interact to give rise to macro level patterns of economic organization. The manifestation of all this activity is what we call an economy consisting of natural resources, technology, social and economic institutions.

Key Factors
Out of this definition we can draw a number of the central areas of interest that any economic theory is going to have to give some basic description to. These fundamental aspects of economics are typically broken down into micro and macro. On the micro level, we need some account of these agents that are performing the act of economizing in the pursuit of their ends. We will also need some description of what we mean by this idea of economic value, as that is clearly central to this whole enterprise. We will need to take account of the fact that these agents are inevitably going to interact and these interactions are going to be another key part of the whole dynamic. This is all on the micro-level, which will inevitably lead to enduring macro-scale patterns of organization, such as whole economies. Thus, we will need to develop some model to these macro-scale phenomena. Lastly, this whole system is going to be changing over time and we will be interested in trying to model the patterns within this dynamic. We will spend the rest of this section discussing each of these areas separately.

Agent-Choice
In most definitions of economics the idea of scarcity is fundamental, that is to say, that the resources that are being allocated are not infinite. There is some limit to their availability. Maybe a better way of putting this is simply to say that there will always be a hierarchy of value. In aggregate there will always be some things that we value more than others. Because we can not have everything, we have to make choices as to how we allocate our resources. We have to choose some things over others. As such, an economic framework will need some description as to the logic under which economic agents act and make choices with respect to the allocation of their resources in the pursuit of their ends.
Economic agents wish to achieve their valued ends and economize in trying to achieve this. This is not to say that they will always try to maximize their total economic or financial value. This is clearly not the case. People sometimes take lower paid jobs because of work satisfaction or other factors, but they opted for this choice because it gives them the greatest overall value. Thus, we are using an abstraction where we are talking about value of any kind – social, cultural, financial, ecological etc. This helps to illustrate how economics is not really about money, products or capital. It is an abstract way of representing human behavior in terms of means and ends, based on the assumption that humans will strive for the highest valued ends at the lowest cost means. In so doing, they perform the act of economizing. This basic premise that people will adopt the most efficient means to achieving the highest value ends is not a particular economic theory or paradigm. It is part of the very fabric of the subject of economics, but different paradigms will go on to define value in different ways, some expansive and some reductive.

Theory of Value
This fact that there is scarcity and a hierarchy of outcomes leads us to the idea of value. The concept of value is one of the deepest and most complex concepts within all of the social sciences. The theory of value is a term that encompasses all economic theories that try to define what economic value is, where it comes from, and how to quantify it through some objective metric, what we might call a price.
There are two fundamentally different conceptions of value within economic theory; one intrinsic and the other extrinsic. Intrinsic value is the value of a product that comes from the value of its inputs. Intrinsic value theory holds that the value of some commodity is inherent to it. That value is objective in that it is independent of any person’s individual evaluation of it, and thus from this perspective value is seen to be absolute.
Extrinsic value can be seen as a value that is ascribed to a commodity due to the perception of society. Extrinsic value is a measure of the benefit provided by a good or service to an economic agent. Extrinsic value is captured in the concept of utility. It represents satisfaction experienced by the consumer of a good. A good then has value in that it satisfies human wants. Put very simply, from this perspective no absolute metric of value exists for any good or service except its price which is a reflection of its demand and supply position and not of any inherent quality of that item.

Interactions
These economic agents will, during the course of their actions, come into contact with each other - that is to say, they will inevitably interact. Through these interactions, agents may find that they share a common pursuit, and by working together they can achieve those ends more efficiently than in isolation. Thus, they may work together by differentiating their activities with respect to each other, while all the time coordinating those activities towards the common end. In so doing, they will become interdependent. We call this type of interaction cooperation, and it is a fundamental type of social interaction.
Inversely, these agents may find that their interests are in fact mutually exclusive. The end goal of one agent’s economic activity may be some finite resource that is the end goal of another’s, and both of these agents want as much of this resource as they can possibly attain given its finite nature. In such a case, we may well get a second type of fundamental social interaction; what is called competition.
Also, we may get some form of both, what is called coopetition, a more complex dynamic involving elements of cooperation and competition. All of these different dynamics are studied within the area of game theory.

Institutions
All of these interactions between agents are going to produce some enduring patterns that become solidified into what are called economic institutions. The idea of an institution is one of the basic concepts within all of the social science. Wikipedia has a good definition for a social institution: “Institutions are stable, valued, recurring patterns of behavior. As structures or mechanisms of social order, they govern the behavior of a set of individuals.” Examples of economic institutions are financial markets, corporations, banks, pension funds, insurance companies and all kinds of special purpose vehicles amongst many others.
These institutions facilitate specific interactions by defining a set of rules so that these rules don’t have to be reinvented and renegotiated for every agent, for every new choice, or for every new interaction. Because of this, institutions enable automatic well-defined behavior and interactions that facilitate the coordination of economic activity. These enduring patterns that we call institutions are composed essentially of nothing more than the coordinated choices made by individual agents, their submission to follow predefined protocols. But they become embodied within abstract principles and rules that both enable and constrain individual agents within the institution. If institutions are primarily the aggregation of the choices made by economic agents, then a key consideration is how these choices are aggregated and distributed out, that is to say, what is the structure of the institution.
Is this aggregation of choices concentrated within a small subset of the overall system, which would give it a centralized structure, such as a monopolistic market or command and control economy? Or is it more distributed, such as an oligopolistic market? Or is it fully distributed, such as a pure market economy, where producers and consumers have the freedom to make their own economic decisions without those decisions being guided or coordinated by some central controlling mechanism? These different institutional structures will give rise to very different properties to the overall system with different dynamics and different responses to the question of macro level resource allocation.

Economic Dynamics
The last major set of questions we will be interested in asking - and any major economic paradigm will have to try and answer - is that of economic dynamics. Economic dynamics is the study of how the structure and makeup of economic systems change over time. What we are doing here is asking are there patterns in the time series data to the state of the economy, and what logically consistent models can we create to match those patterns?
This time series data is, of course, giving us a snapshot of the macrostate to the system at any given time. A macro-scale economy like that of a nation involves many interacting parts, from demographics to education, to employment, to international trade, to government policy, to corporate management, to the availability of capital in the financial markets and so on. Our theory will want to give some basic overall model of how these macro-level subsystems interact, and how they give rise to the overall state of the system at any given time.

Growth
If we remember back to our definition, this whole economic project is about striving for more of what we define as valuable. In a certain sense then, this whole enterprise of economics is setup to grow, but that idea of what growth means can be defined in different ways. Is it simply getting more of the things we value, as in more cars, more houses, more holidays? Or is it getting things of a higher value and quality, that is to say, instead of buying more watches I switch to a Rolex watch? Thus, instead of getting more of something I have moved up the value chain, and this moving up the value chain is one form of economic development. The end result of both of these will be a greater total value which we could define as growth, but they are both very different ways of achieving it, with different consequences. Thus, at the end of the day we want our model to aid us in reasoning about such questions as, how do economies grow? Why and when do they go into recession? Is there such a thing as distinct and objective economic stages of development? If so, what are they? And with respect to policy, how can we manage the system in order to achieve this development in an equitable and sustainable fashion?

Conclusions
Finally, we will make a quick note about theories in general and economic theories in practice. Model and theories are not real. There is a real world and models do not exist there. They simply help us to interpret and give structure to it, sometimes even predict it. But this is not to say that models do not affect the world – quite the contrary. Within the social sciences, they have a very significant effect. We create these models. People adopt them and go around seeing the world through them and acting on them. In so doing, the models change the world. Thus, in creating models we are responsible for creating the future state of the system. Economic theories are translated into the design of economies through economic policy. If we build robust models and they are properly translated, things will work. If we build incomplete, inconsistent or inaccurate models there will be real consequences that we need to take responsibility for. And thus, as always, we should be careful when dealing with very abstract models and try to play safe. Playing safe means being aware of the assumptions that support the theory and making explicit why one has made those assumptions; when the assumptions are relevant and will work and under what circumstances they will fail, warning people not to use them under such circumstances and always keep in mind that models are not reality, they are simplified representations that aid in our reasoning.

Standard Economic Theory
In this section, we will be taking a brief overview of the internals workings of the standard theory of economics. We talk about how it is a framework that applies linear systems theory to economic analysis. In so doing, it defines the economy as a closed system, the core structure of which being a general equilibrium between supply and demand leading to a framework that is often defined as the "rationality-individualism-equilibrium nexus." We discuss this idea of rationality of agent behavior, that is, individuals making consistent choices in isolation. We talk about zero sum interactions between agents and how methodological individualism de-promotes any conception of institutions beyond that of pure market mechanisms, which is seen to be the optimal method for macro-scale resource allocation. Finally, we talk about how linear systems theory gives us a certain view of economic dynamics that sees change coming from exogenous factors and economic development as an increase in gross throughput to the system.
This section will not be a critic. If you are reading this book, you would have probably heard many of the critiques leveled against standard economic theory. The limitations of our standard economic framework are not superficial. They are systemic in nature, meaning they are part of the very foundations and fabric of the framework. What we will be trying to do here is get an idea of why our traditional economic framework is the way it is. From this, we should gain a greater appreciation for it and gain a true understanding of where its limitations lie. Key to understanding this is in understanding what we call linear system theory. So we will spend quite a bit of time talking about that first.

Standard Economic Theory
The first thing we need to appreciate is that standard economics wants to be a quasi-hard science. It is quite explicit about the fact that it does not wish to be seen as a so-called soft science like sociology or anthropology. Hard sciences are what they are because they are supported by a formal mathematical language through which everything can be decisively proven to be correct or incorrect within that logical framework, and this rigor gives them their so-called hardness. Formal mathematical proofs and equations are the gold standards in terms of validation within modern science, and traditional economics wants this gold standard of validation. The important thing for us to note here is that in order to achieve this, it has adopted a particular theoretical framework. This framework is called linear systems theory.
Linear systems theory is a mathematical modeling framework that was most coherently formalized by Sir Isaac Newton and then fleshed out within the development of classical physics some three to four hundred years ago, where it has many successes. It has gone on to form the backbone of modern science. Economics like many other areas of science adopted this framework during the 19th century because it is a very abstract powerful framework, and by formalizing your theories within this framework you can get access to quite advanced mathematical machinery, the kind that supported classical physics such as linear algebra, calculus, differential equations and so on. In short, if you wanted to be a respected science in the 18th, 19th and much of the 20th century you had to adopt linear systems theory and that is what economics did.

Formal Languages
Linear systems theory is the dominant formal language behind mainstream economics. If you want to formalize an economic theory in standard economics then linear systems theory is largely all you have. Thus, everything has to fit into this formal language. Formal languages have alphabets and syntax that enable valid expressions. There are things that you can encode into that language and express within it, and there are things that you cannot encode or express with the language. Trying to use a formal programming language like C++ in order to describe the feeling of guilt would be a lost endeavor. That formal language was not designed to encode or communicate such a phenomena, it will not give you the vocabulary or methods for properly expressing such things, it may capture certain aspects but much will be left out. This is very much the same with standard economics it is using a language that is best suited for talking about simpler linear systems - as are commonly found in physics - and its limitations become apparent when presented with trying to encode and communicate more complex phenomena that lie at the heart of economic reality.

Linear Systems Theory
A full discussion to the internal workings of linear systems theory is beyond the scope of this section. But in its essence, linear systems theory deals with closed systems. Closed systems tend towards equilibrium. Equilibrium is a point of stasis where different forces acting on the system are counterbalanced. You can then use this concept of equilibrium as the "normal" state of the system and describe it in terms of the different forces acting on it and how they will drive it back to the equilibrium state. Likewise closed linear systems obey the additivity principle, meaning the whole is equal to the sum of its parts. The whole is never anything other than the sum of its parts. This is an important assumption that it is necessary to make if you want to get nice closed form equation based models.

Closed Systems
In order to use linear systems theory, it is necessary to define a closed system, and the primary aim is to identify an equilibrium within that system around which there is a balancing negative feedback loop. Standard economics has integrated economics with linear systems theory by defining equilibrium points such as supply and demand, and this is key to understanding why it is the way it is because everything has to come back to this equilibrium as the "normal" state to the system.
What you do from here is assume this general equilibrium and then work backward by asking what rules governing the behavior of actors would result in this equilibrium. If you can come up with a theory to do that then you will be able to create a closed form equation based solution, and that is the primary aim of models within standard economics.
This means that standard economics does not ask, what choices do people make and what are the outcomes of those choices – which would appear to be the obvious questions to ask. But instead, because it is based upon the premise of the outcome already being an equilibrium, it has to work backward assuming there will be an equilibrium and then asking what agent behavior is consistent with that outcome. This places significant constraints and limitations on the whole framework as it will limit how agents act before we even go and get empirical data as to how they actually act. This is a constraint that leads to a number of problems further down the line when it is confronted with how people really act.

Individual Agents
This leads us to the model of agents within standard economics. Standard economics is sometimes described as being defined by what is called the "rationality-individualism-equilibrium nexus." It is like this because this is how one needs to model individual economic agents in order to get general equilibrium, and thus make it compatible with linear systems theory. This is called rational expectation or model consistent expectation. Because everything has to add up to zero in the end in order to get a closed-form linear solution, the agents have to act in a rational fashion. Where rational is defined as acting in their own consistent, purely economic self-interest and out of the suppliers and the producers acting in this rational fashion we will get our negative feedback loop and the model will work.

In the standard view, economic agents are defined as rational actors, that is to say, agents that are governed by a logic of rational choice. Rational choice is defined to mean the process of determining what options are available, and then choosing the preferred one according to some consistent and independent criterion, with each agent performing this process autonomously according to their own well-defined preferences, thus each essentially performing an optimization algorithm. One thing to note is that these are expectation models, which means that they are not really saying that this is how agents act, but instead that this is how they should act in order to get our general equilibrium.

Value
Next, we will talk about the standard theory of value. Within standard economics, economic value is a single homogenous variable that is well defined. It is a measure of the benefits provided by a good or service to an economic agent, what is called utility. Utility is a measure of preferences over some set of goods and services. The concept is an important underpinning of rational choice theory.

Utility is an important concept in economics and game theory because it represents satisfaction experienced by the consumer of a good. A good is something that satisfies human wants. Since one cannot directly measure benefit, satisfaction or happiness from a good or service, economists instead have created ways of representing and measuring utility in terms of economic choices that can be measured. Utility is revealed in people's willingness to pay different amounts for different goods.

This is determined primarily by the demand for the object relative to supply in a perfectly competitive market. Many neoclassical economic theories equate the value of a commodity with its price, whether the market is competitive or not. As such, everything is seen as a commodity and if there is no market to set a price then there is no economic value. This is, of course, an extrinsic formalization of economic value. Value is relative and it is relative to scarcity and competition.

Market Failures
Of course, there is no mention of intrinsic secondary value here, that is the value that an entity may have independent of an individual's evaluation of it - such as a tree might have in providing ecosystems services to maintain a functioning ecosystem. There is no real way of defining secondary value or converting it into primary value. Thus, this formalization of value creates a dichotomy between primary economic value and secondary supporting value. If something does not have utility - that is to say immediate economic value to some actor - it cannot be properly brought into the framework and managed by the market. This formalization of value results in two types of commodities, one free market where all these conditions hold and another where they don’t hold and they have to be managed through government regulation. Where government provides the secondary evaluation mechanism that the market could not provide because these secondary values do not have immediate utility. This is called market failure. Market failure is when the evaluation of something in terms of its pure utility leads to far-from-optimal societal outcomes because these secondary values are not being taken into account by the market. More formally we call this secondary value a positive externality, it is called an externality simply because these models can not incorporate it into the framework built on a utility based value system.

Externalities
The result of this dichotomy is the idea of externalities, that is, that value is being transferred from the primary economic domain of utility to secondary value which is not captured by the model, and thus outside of the market mechanism and considered an externality. Externalities can be both positive and negative, and of course, societies want more of the positive and less of the negative externalities. Thus, an alternative set of relations is defined by government regulation in order to capture and quantify these external forms of value and reconnect them back into the economic equation governing the actions of the agents in the system - through such mechanisms as subsidies, grants, taxes, tariffs etc.

The net result of this model of value in purely extrinsic terms as captured by the concept of utility is that the market becomes dependent upon regulation. Because this secondary value is externalized from the model - and thus the market system - while at the same time it is dependent upon it, the whole thing is not sustainable without regulation, but regulation is an artificial mechanism that places constant friction on the system.

As previously mentioned, value is a very complex thing and fundamental to any economic paradigm. How the framework defines it will have major consequences down the line.

Interactions
Next, we will talk about the interaction between agents within the standard model. One of our key considerations within the domain of economics is the fact that during the course of the agents pursuing their valued ends, they will inevitably interact and how they interact will be of great importance to the overall enterprise.

The interactions between economic agents within the standard model will be significantly constrained by the fact that, in order for linearity to hold, additivity has to hold. Additivity means that the whole can be nothing more than the sum of its parts. Within the Walrasian economy - which is the standard general equilibrium theory of the economy - there cannot be any macro properties that cannot be derived in theory from micro properties.

All interactions between agents need to be additive for equilibrium to hold. Additive interactions are within game theory called zero-sum. Zero-sum interactions define a certain subset of possible interactions between agents. What one wins, the other loses, meaning everything sums up to zero and additivity holds. These are zero-sum interactions between agents.

When the Neoclassical paradigm is taken to its natural conclusion, relations between agents both external to an organization and internal to the organization are defined as zero-sum. Which is somewhat counter-intuitive because we typically think of organizations as forms of collaboration. But by creating a hierarchy where the gains and losses of an agent at any level within the hierarchy are counter-balanced with the gains and losses of an agent above or below in the hierarchy, we again get a zero-sum game, and thus, a model for defining organizations as nothing more than the sum of their parts. Again, this is important because it means the additivity principle holds and linear models will work. Organizations are then defined to exist primarily simply because of transaction costs.

Of course, within game theory, there is another possible class of interactions between agents, what is called non-zero-sum. Through non-zero-sum interactions - such a synergies or interference - value is added or subtracted from the combined system by the relation between the agents. Thus, the whole is not a simple aggregate of the parts and it is non-additive, thus nonlinear, thus not compatible with general equilibrium theory.

This model can only really help us in describing and modeling one type of interaction. Any type of interaction that adds or subtracts value to the organization as a whole cannot be properly formalized - because of the requirement for additivity which is an inherent part of linear systems theory.

Institutions
This approach leads to the idea of the efficient market hypothesis, the idea that without external intervention causing friction the market will always clear and be the best mechanism for macro-level resource allocation, what is called Pareto optimality. In order to have so-called efficient markets, every agent must be a price taker. Agents are price takers when they act on the belief that the terms on which they can transact can not be affected by their own behavior. These conditions only really hold within a pure market. Thus, this model only really works and describes pure markets, which of course is just one type of market amongst others. But within this paradigm, pure markets are always seen to be the most efficient.

Anything that deviates from the free market is seen to be suboptimal and these deviations are thought to derive from exogenous factors that add friction to the system.

Macro-level regularities or institutions within economies are explained within the standard model through the use of what is called methodological individualism, which within economics is the position that economic phenomena can be explained by aggregating over the behavior of agents. Any form of macro-level structure or institution is believed to be fully derivable from micro-level phenomena - although in practices this is not really possible. Methodological individualism is not particular to economics. It is used in many areas of the social sciences and it will give us linear solutions.

Development
Lastly, in our discussion on standard economic theory, we will look at what models it presents for analyzing economic dynamics. The first thing to note is that because it is based on linear systems theory, we are always going to get general equilibrium. Equilibrium is a point of stasis, a static point. It is going to be very difficult to describe how things change when everything is dependent upon them always adding up to zero and thus staying the same. The net result will be that there is nothing inside of the model that will allow us to describe the development of the whole system.

Any change is going to involve some period of non-equilibrium. We do not have the language to describe non-equilibrium. Non-equilibrium is simply non-existent in this language, so all we can really do is ascribe change to exogenous factors, saying that they are outside of the system - such as natural disasters, social unrest, innovation in technology, cultural factors etc. We will simply say that these exogenous factors knock the system out of its natural state of equilibrium and then describe how it will go back to equilibrium again. This is what these models will allow us to do. They will not allow us to think about the economy as a dynamic system that is constantly changing due to internal drivers.

If we can’t really talk about how the whole system changes over time within its environment and our focus is internal to the system - which it always is with analytical modeling - we will define change and growth in terms of how much the system processes, that is the quantity of economic activity which is captured by the metric of GDP. Quite simply then, growth will be defined as more economic activity, more throughput to the system. Which is one way of defining our overall objective within economics; which can be defined as the use of efficient means towards achieving valued ends. Standard economic theory gives us a picture of the economy as forever progressing in a linear fashion without the capacity to describe how it may evolve through abrupt phase transitions - as experienced during financial crises for example - into new overall patterns of organization.

Conclusion
Formal languages are very abstract conceptual mechanisms and their high level of abstraction gives them a lot of power, but also they are in many ways quite dangerous in that they can systematically prevent us from seeing certain facts that may be blatantly obvious without them. Like all modeling frameworks, linear systems theory has its achievements and its failings. It has relevant applications and inappropriate applications. Many other areas of science have come to recognize both the achievements and limitations of linear systems theory. In particular, we could cite physics - which since the early 20th century when general relativity and then later on chaos theory presented it with the limitations of this modeling framework - has managed to a certain extent to develop and incorporate both linear and nonlinear methods and use them when appropriate.

Theories are like tools that aid us in trying to describe the world around us. There is little point in asking whether a tool is correct or incorrect. What is of value to ask is whether the tool we are using is appropriate for the job that we are using it for. A hammer is appropriate for putting a nail into a piece of wood, but not appropriate for putting a screw in. Thus, whether the tool is appropriate is relative to the function we are trying to perform. Linear systems theory applied to economics has offered us a lot of insight and traction on this very complex phenomenon that is an economy. Like all theories, it has its capabilities and limitations. After all, it has provided the theoretical framework for supporting the development of the vast machinery of coordination that is advanced industrial economies. It is in many ways a great achievement in that it enabled the important stage in our development that was the Industrial Age. But if we want to try and describe something very complex like an economy, we are going to need different tools, but economics has kind of gotten stuck with the one toolbox.

As the economist, Eric Reinsert put it: "We are in the situation described by Mark Twain that if you choose a hammer as your tool, you are going to spend the rest of your life looking for things that look like nails. And this is what economics is doing. Instead of saying, here we have a real world problem – what angle should we look at this from and what tool should we use, we come to all situations with the same tools."
Our global economy is in a state of rapid and fundamental change - both its technology infrastructure and social institutions. As we come to an end of the life cycle of industrial age systems of organization, we are in the process of rapidly building a new post-industrial, global, services and information economy. These are major structural transformations that are working to increasingly reveal the limitations to our standard economic theory and necessitating a new paradigm and models.

Rise of Economic Complexity
The standard linear systems framework to economics was developed during the Industrial Age and has enabled a transformation to the domain of economics from being a part of philosophy to becoming a much more powerful framework that could support the huge economic transformation that was the industrial revolution. It has in many ways been very successful doing this, but today a number of major trends are having a fundamental transformative effect on our economies as we transit further into the 21st century. In this section, we will be talking about some of these major trends that are reshaping our global economy both on the macro-level and the micro-level, both in the real economy and on the institutional level. These trends are taking us into a world of heightened connectivity, interdependence, in short, into a world of complexity. A world that in many ways goes beyond our traditional Industrial Age paradigm.

Post-Industrial World
What we will be trying to give an overview to here is the macro scale transition of advanced economies as they are currently going from an Industrial Age form to a post-industrial form. We use this very open term ‘post-industrial’ because it is not totally clear what will be the defining factor to this next generation economy, but we can identify a number of major factors that are becoming more apparent. The term post-industrial is in many ways a synonym for a services economy, and with the huge rise in services over the past few decades advanced economies are already fundamentally service economies. Services are very different from Industrial Age products and this has major implications that we will be discussing.
Given the profound effect that the information revolution is having on our economies as they become driven by information and knowledge, we will look at some of the implications of this for economics. Globalization is another very important transformation. Our economy of the 21st century is increasingly globally interconnected, we will discuss this also. Lastly, we will talk about the rise of sustainability as it is becoming an ever more important factor in building this next generation of sustainable, globally integrated economy based on services, information and knowledge. This is obviously a lot to cover in this short section so we will just get to touch on some of the most salient factors to illustrate how they are leading to an ongoing transformation in the structural complexity of our global economy.

Services Economy
The services revolution can be illustrated with reference to very straightforward empirical data. Over the past number of decades, services have come to dominate advanced economies and are slowly but surely coming to dominate the global economy. Behind this simple observation is a very profound, subtle and complex transformation, as it means the stuff that our economies process is changing. It is changing from tangible industrial products to intangible services. These two things have fundamentally different characteristics, meaning this transformation is having a very significant effect on what the economy does and is.
And remember what all this economic activity is about. It is about the efficient use of scarce resources to achieve valued ends. Within post-industrial societies, these valued ends are subtly but fundamentally changing. Advanced economies have largely completed the process of industrialization - the function of providing basic industrial products to the mass of society. And people want more than this now. They want things like experience, like actual quality of life. People aren’t happy to just go to the nearest beach on holiday anymore. They want a package holiday that takes them to some exotic place, providing them with a full experience they can tell their friends about. They don’t want just a pair of jeans. They want some designer jeans where what they are really paying for is a story that an advertisement agency produced. The actual physical product is outsourced to some industrial developing economy. Advanced economies increasingly create the service experience that goes on top of the product, not so much the product itself.

Nature Of Services
The nature of services is studied within service science and service design. We won’t go into the technical details here, but services include all sorts of things that are way outside the box of our traditional Industrial Age model such as attention, advice, access, experience, discussion and of course information of all kinds. These are not things that you can wrap up and put in a box to be pushed over the counter. But wrapping things up and pushing them over the counter is the only real model we have so we go on trying to use it. The whole model that was built for the mass production of standardized tangible industrial products that were pushed out to isolated and passive end-users is being stretched by the rise of the services economy.
Successful services are things like how happy you felt visiting a restaurant because it was a smooth seamless service that provided you with what you expected and wanted. The focus is on people interacting with people and serving the customer rather than transforming physical goods. Service systems place people at the center of the world. They aggregated disparate technologies and subsystems in order to deliver functionality that is, importantly, measured in terms of customer satisfaction, and that is a very different metric to how many products you push over the counter that day.

Changing Needs
Maybe the best example of this is within advertising. Previously it was about paying some celebrity or beautiful person to tell other people that if they buy a product their lives would be better. Advertising today is increasingly focused on getting your friend to tell you that they brought the item and it actually made their lives better. The difference is subtle but profound. It is not about fancy things that have all sorts of amazing properties. It is about the actual value and experience that they deliver to a specific person often within a specific context. Increasingly this idea of just getting more things is not really cutting it. After many decades of prosperity, we are becoming somewhat disillusioned with this dream that was part of the industrial model. People increasingly want the real thing – happiness, health, well-being, quality of life. And that is a paradigm shift, because the industrial model always looks inside of the economy, modeling its throughput, but in the real world, it is not just about what you produce. It is also about what people want and how the economy matches that. This might sound obvious but it doesn’t fit into our traditional model. All we can capture is the gross output to the economy GDP, not a quality of life which is what people increasingly want their economies to deliver.

Servicization
As mentioned, servicization is a very subtle and complex economic phenomenon and it is in many ways the foundation for the implementation of the information revolution to our real economies. Things have to be servicized before they can be digitized. They are in many ways two sides of the same coin, symbiotic, enabling each other. To quickly summarize, services engender a whole new economic paradigm involving co-creation, enduring service relationships, service process and life cycle, context, product service networks, personalization and extreme customization. This is very different from the Industrial Age mass production of standardized one size fits all, discrete products that can be easily quantified. It is one dimension along which advanced economies are evolving into a more complex form based on networks of services instead of the familiar discrete products.

The Information & Knowledge economy
The information revolution is probably pound for pound the most profound and radical force of our time that is felt everywhere; from hooking up online to the automation of production lines. It is having a structural transformation to both the technology and institutional infrastructure of our economies as they become networked, adaptive, automated and virtualized. Probably the most significant thing to cover here is this big idea of connectivity - or what is also called hyperconnectivity - which is clearly being driven by information technology as it networks our world within all domains and on all levels. Hyperconnectivity is a very radical phenomenon. We will not present data or go into details on this, but just present a very high-level view of what is relevant to our current discussion.

Connectivity
Complexity theory has in many ways taught us that connectivity is a fundamental parameter to a system. When we have a low level of connectivity within a system, the component’s states can remain asynchronous for a prolonged period of time. I might totally disagree with my neighbor about what color shoes people should wear, but as long as there is a big fence between us and I only see him once a month to say "hi" this is not going to be a big problem and we can go on maintaining our very different philosophies about the coloring of shoes. But now let’s turn up the connectivity by saying me and my neighbor get employed by the same company to design the same pair of shoes. This connectivity means we cannot go on in our previous isolated asynchronous state. We will inevitably come into conflict and/or coordination because we are now, and this is the important thing, interdependent. The dynamics of independence, which was our first state, and interdependence which connectivity creates, are very different.
With interdependency, the gains and losses of one become correlated to the gains and losses of another. Within this dynamic, an individual cannot systematically get ahead by reducing the value of another one, but you have to make the whole pie bigger in order for you to get ahead. This fundamentally changes the dynamic towards openness and cooperation not because people all of a sudden become nice, virtuous individuals. We are not changing the variable of how altruistic actors are; we are assuming this stays constant. What connectivity changes though is the structure of the game we are playing. Connectivity drives interdependence and non-zero sum games.

Network Effects
Added to this is the network effect, which basically means that the value of something is in its capacity to interoperate with other things. In an interconnected world, the value is in the network, not so much in a thing, product or organization. Almost all the valuable knowledge your organization has is not in your organization. It is on the internet, and your organization is going to have to have access to that network for it to maintain relevance. That means you have to be part of these networks and your value is in your differentiated function within them.
The point for us to take away here is that information technology is driving connectivity, which leads to both greater conflict and cooperation but ultimately greater interdependency. Because of the dynamics of interdependence, it tips the balance towards open systems of organization instead of closed systems. This is going to present major problems to our traditional economic models based on assumptions surrounding closed systems and zero-sum games.

Mass Automation
Something as profound as the information revolution has many ramifying effects across the whole structure of advanced economies, and another one of these is mass automation. Information technology is commoditizing basic information processing and services as the next generation of software systems and algorithms are specifically designed to automate these functions. Whether we like it or not, whether we are ready for it or not, mass automation is upon us in the coming decades with significant economic consequences. You can take many basic services, information processing, and manual tasks, and there will be some team in Silicon Valley working on automating this process, and major breakthroughs in the technology that supports them in doing this are happening right now. As IT commodities basic economic activities, it will drive value up the value chain and it is within this context that we can talk about the burgeoning knowledge economy.

Knowledge Economy
As the sea of data and information grows exponentially, the amount of knowledge and intelligence become relatively scarce. If you have spent any time in the world of business management, you would have heard the word innovation and a relentless demand for more of it, as human capital and innovation are moving to the forefront of how organizations generate value. Commoditization of basic production processes and services puts business organizations, and in particular multinational corporations, in a very competitive space, as they have to move up the value chain to maintain differentiation. This makes the knowledge economy an ever more clear and presents reality enabled by information technology. Suffice it to say the knowledge economy runs on very different rules to that of the industrial age economy.

Virtualization
Another major factor to be considered here is what we might call economic virtualization. Information technology always and everywhere enables virtualization. Virtualization is the process of decoupling information from its underlying physical supporting structure. The image of a planet once only existed as an extension of a physical planet. Information technology has enabled us to decouple that information from the physical presence of the planet, and we cannot store, manipulate and exchange this information independent from the underlying physical structure. Of course, this process is nothing new. We have been doing this for thousands of years, but with the information revolution, it is in hyper-drive.
As with almost all other areas, this virtualization process is also happening to our economies. With respect to our discussion here, money can be thought of as a piece of information that represents some form of economic value. Finance is then the storage and exchange of this virtualized economic value. From this perspective, finance is the information layer that sits on top of the economy. It is then possible that anything forming part of the real economy can be converted into a financial instrument and become part of the financial system. The process of doing this is called financialization, and financialization is a major trend that has been taking place over the past few decades.
I will quote Wikipedia on this subject when it says: “Financialization is a term used to describe the development over the decades between 1980 and 2010, in which financial leverage tended to override capital equity, and financial markets tended to dominate over the traditional industrial economic activity... Financialization describes an economic system or process that attempts to reduce all value that is exchanged - whether tangible or intangible, future or present promises, etc - into a financial instrument. The intent of financialization is to be able to reduce any work product or service to an exchangeable financial instrument and thus make it easier for people to trade these financial instruments.”

Financialization
Financialization can be thought of as the virtualization of our real economies. Through information technology, mathematical modeling and lots of financial analysis we take any real economic asset and virtualize it into a financial instrument, that can then be processed and exchanged within the financial system. Since the liberalization of financial markets and the rise of information technology, the financial industry has been in a state of hyperdrive performing this activity. The net result of this is that it has come to dominate over the real economy. As you might imagine, this machine that we have built and are now dependent upon is very immature, fragile, and we are far from understanding it, placing us in a very precarious and unstable situation.

Heterogeneous Value
Information technology is also transforming our capacity to quantify and define value itself. With social networking technologies and the Internet of Things, information technology is giving us the capacity to quantify our world like never before. Things that we thought we would never be able to quantify like friendship or Co2 emissions increasingly have real values associated with them, such as likes on Facebook. And as we start to embed sensors in all kinds of devices and objects we can get real data about many aspects to our natural environment that were never possible before. What this means is that it is increasingly possible to virtualize all forms of value, social capital, cultural capital, ecological capital and industrial capital. They are all converging onto common internet based platforms. It is becoming increasingly clear that all these different forms of value are not totally independent but increasingly interconnected. People liking your business on Facebook translates into increased revenue. People being prepared to pay extra for sustainable products means the exchange of ecological value for financial value. Fair trade and social impact bonds mean people are paying for social capital, with ethical bonds and green bonds you are paying for cultural and ecological capital with financial capital. Different forms of value become merged into a single product.

Value Exchange
All of this is only possible due to information. The more information we have, the more we can directly translate all forms of value on to a common platform and see before our eyes how they are exchanged. This means that the value of something is increasingly heterogeneous. Value is less a single thing, as we increasingly recognize, quantify and correlate different forms of value. Thus, a commodity may well stop having a single homogeneous value. Its value will be a network of interacting variables and we will be able to, in some way, exchange between these values, which of course we already do and have always been doing. But with information technology, we now have the capacity to make this explicit. Here again, we are going to get a breakdown within our traditional model that is assuming homogeneous closed forms of industrial value.

Distributed Systems
Lastly, in talking about information technology we will note how it is enabling a new distributed structure to our economy. From manufacturing to retail and finance, information technology enables production to happen at the edge of networks and those goods to be exchanged directly from peer-to-peer, which is in strong contrast to our traditional Industrial Age centralized systems of organization. As an example of this, we will talk about what are called distributed ledgers. You have probably heard of Bitcoin and you probably know that it is just one of many different digital currencies, in fact, it is just one of hundreds or even thousands. These digital currencies are built on top of a technology call blockchain, which is a form of distributed ledger. A ledger is a record of value exchange, typically associated with the counterparties involved in that exchange. The finance industry is built on ledgers. This model of a ledger essentially captures the backbone of what finance is, and because finance is really an abstraction of the economy, it also really captures what a market is.

Centralized Institutions
In order to facilitate a financial transaction, you have to have two identifiable parties who wish to make that exchange, and you need some impersonal system to verify their identities, if needed, and keep track of the transaction in some form of ledger as a record of what happened and who owns what. These third party organizations need to be seen to be legitimate, authoritative, enduring and all those things that enable people to place their trust in them so that the transaction can be facilitated. This is largely what the financial system does. Of course, it serves other important functions, but this is in many ways the center of its function. Within the industrial model, this whole framework was and still is built on a centralized system. Within the industrial model, these ledgers are managed and verified by centralized organizations such as banks. But the assets on these ledgers can be of any form such as currency, pensions, contracts, mortgages or ownership of any asset. Thus, there are many different institutions but these institutions are typically backed and regulated by the government, the ultimate centralized authority within this system.

Distributed Systems
A distributed ledger then is a ledger that keeps track of all of the transactions that have ever been made within the value system. This information is encrypted and held on many different computers. Whenever two individuals wish to conduct a transaction, one of these ledgers is randomly selected in order to verify the transaction. Once it takes place, all of the other ledgers will be updated with the new information. So this is an open system in that the information is distributed out, but this information is of course still encrypted. The ledger is then simply a list of all the transactions that have taken place. The process of verification is distributed out among many different computers. Distributed ledgers are essentially value exchange protocols. You can exchange any value with them, the deeds to your house, some currency, claims to a parking spot for your car, victory points in a computer game. They can all be encoded and safely exchanged without a centralized authority.
This is a technical system. The faith is in the mathematics and technology, not people or institutions as it currently is. Uptake of this technology is very fast at the moment, with somewhere around 10x growth per year. This has major implications for the financial system.
In a recent interview with the BBC, Derek White of Barclays Bank had this to say: “We see the power of what this blockchain can become. Venture capitalists see this but even more exciting is the disruptive minds of entrepreneurs are seeing the power of this and they are building new businesses, new paradigms that are going to change the shape and face of all industries.“
In a World Economic Forum report, they said this: "Economic and monetary management will be overhauled by new systems anchored in digital currencies and the blockchain, making traditional pricing mechanisms and exchange rate systems less relevant."
The WEF notably projected that governments would begin leveraging the blockchain sooner than the mainstream public, with this expected transition occurring by 2023.

Economic Globalization
The abstract phenomenon of globalization is one of the major processes of change in our world today. It is a social, cultural, technological and of course economic phenomenon. On a theoretical level, it is a process whereby the reduction in transaction costs leads to increased connectivity between components within the global economy. The result of this is their differentiation with respect to each other and out of that process of differentiation emerges some global pattern of organization. This is very much the same dynamic that we discussed previously, where interconnectivity drives interdependence and that changes the rules of the game. What information technology is doing for connectivity on the micro-level globalization is in many ways doing on the macro level. But this is a very high-level abstraction of what is, in reality, a very messy and complex process. It is a process that is only just beginning. Our world is a very big place and it is socially, culturally and economically, still very heterogeneous. It is going to take a lot of globalizing before it is properly globally integrated. This process of globalization involves many deep economic and political vested interests that create many highly contentious issues. These are things that everyone cares about.

Process Of Globalization
Our basic premise here will be this: Economic globalization is primarily driven by global connectivity. This interconnectivity is enabled by two primary factors, one technology, and the other institutional - that is the reduction in discontinuities and boundaries between jurisdictions. Lastly, corporations have harnessed both of these to develop global networks. These global networks are the primary structure and drivers to this process of economic globalization.
Starting in the late eighties a new economic and political ideology arose promoting the idea of the free market, both internal to the nation state through privatization and external through the reduction in trade barriers, tariffs and other policies that were designed to reduce the discontinuities between national jurisdictions and enable a global free market. The net result of this coupled with new information technologies has been a mass increase in global economic exchange.

New Technologies
Economies are at the end of the day built out of technology. Corporations are built on top of the available technology. Due to their profit motive and the competitive environment they operate in, they are often the first to adopt new technologies and try to exploit them towards gaining competitive advantage in their respective markets. These institutional transformations are happening on top of a new set of information and communications technologies that enable global coordination at the speed of light. Corporations have been effective at leveraging the new possibilities of these technologies to become global networks - both in terms of their physical form, as supply chains have become globally distributed through outsourcing, but also in their institutional form as networked organizations distributed out across global cities that provide them with the advanced services they need to operate competitively on a global level. And of course, we have financial institutions starting to leverage this technology and also pushing for deregulation and liberalization of financial markets.

Global Networks
The net result of this is that our economies are increasingly managed and operated not by nation states within an independent national economic system, but instead increasingly by these global networks run by multinational corporations. This creates both benefits and difficulties, but it is fundamentally changing the global economy from one that was defined and governed by discrete components to one that is essentially a set of global networks. This can and is enabling a huge restructuring to the distribution of power within the global economy because as we previously mentioned in these highly interconnected systems the wealth is largely in the network. If you can connect into the network and provide it with a differentiated function that needs performing then you can gain access to the resources that are flowing through that network, in terms of foreign direct investment, trade opportunities, expertise and so on.

Economic Development
If you as a nation can connect into one of these networks and provide them with what they need to function, whether that is commodities in frontier markets like Angola, cheap labor like China, financial expertise like Singapore, or tax havens like Ireland, then you can attract these resources and grow your economy at an unprecedented speed, and this has proven to be one of the most effective methods for raising millions of people out of poverty. It is also having a strong redistribution effect on the macro scale as resources within the global economy, that were previously highly centralized around western nations and in particular the US, are becoming distributed out to anyone who can perform a differentiated function that the network needs and if you can do that with a nation that has a billion or so people - like China or India - then you can very rapidly change the balance of economic power, which is what is happening. But of course, this is far from one big success story. It has created many challenges.
The economist Dani Rodrik illustrates this when he says:
“The essential problem of the post-1990 model was that we pushed for hyper-globalization without the institutional infrastructure. And this model created failures of legitimacy where in fact global rules went too far, such as in trade with the World Trade Organization, and created problems of regulation where in fact they didn’t go far enough, and global finance was a key example of that. So the fundamental problem of the world economy in the years leading up to the current crisis was an imbalance between the reach of markets that was increasingly global and the scope of their governance which remained by and large mostly national.”

Market Failures
The thing to remember is that this economic system is designed in such a way that it will systematically under evaluate secondary resources, that is the secondary social and environmental factors that support the free market. Without them, it can’t function. This model to an economic system has systemic market failures. Those failures create externalities that work to undermine the supporting structure to the system. The result is massive environmental degradation, extreme inequality, and many other problems.
Thus, this form of economic system needs some form of external governance to regulate these externalities. Without it, the system is unsustainable not just in the long term but even in the medium and short term. To be succinct this model has systemic failures. It only really works when it has the nation state to support it. Running this model that has systemic failures without its traditional support mechanism, at the scale and speed that we are currently operating it at is a precarious situation.

Governance Absence
The end result of this is that this primary dichotomy and balancing mechanism is breaking down. This is a major unresolved issue in our world today, a constant tension creating many problems that we don’t really have any solutions to. Another factor to note here is as Dani Rodrik noted, social governance remains by and large mostly national. We have global institutions but they are piecemeal. They don’t properly integrate and coordinate in order to be as effective as they need to be in order to deal with the powerful economic actors that are at play. Capabilities are still retained on the national level.
There is currently no real form of democratic social regulation to the workings of our economy on the global level. There is just a significant imbalance of power towards major private economic actors that have the capacity to significantly influence and manipulate weak political institutions. People know this. It affects their lives and they feel disenfranchised. It is expressed at best in mass cynicism and resentment against multinational corporations, and at worst it is expressed through violent protests at economic summits.

Solutions?
So why hasn’t the governance developed alongside the economics? There may be a number of reasons for this. One very simple fact is that coherent social governance is built on top of and requires cultural commonalities and consensus, which remains largely absent on the global level. Different nations have different cultures and from these, we get different conceptions about how they want the world to be governed. That remains in many ways deeply divided and without the consensus required to formalize coherent governance.
There are only a limited number of solutions to this. Either we try to turn back the clock, that is to say, de-globalize by trying to throw up barriers to cross-border flows, which might be possible, or we develop some form of much stronger global social institutions to manage these externalities in the same way as we previously did on the national level. That pretty much worked on the national level, whether it would work on the global level or if we could implement it is debatable. The last possibility would be to find some way of restructuring the market mechanisms, to reincorporate these negative externalities, that is to say, fix the market failures that are creating these issues.
Sufficed it is to say globalization is another vector that takes us into a world of complexity and raises many questions that seem to be unanswerable within the traditional Industrial Age paradigm.

Sustainability
The industrial model of the economy was built in a world of what appeared to be almost infinite resources. It was a world where millions of buffalo roamed across the prairies of North America and all you had to do was tame nature and the bounties were endless. This world of a struggle between man and nature is largely over. Through industrialization, we can pretty much declare victory, but this victory has come at a high price.
With a growing manifestation of the negative environmental externalities to the Industrial Age economic model, coupled with a growing manifestation of the finite supply of natural resources, has come the concept of sustainability, a new awareness, and paradigm surrounding human economic activity and its relationship to the natural environment.

Energy Efficiency
Sustainability is a whole new paradigm because it is a truly a new way of seeing the world. Think about something like a car. Within the industrial paradigm, cars make sense. After all, the auto industry is maybe 10 percent of our GDP, because advertising agencies told us how important they were to our freedom because everyone else had one etc. It all made sense largely because it fitted into the industrial paradigm. But with this new idea of energy efficiency, we suddenly start to realize that only a few percentage points of the fuel that we put into our car is actually used to move us. And this is when it is in use when on average a car is unused 92% of the time. When we start to look at the world in this way, things stop adding up in the way that they used to and we start asking whether that industrial model is still relevant. Within the industrial model, our economies looked like perfectly efficient well-oiled machines. Within the sustainability paradigm, we start to see a totally different picture. We start to see how the average household power drill is used for only approximately 10 minutes during its entire life cycle, how one-third of the food produced in the world for human consumption every year gets lost or wasted across the supply chain.

Integrated Systems
The paradigm of sustainability shifts our focus from the optimization of subsystems to the efficiency of the whole system within its environment. Linear systems theory is focused on subsystems. The industrial paradigm that is based on linear systems theory was thus focused on optimizing subsystems like individual businesses or individual production lines. In so doing, it systematically de-promoted the overall efficiency of the system within its full context. When we change this paradigm, we start to see suboptimal solutions on the global level. As these new ideas of energy efficiency and sustainability rises we are all slowly starting to become aware of this.
Start-ups from Brazil to Amsterdam to Taiwan are ready to take advantage of this. Building new business models around tapping into this vast expanse of under-utilized resources, many governments are eager to support them and people feel inspired by the opportunities. The circular economy may be a massive macro scale transformation to the deep structure of our economies, but in many ways it is happening one recycled plastic bag at a time.

Zero Marginal Cost
With this new paradigm, we are now creating value out of nothing, that is to say at zero marginal cost. We are creating value by reducing waste. Thus, we don’t have to produce anything and it may not even cost anything. Marginal cost is a central structure to our Industrial Age economic system. The whole thing is built around the idea that it cost something to produce value. As such, the circular economy is in strong contrast to our industrial economy that was focused on value in terms of production and consumption.
There is thought to be 62 Lego bricks for every person on the planet. We have produced a lot of Lego bricks and that created value, but the vast majority of those Lego bricks are now sitting in some cupboard not being used. The value proposition today is in getting those Lego bricks to the people who want to use them, and there are no shortage of start-ups that are focused on trying to tackle this problem through peer-to-peer markets. But this is not about production and throughput, which is what our whole economic machinery is designed for. As such it is creating a new form of economy, a circular economy based on the paradigm of sustainability which is only set to rise.

Conclusions
What we have tried to outline in this brief overview of the nature of our global economy today is essentially the problem space that we face as we transit further into the 21st century. As we noted our national industrial economic systems of organization have in many ways reached the end of their life cycle, and we are challenged with building this next generation economy and it is becoming more apparent what it will look like. It needs to be sustainable. It will be globally integrated, based on services, information, and knowledge. As we have seen there are many challenges we face in doing this. We have tried to highlight where and how our traditional models are breaking down and hopefully at this stage it should be apparent that these next generation systems that we see emerging - such as distributed ledgers, networked collaborative organizations, global supply chain networks and the circular economy - all run on a very different set of principles to the ones that are assumed by our existing economic paradigm.

Complexity Economics Overview
Complexity economics is a new approach to economic science that uses models from complexity theory to look at and model the economy as a complex adaptive system. It is one of a number of new approaches to economic theory that have arisen in response to the limitations of standard economic theory.
In this section we will be taking a brief overview to the area of complexity economics, highlighting some of its main characteristics and how it differs from a more traditional approach. We start off by talking about how it models the economy as an open system, meaning that it does not need to be in equilibrium. Relaxing this constraint allows us to create a whole new paradigm built on nonlinear systems theory. Within this paradigm, we get a much more complex picture to individual agents, the motives under which they act, what they value etc.
We talk about how a nonlinear framework will allow us to focus more on non-zero sum interactions where value is added or subtracted to the organization through the type of relations between agents - how synergistic interactions can give rise to emergent macro patterns of organization. Next, we talk about how complexity economics understands these institutions as complex networks, where the structure and makeup of the network defines macro-level resource allocation. Lastly, we talk about economic development as a process of evolution, and how this will allow us to better reason about structural qualitative transformations within the whole system as deriving from internal drivers.

Complexity economics
Because complexity economics is based upon nonlinear systems theory and standard economics is based upon linear systems theory, they are from a theoretical point of view very different. They are both looking at the same economy but looking at it through different paradigms. Whereas standard economics models the economy in terms of a closed system with homogeneous isolated agents, making rational choices that lead to equilibrium static macro-level outcomes. Nonlinear models present a very different picture. It is a model of the economy as an open system composed of heterogeneous agents with bounded rationality making choices within a particular context, which gives rise to networks of interactions that we call institutions and a macro level non-equilibrium to the economy that is in constant change driven by internal dynamics.

Open Systems
Standard economics is based on the concept of equilibrium, which is derived from modeling the economy as a closed system. Complexity economics relaxes this constraint allowing for the economy to be in a state of non-equilibrium. Complexity theory studies open systems, that is to say, systems that are so embedded within their environment, interconnected and interdependent with other systems, that we can no longer define them by their boundary condition and their static internal components.

With linear systems theory, we use the process of reasoning called analysis that starts by isolating the system from its environment so as to hold inputs and outputs to the system constant. This is what we do when we take things from their environment and put them in a lab. It is only by doing this that we can describe the system in terms of the additive properties of its internal constituent elements and derive closed-form equation based models. Complexity theory does not use this method of analysis. Because this method of analysis is very fundamental to modern science, complexity theory results in a very different way of looking at things. Because it does not use analysis it will allow us to study a system as being open; that is to say in terms of its functioning and relations within its environment. This is a process of reasoning called synthesis and it is the opposite from analytical reductionism.

Open Economy
Within economics, this will mean that unlike standard economics where the economy is modeled as a closed system, complexity theory will give us a model to the economy as fundamentally an open system. Standard economic models will not describe how the system interacts with other systems external to it such as the social or ecological domains. The economy exists in isolation. If anything is going to be incorporated into the model it has to be represented as being inside the economy. With complexity economics - because we are using open system models - we can think about the economy as one component interacting with other systems within its environment.

Because we are modeling the economy as an open system, there will typically be no single closed form solution. Isolated systems tend towards a single equilibrium. Open systems - because there is a constant input and output of energy and matter - do not tend towards a single equilibrium. They may have multiple equilibria, which is characteristic of nonlinear systems. This does not mean that they are random, they are just governed by different dynamics. What this means is that the end result of our model will typically not be a closed form solution, that is to say, an equation. In general - because we are dealing with open systems that are defined not by any equilibrium or equation - we look instead at the local rules under which the elements operate and how these rules interact to give rise to emergent outcomes and this is typically done through computer simulation.

Simple Rules
When using this framework we are interested in understanding and capturing the algorithm that the components are operating under and simulating it to derive overall patterns. By components, I mean agents or institutions. If we then want to go on and create a high fidelity model, we will put that algorithm into code. We will then run this computer model in order to get a simulation of the system’s behavior over time. If we do all that, we will have all the information we want to know about the system without ever needing an equation. The power behind this technique is one of the basic premises of complexity theory, that is, the idea that simple rules can create complex phenomena. We are defining simple rules and then using the computer to iterate on these simple rules to give us nonlinear interactions and feedback that will generate a model with a structure that is both complex and intricate – a high fidelity representation of real-world economic phenomena.

Non-Zero Sum
We are very much interested also in the interaction between components, unlike standard economics where these interactions have to be additive in order to get general equilibrium - which basically means the relations add or subtract no value to the system and thus can be largely ignored. In complexity economics, we are not trying to get an equilibrium outcome, and thus these relations don’t have to be additive. Because this is a nonlinear framework, they can be non-zero sum, which means they may add or subtract value to the system and these non-additive relations will be important to the overall makeup. Because these interactions are non-additive, they are going to give rise to non-equilibrium macro-scale patterns of organization that will have their own internal dynamics and structure and what we called emergent properties. The result of this will be a heterogeneous macro scale topology to the system - what we call institutions.

These internal emergent structures or institutions will add or subtract value to the whole system creating a macro-level disequilibrium. When we allow for non-equilibrium on the macro level, we can start to think about how the whole system changes over time and complexity economics uses the model of evolution in order to describe this macro process of change.
The fact that we define the economy as an open system allows us to talk about non-equilibrium, and this non-equilibrium is our first basic principle; it will structure and define much of the approach taken from here on. In the same way that general equilibrium is central to the overall workings to standard economics, non-equilibrium and non-linearity are defining factors in the whole approach taken by complexity economics. As with linear systems theory, this approach will enable us to capture and model some things and constrain us from modeling and describing other things.

Agents
Because we have an open model that is actually embedded within some real environment, we can begin to recognize the complexity of the real world. As the economics Axel Leijonhufvud once remarked, Neoclassical models give us a view of, quote “smart people in unbelievably simple situations, while the real world involves simple people [coping] with incredibly complex situations.”

The implicit expectation of standard economic models is that agents are seen as almost supercomputers that are able to run an optimization algorithm over thousands or even millions of different choices within a fraction of a second. Complexity economics - based on the idea of simple rules - instead ascribes individuals with only a very finite amount of computing power, what is called bounded rationality, the idea that when individuals make decisions, their rationality is limited by the information they have, the cognitive limitations of their minds, and the time available to make the decision. Bounded rationality tries to capture the fact that economic phenomena, actually at the end of the day, play out in the real world, and this has real implications and limitations. Again this goes back to the fact that we are using a model that allows us to see the system within its environment. Linear systems theory, because it is an analytical framework doesn't enable this. Modeling systems as closed is sometimes a big advantage, sometimes not so. But in this case, it is creating a very large disparity between what empirical data tells us and what the standard models tell us, and central to trying to resolve this is the new area of behavioral economics.

Behavioral Economics
Behavioral economics gives us a much-expanded and more complex conception of motives that are driving the individuals as it studies the effects of psychological, social, cognitive, and emotional factors on the economic decisions of individuals. Agents are still seen to be efficiently pursuing their valued ends, but these valued ends can represent a much wider spectrum not just purely industrial capital.
Because we are not constraining our model of the individual towards achieving equilibrium, we can begin to think about the individual agent as being in a real environment embedded within a multiplicity of different networks, each exerting its own force over the agent’s behavior, and thus linear causality, where A causes B, begins to break down. The net result of bounded rationality and a complex set of motives means that agents may come to hugely non-optimal economic solutions.

Value Theory
This leads to a discussion of what theory of value can this nonlinear modeling framework offer. Because we are looking at the economy within the context of its connections with other systems within its environment, we can begin to recognize the value of those other things that are not necessarily inside the economy. Using analytical methods, we can only ascribe value to anything that is inside of the system. For example, ecological capital is defined within the model as the mining or agricultural industries. It can’t have value outside or independent from the economic system.
But when we see these other domains outside of the system and in relation to it, then we can begin to reason about their independent value and how this might translate into primary economic value - utility. As long as we are using analytical methods focused on looking inside the system, we will only be able to ascribe value to anything that is inside the model. When we use synthetic reasoning to create models for the whole environment, we can then ascribe some value to all the different domains and begin to reason about how to create a metric for translating between domains, thus incorporating both extrinsic primary economic value and intrinsic secondary value. And this will be congruent with our model of agents as being under the influence of many different motives and value systems, as they respond to social capital, cultural capital, environmental capital and so on. It is a much more complex model where we are trying to take account of value in all its different forms. Value is not homogeneous, a single price determined by market equilibrium. It is instead heterogeneous, a network of different interacting variables - and with information technology, this is increasingly a practical reality.

Interactions
Next, we will talk about the interaction between economic agents. This is the domain of game theory, game theory models both zero sum games and non-zero sum games. Zero-sum games give linear solutions and are thus central to standard economics. Non-zero sum games result in nonlinear outcomes, and thus the nonlinear study of economics is mainly concerned with these non-zero-sum dynamics. It allows us to incorporate relations of cooperation or interference into our model. Both will give us non-equilibrium results.
Interference between components means some form of conflict between the agents that make the combined system less than the sum of its parts. As an example of this, we might think about price wars between different businesses. Inversely, cooperation is a form of synergistic interaction between agents. Synergies involve the components both differentiating their functions and coordinating them towards the common end. Through synergies, value is added to the composite organization. Through these relations, we get an organization that is greater than the sum of its parts. Synergies form the basis for the process of emergence that gives rise to different levels in the economy with diverse institutions serving diverse functions on these different levels.

Institutions
In the complexity paradigm, macroeconomic patterns are emergent properties of micro-level interactions and behaviors. But because of the nonlinear interactions between components that we previously mentioned, we cannot analytically derive the properties of the macro system from those of its constituent parts. Although we can apply computational techniques to model the behavior of the emergent properties, that is to say, agent-based models can simulate these emergent phenomena in high fidelity.
When we stop focusing on general equilibrium and the idea of individual atomized agents, and start to focus more on these interactions, what we are going to see is that these institutions are in fact networks, and the structure of these networks is very important because it is going to define how things flow through the network. Because we are dealing with open systems this is about input and output, where a component is in a network, the network’s structure and what is flowing through that network is going to be decisive in defining the inputs and outputs to any of its components or subsystems.
Agents within the complex economy are embedded within many overlapping networks, social, cultural, technological, financial etc. How an organization or individual succeeds or fails within this economy is largely a product of these different many interacting variables across different networks and the makeup of those networks.
From this perspective, there is no such thing really as efficient markets that allocate resources in an optimal fashion. This whole idea is only really relevant when we are thinking about agents in isolation, agents as price takers in a pure market, where they face an impersonal price structure and they are computing their rational choices.
From the complexity perspective, people are interconnected they are embedded within networks of production and consumption. Resources flow through these networks, and how those resources get distributed out depends on the structure of the network and where you lie in the network. There doesn’t have to be any equilibrium here. The distribution of resources across the network can be hugely heterogeneous and may remain in a non-equilibrium state indefinitely.

Development
Complexity economics sees the economy as a complex adaptive system that evolves over time. In standard economic theory, there is no mechanism for creating novelty or qualitative change within the economy. In the complex economy, the evolutionary process of diversification, selection, and amplification provides the system with novelty and is responsible for the growth in order and complexity over time.

Eric Beinhocker in his book The Origin of Wealth describes this process as “an evolutionary search mechanism. Markets provide incentives for the deductive-tinkering process of differentiation. They then critically provide a fitness function and selection process that represents the broad needs of the population... Finally, they provide a means of shifting resources toward fit modules and away from unfit ones, thus amplifying the fit modules’ influence.”
Complexity economics focuses on the non-equilibrium processes that transform the economy from within, such as technological innovation and new business models created by entrepreneurs that lead to a process of creative destruction, within an economy that is constantly changing as it grows in a somewhat organic fashion. Changes in one part lead to new opportunities and niches within another as the whole thing co-evolves with different industries and sectors becoming interdependent and self-organizing. Out of this process of evolution, we get what we might call economic growth, not so much in our traditional sense of an increase in the gross throughput to the system but more in terms of its qualitative structural transformation in becoming both more differentiated and integrated to exhibit greater complexity.

Economic Agents
Overview
Humans are inherently complex creatures, and of all the areas of economics no part can be more difficult than deriving a model for how people make choices and act within an economic context. And it is the modelling of economics agents that the limitation of our existing economic framework become most apparent.
Agents are so called because they have agency, which means a thing or person that acts to produce a particular result. The basic premise of economics is that people have some conception of what they value. They will try to be efficient in the expenditure of their resources in order to achieve these valued ends, what is called economizing, and they will respond to external interventions called incentives in order to try and achieve these ends. These agents in the course of doing the activity of economizing will have to make choices. Thus a full and coherent microeconomic theory will need some account to all of these things. That is to say, what do people value, how do they make decisions, act on those decisions and how do they respond to incentives.
Ideas about people acting rationally that were first put forwards as conjectures got mathematics during the twentieth century into highly abstract models of human behaviour that today form the basis of microeconomics. But the disconnect between the foundational assumptions of the rational agent and how people really act in an economic context are becoming ever more apparent to use as reality once again bites back. As people increasingly reject the model of the rational agent this is once again opening up the debate as to how to model people within an economic context. The area today is rife with new experiments and new research as an area of economic science that became highly removed from other domains of social science begins receive a flood of attention from many other areas of the havioral science, such as neuroscience, psychology and evolutionary psychology. In this new research we are starting to see emerge an alternative concept of the how people make decisions and act, a model that are empirical and data driven in their origins, leaving the theory aside and starting once again by looking at how people really act. Out of this new behavioural approach a new model is emerging, one that is greatly more complex in that it incorporates context, it includes heterogeneity, it includes a diversity of psychological motives, it includes interdependency and most of all it includes context, everything that had been removed from the previous set of model is now flooding back in to try and give us a richer model to human economic decision making and choice.
In this section, we will be exploring two different models given to capture this. We will talk about how standard economics offers this model of the rational individual sometimes called homo economicus, and we will draw upon the new area of behavioral economics which presents an alternative model to human behavior within an economic context.

Human Condition
Economics, on its most fundamental level, can be understood as the study of a certain dimension to the human condition. One of the most fundamental things we can say about the human condition is that humans value things, and we are motivated to strive for the things we value. Equally, we can note that we do not strive for the things we do not value. This process wherein we try to achieve the things we value is all pervasive in the human experience. We get up and go to work because of the remuneration and satisfaction it brings, we cook a meal because of a desire to eat, we take exercise because we value our health, we talk with friends because we value their company etc.
In all these situations people are involved in a certain goal-oriented behavior. They are doing certain things in order to achieve other things that they value more highly. In all instances when humans do not exhibit goal-oriented behavior of some kind, economics has little to say about them. For example, we might think about meditation as a state of the human condition that involves "just being" in some sense. As such economics can be contrasted with such a condition of being which is not engaged in a process of attainment.
As Shakespeare might have said "to be or not to be" well economics deals with the human condition that is in the realm of "not being" in that it involved expending our current potential state of being towards achieving something that we value. This could be contrasted with many of the spiritual traditions such as Buddhism that explicitly try to renounce this endless pursuit of our desires and interests in replace of a state of being.
However, for the vast majority of humans and for the vast majority of the time we are endlessly engaged in this process of attainment, pursuing our valued ends through processes of investment, production, exchange and consumption of all kind. Economics can not be anything more than the study of this means-ends dimension to the human condition - it will never tell us about the ultimate meaning of reality or how to live at one with the universe - but equally, it should not be defined as anything less than this, in a narrow sense. Thus we should be careful as we elaborate the theory that fits within this overarching concept of the subject not to lose sight of it and restrict our analysis to something that is disconnected from this bigger picture.
Inherent in this mode of being wherein we operate to achieve a certain end is a logic that we try to increase the overall outcome at the most limited input. This difference between the input to a process and the output defines the efficiency of the system.
This is not to say that we always try to maximize a single parameter. Many actions take place under a complex set of motives within a constraining environment, and those different motives and factors work to constrain each other. Thus we may or may not wish to have a job wherein we do nothing and get paid a thousand dollars a day. This is because there are other social and cultural factors that are limiting how much we might like to earn. But just because we are not trying to maximize a single metric does not mean that we are not trying to improve the whole outcome. We are trying to improve our overall welfare or well-being - and potentially that of others and other things - that means optimizing across a number of different parameters, social, natural, financial, cultural etc.

Agency
In this process of striving for the things we value we affect our environment in specific ways to achieve our valued ends. We call an entity that takes an active role to produce a specific result an agent. Thus we use the term bleaching agent, which is a chemical that is specifically designed to act on other substances, such as a textile, in order to achieve the desired result of removing color from it.
Agency, in a social and economic context, means the capacity to make choices and to act independently on those choices to affect the state of the environment so as to achieve the things of value. Thus economic agents are abstract models of individuals or organizations which have this capacity for agency.
There are a number of important elements to agency. Firstly, there must be some value system. The system has to have some logic under which it processes information in its environment. The system has to have a means to effect its environment and be able to adapt and respond to changes within the environment.
A plant is an agent because it will actively strive to attain more light and nutrients. Its value system is based on what is called exergy. There is some logic built into the biomechanics of the plant that enables it to affect its state and adapt to its environment in order to move towards the light and nutrients that are required for it to grow and increase its exergy.
Likewise, a person cycling a bicycle is acting as an agent, their goal is to stay moving forwards on the bicycle and they use their brain in order to process information according to a certain logic that enables them to adapt to the environment in moving towards their goal. The same is true for a person at work, a criminal trying to steal cars, a business organization, a trader making investments, a government, they are all agents.

Value
In order to get agency we have to have some form of value system. The value system ultimately is what tells the agent which way is up and which way is down and thus forms the foundations for defining which direction the agent should go in. A value system is a hierarchy of values that all agents possess and may be demonstrated by their choices.
The first question we have to ask then is what do people value or how do they value things? Human beings are clearly complex creatures with a diverse set of values. We value many things, food to eat, water, safety, warmth, shelter, comfort, we value, friendship, self-esteem, social status, sense of community, independence, excitement, adventure, and the list goes on.
Human values and resulting motives have been studied most extensively in philosophy and psychology. Probably the most generalized and all-encompassing model we can draw from this is the hierarchy of needs, that brings these various needs and motives together into a generalized framework and parallels many other theories of human developmental psychology. This framework structures values and the corresponding complex set of needs that humans exhibit into a hierarchy that is believed to describe the pattern that ...more complex in nature. The most fundamental basic or primary human requirements are for physiological needs, which are the physical requirements for human survival. If these requirements are not met, the human body cannot function properly and will ultimately fail. Physiological needs are thought to be the most important. Thus people value such things as satisfy these needs first, such as food, water, security, which are basic requirements for all biological creatures. These are what are called "deficiency needs" they are thus called because deficiency needs are said to motivate people when they are unmet. Also, the need to fulfill such needs will become stronger the longer the duration they are denied. For example, the longer a person goes without food, the more hungry they will become. As such these primary needs define a world of scarcity as they exist in relation to a deficit. These primary values are objects that satiate that deficit.
Lower in the hierarchy are what we might call subjective needs. That is to say, they are needs that the individual - the subject - requires. They involve a direct relationship between the subject and the object of desire.

Higher level or secondary needs are needs for connection with something other than ourselves and our personal needs. Secondary values are associated with a connection to a broader social, cultural or natural environment. In a more concrete form they are the connections we have with other people and things, in the form of friendships, partnerships, community, culture, natural environment etc. and the value we get - for example in the form of self-esteem and belonging - from the role we play within these larger systems of organization.

Ultimately this desire to be part of something greater than ourselves and the value we derive from it leads to self-transcendence. "Transcendence refers to the very highest and most inclusive or holistic levels of human consciousness, behaving and relating, as ends rather than means, to oneself, to significant others, to human beings in general, to other species, to nature, and to the cosmos" - Abraham H. Maslow, Farther Reaches of Human Nature

As such we may say that secondary needs are motivated by objective values in that the value is derived from forming part of some objective system and the role we play within that. The value is not in a single thing but in the connections that we have with other things. This is in contrast to subjective values that derive from the attainment of some object that the subject desires to fulfill their specific needs.

People's values are not absolute, they exist in relation to the needs that have already been met. This model posits that people are motivated to achieve certain needs and that some needs take precedence over others. Our most basic need is for physical survival, and this will typically be the first thing that motivates our behavior. Once that level is fulfilled the next level up is what motivates us, and so on. In such a way our value system alters and adapts in response to our current state. This is as much true for the individual as for a whole society, the values of an advanced economy will be very different from those of a primary economy.
The human brain is a complex system and has parallel processes running at the same time. Thus many different motivations from various levels of the hierarchy can occur at the same time and interact to give a certain outcome. In striving for our desired ends we rarely take into account only one form of value but instead are typically making a tradeoff between different forms of value.

Motivations come with certain goals and objectives that organize one's thinking and there is an organizational principle to these motivational systems. Motivation organizes our thinking, perception and action tendencies. The human brain is not an empty vessel performing calculations in a vacuum like a computer, but instead, information is received and processed within a given emotional and motivational state that strongly conditions what information is received, how it is interpreted and how we act on that information.

Decisions
Agents have motivations that drive them to value things. In order for agents to pursue their valued ends, act and affect their environment towards achieving those outcomes they need some logic under which to do this. That is to say, they need to take in and process information according to rules so as to generate a response that will lead to their ultimate desired end. If we want to understand how economic agents behave we thus need to define, to some extent, how this is done.

There are fundamentally two foundations upon which actions are based. Our actions may derive from individual deliberative reasoning, and this would be called a rational action, or they may derive from some other non-deliberative source, such as instinct and emotion, heuristic or social cues etc.

Rational means designed or conducted according to reason. Reasoning is a process whereby data is amassed, processed according to some logic in order to produce a conclusion that is both logically consistent and in accordance with objective data.

Thus a rational decision is one where an agent amasses all relevant information, processes it according to a consistent and objective logic and then acts in accordance with the outcome of that process. In so doing the agent acts independently, they act on their own internal logic in an autonomous fashion.

Thus for a decision to be rational, there are a number of requirements, firstly that the agent has all the relevant information and that any information that is not fully known can have a probability distribution assigned to it.
Secondly, the agent must act according to a consistent and objective logic set, which means that the choices made will not change unless there is some alteration to the objective factors determining the decision.

Agents have to have a fixed set of preferences and these preferences have to be complete - the person can always say which of two alternatives they consider preferable or that neither is preferred to the other. An actor is acting rationally when they take account of available information, probabilities of events, and potential costs and benefits in determining preferences, and act consistently in choosing the self-determined best choice of action.

Although the term rationality simply means according to reason, the requirements for achieving this are only met in some circumstances or some of the time. Rationality requires that we have intelligent calculating agents operating in simple environments. In such circumstances, it is reasonable to say that people often act rationally in pursuing the things they value. However, just as often we will be dealing with contexts wherein agents with limited intelligence and propensity for reasoning will find themselves in relatively complex environments. In such circumstances, agents do not use reason to determine their actions but use a variety of alternative means, that are contingent upon the social, physical or cultural context within which the decisions are being made. That is to say, that the rationality of an agent is bounded when it reaches a limit it switches to alternative means for making decisions. This limit is both contingent on the particular subject - there propensity to use reason - and the environment - how complex the environment is.
Much of the time people operate in environments where there is incomplete information, radical uncertainty may exist, where they do not wish to expend the energy and time to reason through their actions, we don't want to take the responsibility of our actions, there are time limitations, social power dynamics or a series of other limiting factors involved. In such circumstances we defer our decisions to heuristics, which are shortcuts, we use social and cultural norms, we copy what others do, we allow random events to determine our decisions.

In order to make choices, agents need some set of rules under which to make their choices. This set of instructions or rules can be based on some simple linear cause and effect model, what may be called an algorithm, or they may be much more complex models, what may be called a schema. With this capacity of agency comes autonomy. In their choices and actions, agents define themselves as independent from other things and thus define their own identity with associated responsibility for their actions.

Choice
The decisions we make feed through to the choices we make and ensuing actions with associated consequences. In the act of performing this process of striving for the things we value we have to inevitably expend resources. As many economists try to derive all economic phenomena from micro foundations, the theory of choice can be seen to play a key part in the whole enterprise. The two primary interpretations for this are rational choice theory and what might be called behavioral choice theory.

With rational choice theory, choices are seen to be made rationally, preferences are seen to be fixed and externally given. In such a model choices are seen to be an optimization process over a given set of well-defined preferences that can be all directly compared according to some common criteria called utility - in its more concrete form this is typically money.

The assumption of rational choice theory is that an individual's behavior is directed by the primary motive of maximizing self-interest based on personal preference. Rational choice theory is able to show with detail how an individual can act rationally according to their own preferences, it says little about where individual preference come from and how they may change over time. With rational choice theory, preferences are provided exogenously but there is no explanation of how they are formed.

Choices are seen to be made in an isolated context where each agent faces an impersonal set of fixed options and then makes their choices independently from others. When we do not need to take into account differences in people's motives, and context we can often define one single representative "normal" actor that accounts for a whole population of agents.

**Adaptive Choices**
In contrast, a behavioral model would see choices not as being fixed and hardwired but as adaptive, depending on context. Here fixed preferences are replaced with motivation. Whereas preferences in the rational choice model are seen to be fixed and exogenously given - like you are born with them - motivation is context dependent as preference changes depend on which motivational systems are activated within a given context.
Motives come first and these motives then define the value of things, thus value can be seen to be more dynamic.
Choices are not fixed but instead agents are continuously adapting their expectations based upon current and previous information they receive in order to adjust their expectations about the future.
One example of adaptive choice would be individual reinforcement, in which agents reinforce choice probabilities based on their prior choices. Another example would be social reinforcement, where an agent reinforces their choice probabilities based on the choices of other agents in similar decision environments.
In such circumstances where context comes to play a part in the choice making process it is required that we look at the network of connections that the agent is embedded within, social, cultural, environmental etc. both in time and space and also look at the nature of those connections i.e. are they reinforcing or dampening each other out.
Unlike the rational model to choice theory that leads to a much simpler model - because agents are making similar choices in isolation leading to stable outcomes - this model takes us into the world of complexity in that it requires modeling choices as heterogeneous, interconnected and leading to unstable or non-equilibrium outcomes.

**Incentives**
Finally, these agents in the course of doing the activity of economizing will have to make choices and they may respond to external interventions called incentives in order to try and achieve these ends and this is another important consideration both in microeconomics and management. A basic premise of economics is that people respond to incentives. The fact that people are trying to achieve some end through efficient methods, means that if we change either the context or the ends they will change their behavior.
Because in the rational choice model the choices actors make is seen to be defined by an optimization calculation - taken in isolation in relation to some fixed set of preferences - it is seen that if we change the values to the parameters involved in the calculation we can change the choices made. That is to say that the standard model to incentives focuses on altering the ends that are given to agents in order to alter their motives. These payoffs are called positive incentives , where the positive-incentive value is the anticipated pleasure involved in the performance of a particular behavior, such as eating a particular food or drinking a particular beverage.

The theory of incentives is one of the major theories of motivation and suggests that behavior is motivated by a desire for reinforcement or incentives. Thus, in contrast with other theories that might suggest we are motivated into our choices by internal drives, incentive theory instead suggests that we are pulled into action by outside incentives. According to this view, people are pulled toward behaviors that offer positive incentives and pushed away from behaviors associated with negative incentives. In other words, differences in choices from one person to another or from one situation to another can be traced back to the incentives available and the value a person places on those incentives.

The management paradigm that follows naturally from this insight is that if we change the payoffs to the agents then we can alter their choices and design the organization towards achieving what management see as the desired results.

"The basic idea of human motivation is that we think about people like rats, people don't like to work, if we were left to our own accord we would be on a beach somewhere sipping mojitos and the only reason we work is to get money so that we can sit on the beach drinking mojitos. But the basic motivation is to enjoy leisure and not work and everything else is a distraction from it so that we can do that. It is a fine model, but you should ask yourself is this really what gets us to act and do things" - Dan Ariely, Predictably Irrational

When we incorporate the idea of context into how people make choices then incentive theory can change from one that is solely focused on the explicit payoffs, to focusing more on the network of connections within which they make choices and act and how altering this set of connections can, in fact, alter how agents make their choices.

Behavioral economics is currently exploring an alternative model to incentives that looks at the broader context within which agents are making choices, this can be the physical environment, the social environment or cultural context. One example of this is advertising, where advertising functions by creating a cultural or psychological context around a product that works to alter the agent's perception of it and thus alter their behavior towards purchasing the product. Of course, advertising as a means of affecting people's behavior has long since been known to business management but it remains excluded from our standard choice model.

Already new terms and even new professions have built up around the behavioral approach to incentives, such as choice architecture and nudge theory. Where choice architecture is using this basic premise that context matters to incentives and then designing the physical, social or cultural context within which choices are made to achieve the desired results.

For example, the use of a default choice is one method through which choices can be influenced based on psychological factors that would not affect the choice if people were, in fact, making reasoned decisions. It has long since been shown that typically consumers are more likely to choose options that are presented as a default - where default is the preselected option that individuals must take active steps to select another option, for example signing someone up for a newsletter as the default option when they register with an organization. Likewise, the physical context can be used to alter choices, such as having open offices where the physical office space is specifically designed to enable interaction between members.
All of these illustrate that people are not simply considering the end payoff but are instead also affected by the set of connections within which they find themselves making the choices and by altering those connections it is possible to alter the behavior.

**Bounded Rationality**

In this section, we will be giving a short overview of the ideas of rationality and bounded rationality as they apply to the decision making of economic agents. We firstly look at the standard model of the rational agent where value is defined subjectively in terms of utility; where agents have well-defined unchanging preferences, perfect information and choice making is seen as an optimization process. We go on to look at the contrasting model of bounded rationality where agents may have a diversity of motives; where they exist in a complex world, always embedded within space and time with limited information and cognitive capabilities, often facing radical uncertainty; wherein their choices are more a product of how they are contextualized and framed, both physically, socially and culturally as they imitate others, use heuristic shortcuts or create narratives to aid them in their decision-making process.

In many ways, the divide between standard economic models of the rational agent and behavioral economics models of bounded rationality is a divide within economic science between theory and empirical data. On the micro level, standard economic theory has never really been subjected to empirical data. Models derived from classical physics got mathematized during the 20th century into very quantitative abstract and theoretical representations of human behavior with limited reference to empirical data. The emphasis was on formalizing equation-based models. Empirical data was seen as somewhat redundant.

Over the past few decades, researchers in neuroscience, psychology and new areas of economics have started to conduct experiments and it has turned out that the data coming from these experiments does not fit very well with the standard models. In order to try and describe what is coming out of the data, behavioral economics has grown as an alternative approach pursuing more experimental, data-driven methods, without reference to the more traditional models, and some very interesting insights have come out of this. Complexity theory is very well suited to supporting this new approach to microeconomics as much of this empirical phenomena can be best understood with reference to nonlinear models.

**Agents**
Economic agents are people or organizations taken within an economic context that have agency, which means a thing or person that acts to produce a particular result. The basic premise of economics is that people have some conception of what they value. They will try to be efficient in the expenditure of their resources in order to achieve these valued ends, what is called economizing. These agents in the course of doing the activity of economizing will have to make choices and they will respond to external interventions called incentives in order to try and achieve these ends.
A central question we are interested in then is how do people go about trying to achieve their valued ends? How do people make choices in the allocation of their resources towards achieving their desired ends? Under what set of rule do agents get from where they are now to where they want to be, is a central question of microeconomics?
In this discussion surrounding the model of the rational agent, we can divide the ways in which people act and make choices, into those that are based upon deliberative reasoning and those that are not, instead deriving from some form of reflex.

Deliberative reasoning means that the individual amasses all relevant information, reasons through it according to some consistent and objective logic and then acts according to this set of instructions. In so doing the agent acts in what we call a rational fashion in that their actions are in accordance with reason. Rational actions though have a number of requirements that must be met. The agent must have the required information, they must perform the act of processing that information according to some logical set of rules and they must act according to the outcome of that process.

In contrast, agents may act based not on deliberative reason but instead on reflex. Reflex is an automatic response to a stimulus that does not receive or need conscious thought. Reflexes are thus non-rational in that they do not involve the considered deliberation of the individual; they are instead determined by the environment and the learned adaptive reflex. Unlike rational actions reflex actions have limited requirements, they are simply actions in response to a stimulus from the environment, they do not require full information about the environment or future. They do not require deliberation or the accordance of one's actions to any reason given. These reflexes can be seen to derive from emotions and heuristics; evolved emotions and rules that are designed to make quick decisions without deliberation.

**Rational Agents**

Standard microeconomics is based on a model of the so-called “rational agent.” The agents have unlimited rationality, the idea of omnipotence, that is to say, they know everything, and can compute all the consequences. Within this model, agents have perfect information and any uncertainty can be reduced to a probability distribution. The agent’s behavior then will be an optimization algorithm over their set of possibilities, and it is thought that behavior can be altered by changing the input variables to this optimization algorithm, by what we call positive incentives.

The rational model to agents sees choice as an optimization algorithm over a set of well-defined options. Standard economics uses a subjective theory of value. This concept of value is derived from the revealed preferences of agents. Standard economic agents have clear preferences. This preference reveals their values. In choosing one thing over another, the utility of that will be revealed to the economist. Because agents are considered to be acting rationally we will get consistent choice. If you choose one thing over another now, then you should always choose that thing over the other independent from other factors that are exogenous to this equation. When making choices, agents are seen to be simply computing the results to an equation and choosing the maximum payoff.

**Perfect Information**
Part of the rational agent model is the idea of complete or perfect information, that is to say, agents have complete information of costs and payoffs to all options that are available and they are able to compute all of these payoffs. Of course, everyone recognizes that only very simple situations will have explicit values associated with all options. In many situations, the values associated with costs and payoffs are not explicit. They are contingent on other events and how things play out over time. In such a case, the rational model uses probability and statistics to ascribe a well-defined value to these unknown variables. An assumption built into this is that we can take a sample from the past and project it onto the future. It is an assumption that the past and the future on aggregate are fundamentally the same. Another assumption here is that the actions of an individual agent are on aggregate the same as the average of the entire population. These assumptions only really hold within closed linear systems without positive feedback or emergent features.

**Infinite Cognition**
Some choices, such as choosing which song to purchase on iTunes may involve millions of different options, and also many choices that agents face are dynamic, meaning they will unfold over time. The choices we make now will affect the choices we make tomorrow and so on, as the possibilities branch out into the future. Because this is a tree graph, the number of options and associated payoffs typically grows exponentially. The net result is that we will a need massive amounts of computing power if we want to try and calculate closed form solutions for many real world choices. The rational model ascribes this computational capability to agents - not because anyone really believes that this is how people really are – but instead because it is necessary to get these closed form solutions. Within this model the human’s cognitive functioning is seen to be very much comparative to that of a computer, simply running logically consistent optimization algorithms over a well-defined database of options, with systematic logical inconsistencies thought to be impossible.

**Complete Knowledge**
The standard model sees the world as fundamentally knowable. This is the Newtonian paradigm of what is called the "Clockwork Universe" where the universe is seen to be a big machine, like a big clock with lots of cogs turning as time moves forwards. The whole thing is predetermined and time is theoretically reversible. Theoretically, we could simply turn these cogs backwards. Thus, the future and the past are determined and because of that, they are knowable. It is simply a question of figuring out how it all works and then doing lots of calculation to compute it all. Within this paradigm, the idea of uncertainty is treated as a function of incomplete information about a well-defined objectively knowable past, present or future state.

**Limitations**

The rational model of agent behavior is an analytical framework. Analytical methods of reasoning are specifically designed to focus on the internal workings of a system. They do not and cannot model the system in relation to its environment. Thus, any analytical modeling framework will try to model agents’ decision-making as a closed formula. Meaning the model will contain agents who have a fixed set of well-defined preferences, rationality and complete information with which to make autonomous decisions independent from any context. This is the idea of deliberative decision-making and if a closed form solution is the objective, these agents are going to have to have perfect information.

The standard model is based upon this idea of complete information, but it only really works in simple environments where there is a finite amount of choices and the agents are making choices independently. But these properties do not always hold. In more complex environments, there may be a very large number of options. Agents’ choices may become interdependent and due to nonlinearity and feedback a risk-based analysis of the future may break down. In such cases, we will not be able to use a model based upon perfect information and will need to replace this with an alternative, what is called bounded rationality. This fundamental limitation means that agents cannot make decisions based purely on the rational analysis of objective information. Behavioral economics presents a number of methods to how agents operate when rational choice breaks down. By imitating others, by using heuristics and narratives. All of which are social, cultural, or environmental contexts that enable people to make choices in a world where their capacity for rational decision-making is limited.

Behavioral economics gives us some very different answers to these questions by allowing for more social, cultural and environmental factors. Value will become a more complex multi-dimensional thing with agents often making trade-offs between different types of value and never fully sure about the value of things or their preference. From this perspective people’s rationality is bounded, meaning they can only think so much. They always exist within a context of space and time and are strongly limited by that particular context. You can only spend so much time thinking about which cookies you want to buy in the supermarket. You don’t have your whole life to do it and you don’t have a supercomputer to help you process the prices of all the other cookies available on the market and their expected utility. Information is often incomplete and radical uncertainty may exist in outcomes. Due to all of this agents will use all sorts of heuristics and shortcuts in order to make decisions on incomplete information with limited cognitive capabilities. From this alternative vision of behavioral economics, we get a very different answer as to how to design and build incentive systems, one that is less focused on altering the payoffs to individuals and more focused on altering the context within which agents are making their decisions.

**Bounded Rationality**

Herbert Simon created the term bounded rationality and talked about it as such: “The term bounded rationality is in my mind largely intended as a warning to economists that you cannot predict human behavior by setting up an abstract model of what is rational and inferring the behavior from that; that you have to know a tremendous amount about what is inside that person’s head and what methods they use for calculation; that those are empirical questions that are not to be settled by sitting in an armchair. Bounded rationality... is (rather) a strong demand that like any other empirical science that proposes to explain the world, we go out and observe the world.”

Bounded rationality is essentially the idea that agents cannot know and compute all information about the options available to them, and faced with such incomplete information they use all sorts of shortcuts in order to cope. Central to this idea of bounded rationality is the concept of radical uncertainty.

**Radical Uncertainty**
The idea of perfect information and that the future is potentially fully knowable only really holds within linear systems. In nonlinear systems, it will break down. This was first made explicit in physics by the findings of chaos theory. The idea of the clockwork universe was central to the Newtonian paradigm that supported classical physics for many centuries. But in the mid- 1900’s it became called into question by a number of experiments. And by the 70’s and 80’s, it became accepted within physics that it was not applicable to nonlinear systems as chaos theory came to describe. Chaos theory, on a very high level, showed us that the dynamics of a nonlinear system emerge out of the nonlinear interactions between the parts during the system’s process of development. This is part of what we mean by the term sensitivity to initial conditions. An indiscernible small change to the input value to a system can lead to a very large change in the output variable at a later stage due to these compounded feedback loops allowing for small changes to grow exponentially and this gives us the butterfly effect.

The net result of this is that our capacity to predict the future state to a nonlinear system is very limited. In terms of the capacity to make numerical calculations, it falls off exponentially, which means you are going to have to stay putting in more and more information just to get a smaller and smaller increase in your horizon of prediction. Nonlinear systems go through phase transitions. These phase transitions are structural transformations, meaning a sample from the system’s state space prior to the phase transition and after will not be comparable. This means it is highly unlikely that there will be some closed form function that maps between the two state spaces. These phase transitions create path dependence - meaning time is essentially irreversible. Nonlinear systems also have non-normal distributions, meaning events that are statistically virtually impossible within linear systems can happen, what are called black swan events. All of this represents the theoretical underpinning to the idea within economics of radical uncertainty, also called Knightian uncertainty, which is a risk that is immeasurable; not possible to calculate. With this ontological uncertainty, the future is not yet created. We simply can not predict what entities will exist and how they will interact.

**Complex Environments**
When we start to allow for this concept of bounded rationality, the first consequence is to start to ask: How do people make decisions without the aid of complete information and rationality, or at least when these two things are limited? In complex open environments where the future is unknown, where there are too many choices and our capacity to process them is limited, we can no longer simply depend upon our own independent rational capabilities to make decisions. In such circumstances, people resort to the aid of context. This might be a social context where they simply imitate what other people are doing, or they might use a cultural context using heuristic shortcuts, or create narratives that enable them to form decisions, or they may even use their physical environment as another context through which to interpret an uncertain situation.

Imitation is probably the most common shortcut we use when faced with uncertainty. We simply copy whatever other people are doing. For example, this may take the form of herd mentality, which describes how people are influenced by their peers to adopt certain behaviors. This phenomenon will create a nonlinear dynamic, meaning the actions of agents are not independent, where they would cancel each other out and we would get an average. But in fact, in this situation they are interdependent, meaning they will not cancel each other out. The variables will all move in the same direction. Out of this nonlinear dynamic, we will get emergent phenomenon such as stock market bubbles which cannot be accounted for using our linear models, that simply aggregate over isolated rational agents.

**Heuristics**
Where trying to find an optimal solution through logical reasoning is impossible or impractical, heuristic methods are often used to speed up the process of finding a satisfactory solution. Heuristics can be mental shortcuts that ease the cognitive load of making a decision. Examples of this method include using a rule of thumb, an educated guess, an intuitive judgment, stereotyping, profiling, or just plain common sense.

All of these are derived from the very simple schema that agents have developed through an evolutionary process, which can be modeled using Bayesian inference. We use these heuristics because they have worked in the past. Things considered common sense are with us because they have stood the test of time. We don’t need a Ph.D. in theoretical physics to tell us that things fall downwards towards the ground. It is common sense because we have seen it millions of times. And this forms the foundation to our assumption that it will happen next time because it has been validated so many times we are not about to let go of it. And even though we might not understand the theory of gravity, we will still use this assumption to help us reason about future events, simply because it has stood the test of time and worked in the past. People in the real world aren’t computers. Not everything they know has to be supported by logic. Many of the tools that we use to interpret our world and make decisions have just evolved as a survival strategy. Actually rationally reasoning about something takes time and energy, which many people would prefer to avoid unless necessary.

**Narrative**
In more complex environments where we face novel circumstances under uncertainty, we may use cultural, psychological contextualization - what we call narratives or stories that express emotions. When we create these narratives about the world and how a future course of events will play out, we are really just creating a string of ideas that express our different emotions about that situation. Through them, we express our hopes and fears. This allows us to contextualize the situation and gives some kind of basis and confidence to make decisions. This narrative allows us to act and make choices in the face of complete uncertainty while maintaining some sense of reason. But narratives don’t always exist in isolation. They can also be socially constructed, shared and supported by a group of people.

With narratives, we get the idea that people can, in fact, have different conceptions of the world. The rational expectation hypothesis assumes that there is only one way to think about the future and all agents have adopted this model. And thus, the outcome is simply a product of the information inputted. But with narrative, the outcome might, in fact, be a product of the interplay between different narratives, in the way that different organizations or different media channels might promote different discourses and interpretations of events, influencing different people’s opinions. This is an example of why we need to use complex models to represent economic phenomena because events in the real economy play out as a product of the interaction between many different networks.

**New Models**
Finally, we will discuss a bit the context surrounding this current debate between the rational model and the behavioral model. Until recently, it was very difficult to mathematically model systems that have many components with each of those components having many degrees of freedom, what we call a complex system. All we really had was things like differential equations, vector fields and basic statistics and probability. These tools were designed for computing the trajectory of planets around the sun or fluid dynamics. They weren’t really designed for this application. Thus, our economic models were always trying to accommodate this lack of basic tools. Many standard economic models to the behavior of agents look austere with simplified assumptions. This is because they are trying to encode complex phenomena into traditional tools that require many simplifying assumptions.

Today, we have new tools based on computation such as agent-based modeling and nonlinear iterative maps. These computational models can handle massive amounts of information. From them, we can get much richer models that don’t require these very simplified reductive assumptions of standard economics. They will allow us to paint a much more complex and subtle picture to the values, motives and real world behavior of agents.
Traditional models dealt with very generalized aggregations. Due to lack of information, they could not say what people were actually thinking or doing. With the availability of a mass of new data sources from social networks and the internet that we now have access to, we can get much more personalized models specific to each individual, possibly even in different unique situations, again enabling new models that are not so dependent upon very austere abstractions of generalized behavior. Part of the problem today is that relatively few people understand the nonlinear models and computational methods that are required to support this new approach. Thus people stay coming back to this ‘either or’ situation where either we use formal models that are known to be limited but are tractable or accept the data and lose the traction when in fact, we increasingly have the computational models and methods to formalize this data.

**Conclusion**
If agents are in a relatively simple environment where there is limited uncertainty and they can gather and process all the information required to make a choice, then the rational choice theory will work well. But rational expectation is based upon the assumption that the information agents need is in fact knowable. People are basing their decisions on information about their environment and the future state of that environment. This model is assuming that the information about the future is, in fact, knowable, and as we have discussed this assumption will only hold if all of this is playing out in a closed linear system. It also assumes that people are making choices independently, that in the absence of getting all this information to process it all, their inaccurate choices will be randomly selected.

This whole model is clearly dependent upon additivity, meaning that the system we are modeling is going to have to be linear or else we are going to have problems. If the agent is in a complex open environment making choices about the future where that future is fundamentally unknowable; where information is inaccessible or there is too much information to process, then the model of rational choice is limited. In such circumstance, agents’ decision-making becomes dependent upon the context they find themselves in, mimicking other people in using local reference points and heuristics, or they may create their own context through the formation of narrative in order to interpret events and give a basis to their actions.

Value Theory

Value theory lies at the heart of economics. Behind every production process, every exchange of goods, every purchase, every choice agents make, is the concept of value - value is the essence of economics. Thus any coherent overall economic paradigm is going to need a formulation of economic value and how we define value will be of critical importance in the formation of any economic paradigm. A reconception of economic value will lie at the heart of any reformulation of standard economic theory. In this section, we discuss the basics of economic value by looking at the two primary approaches to its formation; that of the subjectivist theory of value and that of the objectivist theory of value. We will try to answer the question as to the foundations upon which each bases its derivation of value. We will then go on to analyze the advantages and disadvantages of both approaches before drawing conclusions about the potential for advancing our current formulation of economic value theory beyond its existing limitations.

Value

Economics, in its most abstract sense, may be understood as the study of the relationship between human means and ends. That is to say how people use efficient means to achieve their valued ends. As L. Robbins defined it "economics is the science which studies human behavior as a relationship between ends and scarce means which have alternative uses"

As economics is about how we allocate our valued resources - in production, exchange or investment - in order to achieve more of whatever it is we value - whether this is for the individual or for whole societies - this concept of value is all pervasive within economic activity. Behind every aspect of economics and economic activity will be the idea of value in some form. People do things, and thus involve themselves in economic activity because they wish to attain the things they value, where we are using the term value in a very generalized sense. Thus any effective economic paradigm is going to have to have a coherent understanding of what is meant by this term value.

Instrumental and Intrinsic Value

More broadly the concept of value is a very fundamental concept within the social sciences and is of major philosophical importance. As such any formulation of economic value will exist in relation to a broader philosophical discussion about the nature of value. Thus it is important to have at least a general understanding of this more general conception of human value.

In philosophy, a basic distinction is often made between what are called intrinsic value and instrumental value. The concept of intrinsic value can be defined as what is valuable for its own sake, as an end in itself. By contrast, instrumental value can be defined primarily as what is valuable as a means to achieving some desired end. Something is considered to have intrinsic value when we value it in some way for its own sake. These are things that are pursued for their own sake, not to acquire something else. Things like happiness, truth, and beauty are often considered intrinsically valuable. You don't need a reason to pursue truth; the fact that truth is good in itself is enough.

**Spectrum**
In order to turn a philosophical debate - where we are talking about the absolute nature of reality - into a practical economic discussion - where we are talking about human means and ends - we can define the distinction between intrinsic and instrumental value as existing on a spectrum.
Identifying something as having purely intrinsic value or as having purely instrumental value would seem rare, most of us identify most things has having some of both as existing on a spectrum between the two. We don't take a hammer and smash up our cup because, firstly we might like to drink out of it in the future - instrumental value - but also we would feel that callously destroying a cup for no reason is a waste, and this comes from the fact that we think that the cup has some inherent value irrespective of whether we want to use it or not. Likewise, we might think of friendship as being intrinsically valuable but friendships also involve elements of instrumental value.
In the same way that pure altruism or pure egoism may be seen to be virtually impossible, pure intrinsic or pure extrinsic evaluation may be purely theoretical when in practice elements within value systems exist on some spectrum between the two.
When we go to the instrumental value end of the spectrum we are talking about the value that something has in its capacity to enable us to achieve some desired end. When we go to the intrinsic value end of the spectrum we are talking about the value that something has in its relation to a whole system or environment that is independent of our immediate requirements. On this more practical level, we of things like community or truth not for the immediate utility but because they are necessary to maintain the whole social or cultural context.
The distinction is between those things that have immediate utility in satisfying some desire or goal that we have, and thus we ascribe utility to them, and those things that do not have immediate value in fulfilling some goal we have, but we recognize their value as part of some larger system of organization. Such a system, like the environment as a whole, or society as a whole does not have an immediate need in fulfilling our current goal but it is still required to support it in the long run.

**Economic Value**
This more philosophical discussion surrounding value feeds into the formation of value within economics through the concepts of subjective and objective value, that have developed over the course of centuries of discourse within economics. A full discussion of the subtleties of this history is beyond the scope of this paper. But the history of economic theory is full of struggles to establish the meaning of value; what is it and how it can be measured. This goes all the way back to Aristotle first distinguishing between value in use and value in exchange and follows a long history of economic thought through Classical economics, Marxism, the Marginalist Revolution and Neoclassical thought.
The essence of this discourse is the long since noted fact that the value of some economic good can be formulated in terms of the resources that are required to produce it, or in terms of its utility with respect to some economic agent, and this two different derivation certainly don't always correspond to the same outcome; quite the contrary in fact. This subjective theory of value is where value comes from its utility to some economic agent clearly corresponds to instrumental value. The value of something is relative to people perceiving it as of utility in achieving their valued ends. Inversely the objectivist view of value is based more on the intrinsic conception of value, in that value is deemed to exist independent of people's subjective evaluation of it. In this paradigm, the value of an economic good is not seen to exist in its capacity to fulfill a human desire but instead it is derived from the resources that were required to produce it.
The classical economists searched for a conception of value in an absolute objective sense seeking a standard physical commodity unit for measuring exchange value. This derivation of value ran into difficulties that were made most explicit in the so-called diamond–water paradox. The paradox observed that while water has infinite or indefinite value, being necessary for life, its exchange value is low; yet unessential diamonds, being of little use in the support of life forms, had a very high exchange value. Added to this one might come across a diamond one day walking along the beach, thus creating a huge amount of economic value without any work input. The classical economists, such as Smith and Ricardo, could not resolve this paradox using their labor theories of value. It was resolved only by recognizing the importance of utility and scarcity in determining exchange values, and the role of margins in value determination. While the classical theorists sought a standard physical commodity unit for measuring exchange value, neoclassical theorists did not need such a commodity. The Marginalist Revolutions set the stage for the subjectivist theory of value that has become dominant ever since and forms the default conception of economic value that we inherit today.

**Subjective Value**
The foundations for defining an economic good and value within the subjectivist framework were laid down by Carl Menger. Menger stipulated a number of prerequisites to defining an entity as an economic good and thus having value within the economic system. A good - in the general sense - is something that is in a causal relationship with human welfare. However, within the subjectivist theory of value, a good has to satisfy a number of conditions before it becomes an economic good and thus has economic value.
Firstly an economic good must satisfy some human need, desire or want. A grain of sand at the bottom of the ocean is not considered an economic good because no one requires it to fulfill some need or desire that they have. Secondly, it must be clear to the actors that the good is the cause or means of achieving the desired end. Thirdly the good must be controllable by some economic actor and in that control it can be owned by some agent. Thus the galaxy is not considered an economic good because it can not be controlled or owned by humans as yet. Thus private property lies at the heart of this conception of value. Fourth, the good must be scarce. There must be a relationship between needs and available supplies, such that needs are greater than supply; there is always more demand than supply of the good.
Subjective value is a relation it is not something that is inherent in a good. It is a relationship in which some economic good stands in relation to some other economic good and relative to some person that has to choose between them. The cause of subjective value is always a choice made by human beings, that is the most fundamental thing we can say about subjective value. Value reflects the choices that we make as such it is fundamentally anthropocentric in nature. Value is thus a result of the expressed tastes and preferences of persons, and the limited means with which objects can be pursued. As a result, the scarcer the object of desire is, the greater its value will be on the margin.

**Utility**
While value is an abstract concept, the actual measurement of value requires some objective measure of the degree to which the thing improves pleasure, well-being, and happiness. In order to ascribe a ranking metric to the value of something the subjectivist use the idea of demonstrated preference. Meaning the utility of something is revealed in the demonstrated choices that people make in choosing one thing over another. When I choose an apple over an orange I am revealing that I value the apple more than the orange.
The theory of extrinsic value posits that value cannot be measured or observed directly. So instead, economists devised a way to infer underlying relative utilities from observed choice, called 'revealed preferences.' The economist Alfred Marshall put it like this: “Utility is taken to be correlative to desire or want. It has been already argued that desires cannot be measured directly, but only indirectly, by the outward phenomena to which they give rise, and that in those cases with which economics is chiefly concerned, the measure is found in the price which a person is willing to pay for the fulfillment or satisfaction of his desire.” As value was assumed to be determined by the utility on the margin, and consumers were assumed to allocate money optimally across their options, the marginal utility of money was the same for an individual in all its uses. Money thus became the standard unit of measure.
Exchanges between economic agents then come about because of differences in subjective evaluation. If one person exchanges an apple for an orange then the person must value the orange more than the apple, and inversely the person who they exchange with must value the apple more than the orange. Thus exchange of value takes place when there is an inverse ranking of goods under consideration by the agents involved in the exchange. The good must be appreciated by the buyer more than the seller and the seller must appreciate whatever it is they exchange the good for more than the good itself.

**Objective Value**
An intrinsic theory of value, also called the theory of objective value, is any theory of value in economics which holds that the value of an object, good or service, is intrinsic or contained in the item itself. In such a paradigm value is not seen to be contingent on any given subject's demand for it but instead is in the role that it plays within a broader system. Most such theories look to the process of producing an item, and the costs involved in that process, as a measure of the item's intrinsic value. As such they are looking at a good's value in terms of its interaction with a nexus of social, industrial and ecological systems.
The labour theory of value is one such example of an intrinsic theory that was originally proposed by Adam Smith and further developed by David Ricardo and Karl Marx. The labor theory of value propounds that the economic value of a good or service is determined by the total amount of socially necessary labor required to produce it, rather than by the use or pleasure its owner gets from it. In Adam Smith's Wealth of Nations he writes "The value of any commodity, ... to the person who possesses it, and who means not to use or consume it himself, but to exchange it for other commodities, is equal to the quantity of labor which it enables him to purchase or command. Labour, therefore, is the real measure of the exchangeable value of all commodities."
Another similar example of an objective theory of value would be that of the Physiocrats who based their theory of value in the land. The Physiocrats were a group of 18th-century French economists who believed that the wealth of nations was derived solely from the value of "land agriculture" and that agricultural products should thus be highly priced. This is in contrast to the earlier schools of thought called mercantilism. Whereas, the mercantilist school of economics said that value was created at the point of sale, by the seller exchanging his products for more money than the products had "previously" been worth, the physiocratic school of economics recognized labor and land as the primary sources of value. Thus we can see the interplay between subjectivist and objectivist theories of value go all the way back to the origins of modern economics.
A more recent example of an objectivist theory of value would be that of ecological economics. Ecological economists tend to believe that 'real wealth' derives from the value inherent in ecosystems, which can be best understood in terms of thermodynamics and free energy - what is called exergy. An energy theory of value posits that, at least at the global scale, free or available energy from the sun is the ‘primary’ input to the system. Labor, manufactured capital, and natural capital are ‘intermediate inputs’. Thus they are basing their theory of value on physical constraints and the laws of thermodynamics, something has value in its relation to other physical systems and the total supply of free energy. Which can be said to be an objective system independent of human evaluation, and thus an objective theory of the origins of value.

Objective theories of value base value on some objective organization. The value is derived from the resources it takes from that system in order to produce the item. So a tree has intrinsic value within the context of a forest ecosystem - in that removing that tree would degrade the functionality of the entire ecosystem - and this would be called natural capital. Friendship and family bonds have intrinsic value as part of a functioning society and this would be called social capital. These objective forms of value may or may not have immediate utility to someone, but they are typically required to maintain the overall functioning system, whether that is the ecosystem, society or culture. Things have an objective value in forming part of and maintaining processes within these broader systems.

Limitations

We will now try to make an assessment of some of the achievements and limitations of each formalization of value, starting with the subjectivist value theory.

The primary advantage of the subjectivist theory of value is firstly its simplicity and elegance. It is nice and clean, well formulated and consistent in many ways. The challenge of getting an objective price for some entity in a world full of people with different opinions on the value of things is not an easy one, but through the concept of utility, revealed preference and the interaction of utility functions, subjective value theory does a very elegant job of deriving a price metric for things. Subjective value theory works in many ways both on a theoretical level and on limitations as it defines much of the workings of our economies on a daily basis. As illustrated by the diamond–water paradox the subjective theory of value captures a central part of economic reality, the fact that people value things based on their own interests and that there is scarcity, are both clearly critical factors in determining the value of something.

However, after many decades of economic policy built on neoclassical conceptions of subjective value its limitations are also becoming apparent. The subjective theory of value results in a formulation of the economy as a closed system in that it does not account for anything that does not have immediate utility for an economic actor. This creates many problems because in reality economies are never closed systems that exist in a vacuum.

An economic system exists as part of a larger system, social, cultural and natural environment, it is embedded within these larger systems and every economic interaction involves some element of these. The economy is supported by a vast heritage of natural capital - such as clean water, sunlight, oxygen - which stays providing the conditions for the inflow of natural resources. Whereas in a previous age when these may have seen infinite, today it is becoming more apparent that they are finite and we are increasingly looking for means to quantify and integrate them into market decisions.

Likewise, an economy is embedded within and dependent upon a massive nexus of social and cultural institutions that are required for it to function effectively. More recently we are starting to recognize that institutions are critical to the functioning and success of economies - the ...comparison between North and South Korea being an often cited example of this. Equally, we are increasingly starting to look at organizations less as the machines of the Industrial Age but more as social entities. This value that is in social bonds that enable trust and frictionless exchange is called social capital and the economy benefits all day, every day, from huge complex networks of social capital that go unaccounted for.

The net result of using a subjective theory of value and thus defining the economy as a closed system is that it is then necessary to have a supporting framework of government institutions to account for intrinsic value that has been excluded, but is still required to support the system. A formulation of the economy as a closed system, when in reality it is, of course, an open system, inherently creates externalities - both positive and negative - that then have to be managed through alternative means, namely public institutions. This creates a strong dichotomy within the system and much friction between the two management framework that run on different principles. A full elaboration of the consequences of this would take us into a discussion on the free market, state, and globalization that is beyond the scope of this paper.

Likewise, a subjective theory of value inherently results in a focus on consumption, exchange, and finance, because these are what are really being measured and what gets measured gets managed. The result is an economic system that is focused on exchange. When we take this to its natural conclusion we get financialization, where we turn commodities into financial instruments and then create value by exchanging those instruments in a financial system that becomes divorced from any real economic activity.

Likewise, another result of subjective value theory is that we get metrics for value such as GDP, that simply tell us how much is being exchanged and consumed, without telling us anything about people's quality of life. So things like natural disasters that induce more production, exchange and consumption are ultimately recorded as beneficial when they are clearly detrimental to people's quality of life. This misalignment of what we are measuring and what people value has become more apparent in recent years and one of the criticisms leveled at standard economic theory.

**Objective Theory**
An objective theory of value puts forward an economic paradigm that is inherently open, in that it recognizes the value of other systems in relation to the economic sphere. In ascribing value to things in relation to a broader social or natural environment it identifies the economy as interacting with other systems and the inherent value of those other systems. As such, an objective theory of value would play a central role in any form of full cost economy, where all forms of value are accounted for. Thus in contrast to a subjective formulation of value that appears inherently unsustainable - in that it does not account for its supporting system - an objective value system could potentially be the foundations of a sustainable economy, one that recognizes and manages natural and social capital as endogenous factors, not exogenous factors for public services to manage.

In an age of globalization and sustainability when public management of natural and social capital is appearing limited, this has been already identified by many as a key part of developing a sustainable economy in the form of the triple bottom line, natural capital accounting etc. In this sense objective value theory is accounting for the whole not simply what individual economic agent may value. Accounting for the whole - thus mitigating negative externalities that are so prominent in a standard theory of value - would appear the only long term sustainable solution.

Likewise, whereas the subjective theory of value is limited in its capacity to tell us about the overall quality of life that the agent's experience, an objective theory may well be able to complement this to come closer to connecting our formulation of economic value with what people experience as real quality of life.

The subjective theory of value tells us about the exchange and consumption of goods, it does not tell us about the quality of the social, cultural or natural environment within which agents exist. Thus actors can end up living in a severely degraded social, cultural and natural environment - which significantly reduces their quality of life - while still, the economy is churning through vast amounts of resources so as to make up for this, and our metric would still tell us that the system is in an optimal state. This situation is again another critique that is often leveled at standard economics and the role it has played in the formation of a so-called consumer society.

An objective theory of value is a metric which captures this overall value of the context within which agents exist and thus this intrinsic conception of value is closely related to what we would call well being. Well-being is a very complex phenomenon. The value that it represents is a distributed one. Well-being is not the property of a thing, as illustrated by ample evidence that increases in consumption only correlate to increase in well-being up to a certain level and then they become uncorrelated. Well-being is what emerges out of forming part of or having access to many different services, ecosystems services, industrial services, social and cultural etc., but it is also in contributing to those systems, co-creating value within them. The value that emerges is a complex interaction of different forms of capital. A much more sophisticated conception of economic value would be required to capture this more subtle phenomenon of well-being. But there is clearly a growing demand from society that economics move in this direction, to be better able to provide metrics that reflect people's lived experience and the incorporation of some form of objective theory of value would be required to achieve this - as a subjective theory of value is clearly limited in this respect and requires a compliment.

In contrast to a subjective theory of value that appears inherently simple and elegant the implementation of an objective theory would be quite the opposite; inherently complex. The idea that objective value could be defined simply in terms of the physical work that went into the production of an item is clearly not plausible. A proper formulation would require accounting for, natural capital, social and cultural capital. The net result would be a complex network of variables - a move away from the contemporary homogeneous metric of value - required to come close to any form of objective value. This would require significant amounts of information, modeling, and computational capacity.

This being said we already see these new value metrics emerging in the form of social impact bonds, natural capital accounting, green bonds, fair trade, carbon tax, full cost accounting, carbon markets, triple bottom line etc. However as successful as these initiatives are, they are only fledgling, and hardly come close to a viable framework for the full complexity of an objective theory of value suited to a high-tech global economy of the 21st century. The formulation of an objective model to value and its practical implementation within a coherent framework is still a huge challenge in front of economics if it wishes to expand beyond the limitations of a subjective theory of value that currently confines it.

**Conclusion**

This section has been an overview of the basic theory of value within economics. We started with a broad overview of the more general philosophical discussion of value by talking about instrumental and intrinsic value, in order to try and illustrate how these basic concepts relate to standard economic formulations of value.

We outlined the two primary formulations of value as that of subjective and objective value theory and where these frameworks derive their foundation for the conception of value from. We talked about the subjectivist theory as deriving value from the utility that a subject places on an item in achieving their valued ends. While the objectivist theory defines value in relation to objective systems of organization and the resources that are inputted from those systems in order to generate the item.

We outlined the achievements and limitations of each framework, noting the simplicity and elegance of the subjectivist framework but also its limitations in not accounting for all the resources required to maintain an economy and thus its inherent tendency towards externalities, unsustainable results and its requirement for external support through public institutions.

Likewise, we saw the inherent complexity and difficulties engendered in a true objectivist theory of value, but the potential it offers in enabling a full cost, self-supporting economic framework, that factors in and can potentially manage its full set of required resources in a sustainable fashion.

What makes this such a relevant debate at the turn of the 21st century is a combination of both changing societal values/perspective and new technological means. A new paradigm to our global economy is emerging as industrial economies transit into post-industrial services economies; as the reality of environmental degradation becomes apparent and as globalization stretches and challenges the existing national institutional infrastructure. These major trends are driving a new vision and conception of what people value and making apparent the limitations of our existing theory of value grounded in a subjectivist model.

These major trends are combining with new technological means. What has changed with respect to our technological means is that with information technology we have for the first time the capacity to actually access and process a large part of the data required for such an initiative. Big data, IoT and advanced analytics will give us the means to sense and quantify our world like never before, the challenge is to make sense of this data. To build models that enable the economic theory that runs our global economy to reflect the underlying reality and thus enable us to manage it more effectively.

**Behavioural Choice Theory**

Economics is often interpreted as the study of how people make choices in the allocation of their resources. Microeconomics hinges on this process through which agents come to make decisions and then act on these decisions. Indeed as much of contemporary economics is considered to be derivable from micro foundations, choice theory plays a foundational role in the whole contemporary enterprise of economics. However, how we combine our beliefs and desires to make decisions and then act on them is widely considered to be a major unresolved puzzle.

The standard approach to interpreting human choices within an economic context became formalized into the idea of rational choice theory. The limitations of rational choice theory have long since been noted, but today they are coming under increasing critique and once again leaving open the question of how people really make their choices in an economic context.

In this paper, we explore both the standard approach of rational choice theory and newly emerging approaches based on behavioral economics and agent-based modeling. We will look at each aspect that supports the rational choice model, including consistent choice, utility, model expectations, the representative agent, methodological individualism and the macro-level equilibrium outcomes that it leads to.

In parallel to this, we will examine how these assumptions only really hold in simpler environments and have significant constraints when dealing with complexity. We look at the idea of heterogeneous value, adaptive choice, heterogeneous agents and agent-based modeling, the limitations to methodological individualism and non-equilibrium macro-level outcomes.

**Rational Choice**

Rational choice theory is the idea that economic agents have perfect information, both in space and time. They can know all prices and products available across an entire market. They are also perfectly informed of all the events that have previously occurred or will occur in the future through the use of probability, and they have an infinite capacity to compute all this information. From this they can, on aggregate, derive information that is directly correlated to some kind of underlying objective reality and then will act in a logically consistent manner upon this information. This is the so-called rational expectations hypothesis, which basically says that the information that agents act upon is known and cannot be systematically inaccurate or random. It must be correct on average. An important thing to note here is that standard economics does not say that individuals never make mistakes. It recognizes that individual people sometimes make mistakes but states that on aggregate they do not.

**Value**

The concept of value will, of course, be central to any model for describing choice. Fundamentally there are two models to value within an economic context, that of subjective value and that of objective value. Subjective value is the idea that economic value exists only in relation to some subject and is a function of the usefulness that the object under evaluation has in achieving their desired ends. Objective value is the idea that value may exist independently from the subjective evaluation of an entity, instead being derived from the objects functional role within a broader social, environmental or cultural context. For example, the value of a tree may exist in its role within a broader ecosystem it is a part of, and the ecosystem services that the whole system provides.

Rational choice theory is based on a subjective formulation of value, also called the extrinsic theory of value. Which is a theory that advances the idea that the value of a good is determined by the importance an acting individual places on a good for the achievement of his or her desired ends; what is called utility. The theory of extrinsic value posits that value cannot be measured or observed directly. So instead, economists devised a way to infer underlying relative utilities from observed choice, called 'revealed preferences.'

Utility always defines value in relation to someone. Thus, within this model, something cannot have value independent from someone desiring it. When value is defined by the interaction between different well-defined utility functions, this means that the thing does not have an intrinsic value.

Within this model, value is mono-dimensional and seen to be homogeneous. That is to say, that all forms of value can be reduced to a single form of exchangeable monetary value. Thus a comparison of different options an agent has is a simple comparison or optimization according to one single metric.

**Heterogenous Value**

In contrast to this behavioral economics, psychology and much empirical data will present the case that value is not a homogeneous thing but instead people value different things, social capital, natural capital, financial capital, cultural capital and they do not perceive these different forms of value to be reducible to each other. Thus actors in the real economy act in a way that is taking into account and making trade-offs between these different forms of value.

For example, we can go to a restaurant and pay for the meal that we consume, this is considered appropriate in that it is accepted that the cooks and waiters work is exchange for money. However, we perceive that it is not acceptable to go to a meal with one's girl friend's parents and then pay her mother at the end of the meal for her work. What would be acceptable though is that one might invite them out to a meal in exchange, or do some other activity for them. This is because we make a clear differentiation between the different forms of value and they can not be reduced to a homogenous form. Sometimes we can reduce all forms of value to a single form and ...make direct comparisons between them. But just as often we recognize their difference and then have to make a more complex trade-off between different forms of value.

The result of this is a more complex model to how people make choices, where they are never quite sure of the value of things and they are continuously redefining what things they value and the relationship between these different forms.
When we want to go on holiday we may first consider the price of that and its expected utility to us. But we also may consider, how many holidays our friends have taken and whether they will think we are lazy taking another. Whether it fits with our self-image. We keep in mind the picture that we saw on the advertisement of the golden beach. We perhaps may consider the cost to the environment, etc. These are different costs and benefits that can't be reduced to a single metric but in fact, in order to model them, we need to define different forms of value, social, cultural, financial, ecological and then try to optimize that network of values and how they interact. This is a more complex model that requires us to incorporate many more factors into people's preference.

**Consistent Choice**
An important component of rational choice theory is what is called consistent choice. Once an agent’s preferences have been revealed, they are not allowed to change unless the properties of a good they are evaluating changes. If I prefer an apple to an orange now, I cannot change my preference unless some property of the good changes. But if all the properties stay the same and instead we add a banana to this set of choices and I then make the choice again, I am not allowed to choose the orange this time because in both cases I did not choose the banana. It is considered not part of the optimization equation and thus cannot alter my choices. The banana is exogenous to the equation. It is part of the context, and within this model, that context cannot alter what happens in the equation.

Put more formally, if an agent chooses X over Y then whenever X and Y are available she will always choose X over Y. What this makes explicit is that the context cannot change the evaluation of things. The context cannot add or subtract any value. As long as this condition of consistent choice holds, we can then model agents’ behavior in terms of an optimization over a set of choices and we will get a closed form solution. In our previous example, because the banana should not have affected my choice, we can abstract away from the particular context within which the choice is being made, assuming that this context does not add or subtract value to the properties of the goods under evaluation, and thus we don’t need it in our model.

What this means essentially is that the value of something is in the properties of that entity and people’s perception of them. You are not allowed to change your evaluation of it unless its properties change. If you suddenly notice that the apple has a little blemish on it, then its properties have changed and you can change your evaluation of it and choose another option, this is considered rational. But it is considered non-rational to change one's mind based on what are considered exogenous factors.

**Context Dependent**
Much empirical data from behavioral economics has shown that people’s evaluation of things is framed by the context. This context involves many social, cultural or even environmental factors, all of which can add or subtract value to a good, service or activity. Thus, in order to capture this concept of objective value, we need a much more complex multidimensional conception of value, one that incorporates all of these factors. One that includes the different dimensions to people's conception of value, social capital, cultural capital, industrial capital and ecological capital.

Many experiments from behavioral economics will tell us that value does in fact change depending upon the context, and not only this but value may in fact sometimes be fully defined by the context. For example, the value of a color is dependent upon what color is placed next to it. The perceived value of a product in a magazine is dependent upon the other products in that magazine that they were never going to purchase, but the price and quality of those other products did create the context for their evaluation of the item that they did purchase. With hyperbolic discounting, our preference for different payoffs is dependent upon the context of time.

This phenomenon that value is not just dependent upon the properties of something in isolation but also upon its context is everywhere and very intuitive to us, but incorporating context as a defining factor in value would lead us to a whole new paradigm of objective value, where the value of something can be at least partially independent from the value ascribed to it by some agent in isolation. With objective value theory, the change in value may derive from the item’s relations to other things, and thus dependent upon those other things, what we can call the context. Thus, this context can, in fact, have some value and it can add or subtract value to any individual item within that context. Allowing for this empirical fact will give us very different models, where value and preferences are dynamically changing depending on the connections and context.

Out of this more complex conception of value, we get something that is able to approximate the idea of well-being. In that we know that well being is not captured in a single value such as GDP, but in fact is a much more subtle thing that emerges out of one’s connections with the things that one values – friendship, sense of purpose, respect from others, security, health etc. all of which this more complex metric of intrinsic value tries to capture. What behavioral economics and the empirical data coming out of it have shown, not surprisingly, is that people are in fact, people. They are complex creatures. They don’t just value one thing. They value lots of different things. What people really want is well-being, and well-being is not just one thing and people are then making a trade-off between different forms of value.

**Unstable Preference**
Behavioral economics draws upon neuroscience and evolutionary biology to present a picture to human decision making that is driven much more by irrational instincts, primordial motives such as hope, fear, and greed, that all totally bypass any kind of abstract isolated reasoning based on objective information.
Agents are driven by motives and these motives frame our whole point of reference. So if your care motivation or fear motivation is activated, then you will interpret information through this context. You will interpret signs differently, seeing cues that symbolize these things more readily. Motivation organizing one's perception is very different from the computation model to how humans interpret and process information. This agent with limited cognitive capabilities is placed in the world with a single location at a single point in time. In this scenario, information is scarce. Agents may only have access to local information and the future represents a deep uncertainty. With all of this lack of information and incapacity to process it all, we use all sorts of shortcuts that allow us to cope in complex environments. We make many irrational associations between things that aren’t always apparent. We make reference to the context and our environment, such as simply copying other people. We think in scenarios and narrative. Everything has to fit into a context for us to make sense of it and that context can alter the meaning and value of anything within it.

**Adaptive Choice**
Much of how people make choices in the real world is the product of an adaptive strategy. Instead of always having the same preference and making the same choice, people's choices evolve over time, the choices we make adapt to past events and information. We take actions in the world, see how those actions affect the world, and then make choices based upon that. Continuously updating and adapting our strategy in an evolutionary fashion, where we select from those choice patterns that worked best in the past. Much of human behavior that is non-rational is a set of evolved adaptive strategies for survival and homeostasis.

In economics, adaptive expectations is a hypothesized process by which people form their expectations about what will happen in the future based on what has happened in the past. For example, if inflation has been higher than expected in the past, people would revise expectations for the future. In such a way people take a limited amount of past data to predict future events. Adaptive expectations economize on the need for information as the agent only needs a limited amount of information on past period values. Adaptive expectation is time-dependent in that it puts more weight on the near past as opposed to information from the distant past. As one moves farther into the past, the effect on the current choice is reduced.

Adaptive expectations can be seen during periods of financial crises where actors have lost significant value and institutions have been shown to fail. In such a case markets can seize up as agents use their recent information naive. Adaptive choices are typically based on simple heuristics, such as naive expectations, where the agent's forecast is simply a continuation of the last state that they observed or experienced. Or it may be a simple change rule heuristic, for example following previous changes, if economic growth has been growing by one percent in the previous cycles then extend this out into the future etc.

**Homogenous Choices**
The standard economic theory of action is built on the idea of the representative agent. An economic model is said to have a representative agent if all agents are of the same kind and will thus act identically. Many macroeconomic dynamics stochastic general equilibrium models today are based on this idea of the representative agent.

The homogenous agent models work only as long as the deviations from the representative agent are not correlated. Typically this requires that the actors are acting independently, without interdependence between their actions and thus deviations can cancel each other out with negligible effects on the aggregate. When economists study a representative agent, this is because it is simpler to consider one 'standard' or 'normal' decision maker instead of looking at many different decisions at the same time. It is an analytical convenient shortcut required to achieve closed form equation based models within a complex world. Of course, this assumption must be left aside when differences between individuals are central to the question at hand as we will discuss.

A corollary to this is what is called model expectations. Model expectations underpins the rational agent model and means that people will make mistakes and will get misinformed, but because this is random noise it will on aggregate cancel itself out, and thus on aggregate people will act according to the model's expectations. Because it is random, meaning not correlated, one person’s misinformation that goes in one direction will be canceled out by another person’s misinformation that goes in another direction. If we add all these up, we will get some kind of equilibrium that is a correct representation of the actual underlying information.

This is part of how we can get very abstract clean models out of very complicated and noisy data. It works by assuming that the individual has the same properties as the average, and this will work on aggregate as long as the system is linear. This is why we will never get a model for any specific individual agent. We will always be talking about averages and aggregates because we have to take everything to the aggregate level to cancel out the noise and then assume any individual is identical to this average individual that is derived from the aggregation. The net result of all of this is that we can on average expect people to behave as if they have perfect information and act rationally upon it. Rational expectations hypothesis is a necessary condition to obtain internal consistency in stochastic dynamic aggregate models in economics. All of this will of course only work if we are dealing with a closed linear system.
Thus, it is assumed that outcomes that are being forecasted do not differ systematically from the market equilibrium results. As a result, rational expectations do not differ systematically or predictably from equilibrium results. That is, it assumes that people do not make systematic errors when predicting the future, and deviations from perfect foresight are only random.

A model that contains many different agents whose choices cannot be aggregated in this way is called a heterogeneous agent model. In such circumstances, it becomes more the correlations between actors choices rather than the choice of the representative agent that comes to define the aggregate outcome. In such circumstances, one must look at both the network of interactions and the differences among the actors in order to form models that will describe the macro system. Methodologically this requires a combination of both agent-based modelling and network analysis.
Agent-based models are the primary alternative to the limiting assumptions and model of the representative agent approach. Computers can deal with thousands and even millions of free parameters, and thus it is possible to code models with different expectations, preferences, information, propensities, psychological framing and tendencies etc. Agent-based simulation allows the explicit representation and exploration of the complex relationship between individual behavior and society; the micro-macro link between them.

**Equilibrium**
The premise of rational choice theory as a social science methodology is that the aggregate behavior in society reflects the sum of the choices made by individuals. Each individual, in turn, makes their choice based on their own preferences and the constraints they are presented with. This approach is called methodological individualism, an approach where the whole social system is seen to be nothing more than the sum of its parts. All higher level socioeconomic phenomena are seen to be traced back to micro-level elementary parts - more generally this is the idea of reductionism. Thus no higher level phenomena can exist that can not be derived in a linear additive fashion from the micro elementary parts. The net result of this will be an equilibrium on the macro-level. A key part of the rational choice theory is that agents are making choices in isolation and it is out of this that we are able to get stable equilibrium outcomes. In reality, though, people more often make choice in the context of others, so that how people act become synchronized.

When the choices people make becomes interconnected and synchronized things can all move in one direction and we get positive feedback instead of simply balancing negative feedback. The classical example of this being a stock market bubble. For example, if you look at the dot com bubble, what happens is that due to a few positive shocks new technology, the internet technology, pushes the prices up for fundamental economic reasons and these trend following rules then take over to reinforce this trend as positive feedback takes over. This is an explanation of the dot com bubble due to trend following heuristics.
Instead of there being an economy of agents making choices in isolation leading to stable balancing negative feedback, when we allow for the interconnectivity between agents we get positive feedback, things can all move in one direction and we get non-equilibrium outcomes that we see during financial crises and other forms of herd mentality where more begets more.

**Incentive Theory**

The study of incentives is one of the central topics in microeconomics – incentives to work hard, to produce quality products, to study, to invest, to save, etc. How to design institutions that provide good incentives for economic agents has become a central question of economics. Behind this, though is the idea of motives, that is to say, what motives do economic agents operate under. In this paper, we will be presenting two very different frameworks for understanding agents’ motives and associated incentive systems. We will look at the model of incentive theory that is central to standard economics and then go on to talk about the more complex model of intrinsic motives and choice architecture that is emerging out of behavioral economics.

**Hierarchy of Needs**
The motivations of economic agents derive from the needs, desires, and aspirations that they are trying to fulfill. These different types of needs are typically structured through the use of a model called Maslow’s hierarchy that fundamentally divides them into primary needs and secondary needs.
Primary needs are physiological in nature. They include such things as food, water, shelter, and sleep. Secondary needs are internal states like the desire for power, achievement, belonging, opportunities for advancement, relations with work colleagues, input into decision making, etc. People’s and society's needs can change over time as agents move on to new ones that become more intensified and important to them.

**Motivation**
Motives are the reason or reasons one has for acting or behaving in a particular way. It accounts for the direction, level, and persistence of a person’s resource expenditure in performing an activity or trying to achieve some end. Motives are divided into two different kinds: intrinsic and extrinsic. Extrinsic motives always have an end, a locus of desire, and the process is just a means for getting there. Intrinsic motives do not necessary have a final point of design but are more process orientated. The end value is more in the process.

**Incentive Systems**
A central question then within economics is how to create systems for aligning agents’ behavior with those of the organization or society. From driving too fast, to smoking, to work apathy, to lack of health insurance, economics, business management and policy makers spend a lot of their time thinking about this question. And there are really just two ways to do this; either we use direct incentives or we alter the context within which agents are acting. Behavioral economics focuses on this later solution while standard economics focuses on the former, what is called incentive theory.

**Incentive Theory**
A basic premise of standard economics is that people respond to incentives. The theory of incentives is one of the major theories of motivation and suggests that behavior is motivated by a desire for reinforcement or incentives. Thus, in contrast with other theories that might suggest we are pushed into action by internal drives, incentive theory instead suggests that we are pulled into action by outside incentives. According to this view, people are pulled toward behaviors that offer positive incentives and pushed away from behaviors associated with negative incentives. In other words, differences in behavior from one person to another or from one situation to another, can be traced back to the incentives available and the value a person places on those incentives.

**Rewards**
The most common incentive would be a reward. Rewards can be tangible or intangible and are presented generally after the occurrence of the action or behavior that one is trying to correct or cause to happen again. This is done by associating positive meaning to the behavior and or action. Studies show that if the person receives the reward immediately, the effect is greater, and decreases as delay lengthens. A combination repetitive action and rewards can cause the action to become a habit. This model has both its achievements and limitations. Incentive theory will give us a nice closed form model with direct linear cause and effect relations. They are very well suited to a top-down form of management because extrinsic incentives are designed to give compliance. They are explicitly and directly trying to alter agents’ behaviors according to the instructions of some managing body.

**Incentive Design**
Incentive systems have to be well designed, aligned with the interest of the agents in the system and the desired outcomes. Human beings are both finite and creative. That means that the people offering incentives are often unable to predict all of the ways that people will respond to them. Thus, imperfect knowledge and unintended consequences can often make incentives much more complex than the people offering them originally expected and can lead either to unexpected windfalls or to disasters produced by unintentionally distorted incentives. Added to this, direct incentives may have a crowding out effect. If we only take into account one form of value, we may try to optimize it at the expense of others with the overall outcome becoming suboptimal.
Extrinsic incentive systems work well when there is a clear set of steps and clear well-defined expected outcome or goal. But they only really work for analytical processes, as they narrow our focus and concentrate the mind. Extrinsic incentives only really work as long as the task involves only rudimentary mechanical tasks or simple algorithmic operations. Research has shown that when tasks become more complex, that is, as soon as the task involves some form of cognitive skills, creative skills or conceptual capabilities, extrinsic incentives were no longer effective and actually led to poorer performance.

**New Context**
This theory to management has been the default since the Industrial Age. This system has been the motivational structure for making people work throughout the 19th and 20th century and it is a core part of the whole industrial age capitalist model and the dichotomy between work and leisure. But the post- industrial economic environment we are moving into requires a new skill set involving entrepreneurship, cognitive capabilities, innovation, and self-engagement.
In this economy, people’s needs and motivation structure are more complex. It is an economy where people are connected and feel motivated by forming part of networks that give them different value through social media, collaborative consumption, peer-production, creative commons, open source etc. All of these go beyond our traditional understanding of why people render professional services and this necessitates a more complex nonlinear model. One that looks at the whole context within which agents are embedded in making their decisions and how that context alters their evaluation of things and resulting motivation.

**Value In Connections**
Within this intrinsic value paradigm, the value is in how things are contextualized – culturally, socially, environmentally and technologically. We will take some examples of this to solidify it. I want to be a lawyer because it is a socially respected job. That job is giving me access to a culturally respected identity. In other words, through that job, I am gaining access to cultural capital. Every time another person joins this culture and believes that my job as a lawyer has prestige, the value of the job goes up, not because it got any better or I get paid more but because the network that I am getting value from has grown.
I choose to wear a suit to work because that is what everyone else at my workplace does. The thing that is the suit is giving me access to social capital, derived from being part of this in-group. I buy a tablet computer because it will give me access to the Internet.
The value of these things is really in the fact that they give one access to a network that has value as a whole – the Internet, society, my culture, the natural environment etc. In all these examples the value is actually in the integrity of the entire network, not a property of the thing. Every time another person joins Facebook it makes my account with Facebook more valuable. My account has not changed but the network’s value has. And because the value of my account is in it, access to this network – its value – has gone up. This is what we call the network effect, where the value comes from the network. The network is just another word for the context, a set of connections that add or subtract value to the item.

**Disconnections**
If things then have value in their connections, the inverse is also true. By disconnecting them, we will reduce their value and thus the incentives and motives of the agents. Many of the jobs that are considered undesirable are so because they only give financial incentives. Cleaning the street is such an activity. It has very low social status. It has no enduring value as it will be rubbished again tomorrow and you will have to do it again. You will also have to live with the fact that some machine could probably do the job better than you. All of these reduce the psychological or what we might call cultural capital received from that activity. And due to this, we will have to pay people a financial reward, and that is the only incentive for performing this activity because they are disconnected from any other network that might add value to this activity.

**Value of Integrity**
Because the value is in the connections, it is both in your access to the network and the integrity of the network. If we were to disintegrate the Internet by disconnecting servers or cables, the value of all the devices connected would go down. Or if we believe the organization we form part of is without integrity, the value to us of our social status within it will also be devalued and thus the incentive for us to work devalued. Equally, we can note that the value of the whole system is often an emergent phenomenon, which requires all the parts to be working together in an integrated fashion. Out of this, we get the emergent value of the whole system and people's motive to form part of it. When we disintegrate the system this emergent value no longer exists, and the value of all the components in the system is reduced.
This intrinsic conception of value might be what we call wellbeing. Wellbeing is a very complex phenomenon. The value that it represents is a distributed one. Wellbeing is not the property of a thing. It is what emerges out of forming part of or having access to many different services, ecosystems services, industrial services, social and cultural etc, but it is also in contributing to those systems, co-creating value within them. The value that emerges is a complex interaction of different forms of capital.

**Process**
The value of something is not just contingent on its context within space but also its context within time. The standard model is very much a static one. Time doesn’t inherently change the value of things. In the static model, value just exists and people want it. If they get it they will be happy. It is assumed that agents will always try and achieve it at the lowest possible expense of resources, and thus within this model, there is no value in the process of achieving it. But this is in contrast to empirical data, where we often see that the value of a thing is created during the process that people go through in trying to achieve it. For example, in experiments that have been done with participants building things, like Lego toys or origami figures, the participants who engaged in this process valued those things more than those who did not engage in the process. And those who had harder tasks valued the end product even more.
In experiments, it turns out that people have to be paid more to do repetitive tasks that have no lasting outcome. As soon as you add some element of endurance to the finished product - so that they feel like they are part of an enduring process - this gives meaning to what they are doing and they will be more motivated, being prepared to work at a lower cost. This is an example of cultural capital as a motivator. It gives us a sense of direction and self-realization that adds value to what we are doing. With cultural capital, the value is in fulfilling some psychological motivation, and this motivation plays out over time. It is a process. The value is contextualized by that process.

**Emergence**
The sense of achievement one gets when one goes through the full process of creating something might be an example of an emergent phenomenon. The integrity of that whole process adds some value to it. In contrast, when we divide the process up through specialization, asking a worker to do repetitive tasks on a production line, they become alienated from the end product and receive limited value from it. This example illustrates that, as with our previous example where the value was added by the integrity of the context in space, the same is true of time where the value is in the continuity of the process and that emergent phenomenon adds value to any component within it. Like all emergent phenomena, this is nonlinear. The whole is greater than the sum of its constituent parts. By performing or maintaining that whole process, we get that emergent value. Value is added by the integrity of the network.

**Context**
By incorporating a wider spectrum of motives and values, behavioral economics has developed a very different model of incentives. Within this paradigm, we are thinking about how the broader context affects the choices that agents are making. We are looking at the physical, social and cultural networks of connections that the agents make choices within and how these different networks can add or subtract from the motives of the agents in order to alter them.
For example, in a purely physical context, behavioral economics looks at how choices are arranged within space such as the layout of a city, where plentiful open spaces make walking a more desirable mode of transportation than other options. Or in a canteen restaurant where there is a choice where we place items, we put the healthy food at the entrance making it more accessible than other options. These choices that are the easiest options due to their spatial location are examples of attractor states. Being the easiest option; they are a default, attracting users to adopt that choice. This is an example of what is called a "nudge" which is any small influence within the environment that attracts our attention and influences the behavior that we make. Of course, marketing has been using nudge theory for a long time in the layout of shops or the placement of products in catalogs, but because marketing is largely about creating a context for influencing people’s choices it never really fitted into standard economic theory.

**Social Context**
The social context within which choices are made is just as important as the physical. With the advent of social networking, the social dimension has become much more important in economics, both in work and consumption. By simply connecting people and making social information available, this can strongly influence peoples’ choices and provide motivation through a social context. Intrinsic motivators are self-directional. They can be best fostered by simply giving them space to develop, not crowding them out with incentive systems. We see some companies like Google, who instead of offering an incentive to employees for coming up with new innovations, they simply give the employee a day off every week to explore their interest as directed by intrinsic motivation. In so doing, they are simply not crowding out the intrinsic motives.

**Choice Architecture**
Choice architecture is another outgrowth from behavioral economics, which deals with the design of different ways in which choices can be presented to consumers and the impact of that presentation on consumer decision-making – for example, the number of choices presented, how we arrange those choices or which one is the default option. An important question here is, how do we frame those choices? When we sell a car, do we tell prospective buyers the amount of fuel to run the car or the amount of money to run the car? Although they both relate to the same underlying piece of information, it has been shown that people often make different decisions based on the different ways that the information has been framed. Choice architecture is built on our understanding of people as non-rational actors and how they use all sorts of shortcuts to cope when making decisions.

**Summary**
In this section, we have been talking about incentive systems within economics. We firstly talked about how different kinds of needs create different motivational structures. We looked at the standard approach to influencing peoples’ choices towards desired social outcomes through incentive theory, which suggest that agents are pulled into action by outside incentives, and by altering the payoffs associated with different choices we can alter their motivation. Inversely, behavioral economics is built on this idea of agents as non-rational actors. It tries to understand how people act in the real world, looking more at internal motives and the set of environmental conditions that influence those motives.

**Economic Systems Dynamics**

How economies develop over time is a very complex issue that has continued to evade our true understanding of. One approach to this question is through the use of models from systems dynamics, which is a systems-based approach that tries to look at and model whole complex systems through understanding the types of relations between the parts and the feedback dynamics that create the system’s overall behavior. For systems dynamics, the main concern is to understand how structure – variables and causal links – generates behavior in a world of continuous process, rather than discrete events. 

The model of causal links and feedback loops is fundamental to understanding the dynamics of complex systems as they capture and describe the different types of relations between components within nonlinear systems. Causal links and feedback loops are one of the best examples of the key premise of complexity theory; the idea that complex phenomena can, in fact, be the product of simple rules. But it cannot be a direct product of these simple rules. We can only get this complex emergent phenomenon out of the nonlinear interactions between these simple rules, as they are iterated upon over many cycles and give rise to emergent outcomes.

**Causal Links**

A causal loop diagram (CLD) is a causal diagram that aids in visualizing how different variables in a system are interrelated. The diagram consists of a set of nodes and edges. Nodes represent the variables and edges are the links that represent a connection or a relation between the two variables. A link marked positive indicates a positive relation and a link marked negative indicates a negative relation. A positive causal link means the two nodes change in the same direction, that is, if the node in which the link starts decreases, the other node also decreases. Similarly, if the node in which the link starts increases, the other node increases as well. An example of this might be the relation between manufacturing output and electrical consumption within an economy. They will both move together; the more of one, the more of the other.

A negative causal link means the two nodes change in opposite directions, that is, if the node in which the link starts increases, the other node decreases, and vice versa. An example of this might be the relationship between the amount of driving one does and the amount of fuel in your car. The more driving the less fuel will remain. Negative links are additive in nature, whatever we add or subtract from one side, we add or subtract the same from the other side. Positive links are compounding effects, where more of one thing begets more of the other within the relationship; both variables in the relationship move in the same direction, going up or down together. With positive links, in contrast, when we add or subtract from one element, we also add or subtract from another. Thus, they will not sum up to zero and we cannot create an equation around them. They will give us nonlinear solutions. Positive links and positive feedback are behind almost all nonlinear phenomena. Thus, they are very important to understanding the dynamics of nonlinear systems.

Because negative links are linear and sum up to zero, they can be used to model zero sum dynamics. If we have a cake and divide it up between two people, the more one gets the less the other will get. Negative links are what we might call neutral. The interaction itself does not add or subtract from the whole. In these zero-sum games the whole pie is staying the same, what is changing is who gets what. In contrast, positive links define non-zero sum games. A non-zero sum game is a situation in which the interacting parties’ aggregate gains and losses can be less than or more than zero. Thus, it is nonlinear. Through positive links, the whole pie that is being divided up between agents can grow or diminish, that is to say, the ...interaction is not neutral. The interaction itself is adding or subtracting something from the whole pie. In such a circumstance it is necessary to understand the type of relation between elements.

**Synergy & Interference**

If the interaction between the two components adds value to the whole, this is called a synergy. If the interaction subtracts value from the whole, it is called interference. A synergy is a constructive interaction, meaning the output to the interaction will be more than the sum of its parts. There are many examples of synergies in our world, from the cooperation of cells and organs in the human body to many different kinds of synergies produced by social organizations. Trade is thought to be positive sum for example, because if you are prepared to part with something you must value what you are exchanging it for more. And if both value what they are getting more than what they are giving up, then some value has been added to the entire system through this interaction.
The word synergy comes from the Greek word meaning ‘working together.’ This working together involves the constituent components differentiating their activities with respect to each other and also coordinating these activities towards a common end. One of the best examples of this is our global economy. Many millions or even billions of people perform different specialized functions, but these functions are then coordinated within firms and markets so that we can get something like a laptop computer that no one person could create. It is only through this process of differentiation and then reintegration that value is added to the system. Synergistic relations are pervasive phenomena in our universe as they are part of all complex organizations, and of course, they are nonlinear. The whole will be more than the sum of its parts because value is being added by these synergistic interactions.
Synergies are just one type of positive link where both components’ values will move in the same positive direction as the whole pie grows, but we can also get the inverse phenomenon. They can both move in the negative direction due to what is called interference, the classical example of this being the interference between two sound waves as they cancel each other out. Interference is the opposite of a synergy, that is to say, the failure to differentiate and coordinate. If a society doesn’t provide proper education and training for its people or they don’t choose to take it, there will be too few high skilled specialized workers and too many people looking for undifferentiated unskilled labor. Because of the failure to differentiate, there will be a failure to coordinate and we will get interference and crowding-out. Because of this destructive relation of interference, the whole pie will get smaller and the variables associated with all the components in the relation will go down together.

**Positive & Negative Externalities**

Negative links define closed systems. As such, they are representative of dynamics surrounding rival goods. The more that one person uses of a rival good the less another can. Value is excludable. Thus, we get a well-bounded, well-defined system. Marginal cost will approximate marginal benefit with a trade-off between agents and an equilibrium, out of which we can create the market mechanism of supply and demand. Because nothing is being added or subtracted to the entire system, negative links have no externalities.
Non-rival goods are goods that have externalities. With non-rival goods, marginal cost or benefit approaches zero. The benefit to the additional consumer may be substantial, thus resulting in a non-zero interaction and positive externalities.
Because positive links are non-zero sum, they have externalities – both positive externalities where through synergies the system becomes greater than its parts and thus adds value to its environment. And inversely, through interference, it can subtract value from its environment, what are called negative externalities. When a company achieves internal synergies between employees or departments, it will be able to deliver a better product that will be of more value to the economy and society, which is a positive externality. With synergies and positive externalities, social value is higher than the private value.
With interference, the system will be less than the sum of its parts, and thus the input of resources to the system must be more than the output in order to maintain the system, meaning the system’s environment is paying the cost for running the system. The social cost is higher than the private cost. Some of the cost is being externalized to the environment, a negative externality. Thus, the system will over-produce because the marginal cost to the system will be less than the marginal benefit.

**Market Mechanism**

A negative link can be used as a description of the market mechanism, where the benefits and costs of each agent in the relation are balanced against each other, giving an equilibrium of supply and demand through which to regulate the quantity of goods and services produced and consumed and their allocation; it is a self-regulating system. The market mechanism breaks down when we have both positive and negative externalities; because the marginal cost and marginal benefit are out of equilibrium. The two are not moving in opposite directions or there is a weak correlation between them. As for example might be the case with digital products where the marginal cost of producing one more copy is very small and the marginal benefit can be very large, thus, the two are not directly correlated. This is even more extreme with the network effect where both the producer and the consumer can be gaining value at only a very small marginal expense to one, meaning both variables are moving in the same direction. Civil war is another example of a positive link. We have interference in the system as the two components are in conflict. The marginal cost to one of waging war is also a marginal cost to the other. Here, the two variables are moving in the same direction that is not balanced and thus it can’t be regulated through the market mechanism.

**Nonlinearity**

Causal link diagrams help us to focus on nonlinear phenomena in that they divide the world into linear additive interactions as described by negative feedback, and nonlinear interactions as described by positive links that look specifically at relations that add or subtract value from the entire system through synergies or interference between the agents. They can be used as a basic formal language for capturing many game theoretical microeconomic phenomena such as non-zero sum games, externalities, and non-rival goods or market failures. It is in causal loop diagrams that involve the interaction between many causal links that we can see how complexity may emerge from very simple local rules and their nonlinear interaction over time.

**Economic Feedback Loops**

How complex systems like businesses and economies change over time is studied within the domains of system dynamics that came out of MIT during the 50’s and 60’s. Central to this area is the idea of feedback loops, which we exploring in this article. As we talk about positive and negative feedback, virtuous and vicious cycles, we will touch upon the subject of control systems and finally causal loop diagrams. This is continuing on with our previous discussion on causal links where causal links defined relations between components within space all at the same time, but with feedback loops we are defining these relations over time. So here we are talking about the dynamics of the system, how it changes over time.

**Feedback**

A feedback loop defines a relationship of interdependency between two or more components where the change in state of one element affects that of another, with this effect then, in turn, feeding back to alter the source element. This dynamic captured by feedback loops plays a fundamental role in the self-organization of elements within complex systems. They are also a key model for understanding how nonlinear systems like markets and economies evolve over time.
An example of this might be a dialogue between two people. What you say now will affect what the other person will say, and that will in turn feed back as the input to what you will say in the future. What feedback loops are saying is that the output to the system now will affect its environment in some way and that effect will feed back to be the input to the future state of the system. This is in contrast to linear models that describe linear cause and effect, meaning that the output to the system now will not affect its future state.

**Positive & Negative Feedback**

Feedback loops can be of two kinds – positive and negative. A negative feedback loop represents a relationship between two variables, say A and B, where more of A will result in more of B, which in turn feeds back to result in less of A. For example, the relationship between supply and demand is a negative feedback. The more a producer supplies, the lower the price for it, which will feed back to reduce the incentive to produce more in the future. As opposed to negative feedback where more begets less, a positive feedback loop is a relation where more begets more. More of A will result in more of B, which will feed back to induce more of A. For example, asset pricing involves a positive feedback. As the expectoration of investors goes up, demand and prices go up, which then feed back to increase expectation, once again driving price up.

**Dynamics**

Feedback loops take place over time and thus creates a certain dynamic pattern to the system’s development. A negative feedback loop is one of constraint and balance. As different things are being balanced, it is always tending towards some equilibrium point. If there is some external shock to the system that is not too large the negative feedback loop will bring it back into balance. As such, a negative feedback is a control mechanism. For example, governments try to control economies through automatic stabilizers where income taxes and welfare spending are used to dampen fluctuations in real GDP. They act to stabilize and balance economic cycles. Negative feedback control of this kind results in an inherently static system as it is designed to resist systemic change. Stimulus packages and bank bailouts during a financial crisis are another example. They are using the control system of the government to try and bring the economy back into its previous equilibrium.

**Destabilizing**

Positive feedback in contrast to negative feedback is a destabilizing process because some change in the system’s output now will be fed back in at the next iteration where that change will be increased. Thus, there is no balancing mechanism. The system will stay moving off in the same direction as the change gets compounded with each iteration. This compounding gives us exponential change and if we have rapid iteration this exponential change is a very powerful force driving the system away from its equilibrium. If it does not get balanced by some negative feedback loop, it is bound to take the system out of its current regime and into a whole new state. Positive feedback loops and the exponential change they give rise to can be best described as radical phenomena. When they operate in isolation without negative feedback the outcome will be extreme.

**Virtuous Cycle**

This change may be either very positive or very negative. A change in a positive direction is called a virtuous cycle, where more of a positive thing begets more of it. For example, investment in economic infrastructure is a virtuous cycle, as companies can be more productive, rendering more tax which can then be reinvested in better infrastructure leading to a more efficient economy and so on, creating a spiral that moves up in one direction until it hits some ceiling.
Economics of scale is likewise a virtuous cycle that a startup company can rise. Greater scale of production leads to lower marginal cost and low price to consumers, which leads to more consumers, which leads to more revenue, which feeds back to enable greater scale of production, and so the cycle goes on. The net result will be exponential growth in the company’s early years, but this only lasts for so long. As a market becomes mature, some limit will be met that will place negative feedback on the system to stabilize it.

**Vicious Cycle**

A vicious cycle is a positive feedback loop that goes in the opposite direction, spiraling downwards like quick sand. It is what management and governments fear greatly. A classical example would be hyperinflation, or for example, there was a vicious cycle behind the previous financial crisis. As housing prices declined, more homeowners went "underwater," when the market value of their homes dropped below the mortgage on it. This provided an incentive to walk away from the home, increasing defaults and foreclosures. This, in turn, lowers housing values further due to over-supply, reinforcing the cycle in the same downward direction.

This whole process of an economy going into recession is also an example. Significant job losses lead to reduced spending, harming additional firms, causing more job losses and causing prices to fall in a way that makes those who still have an income hold back on spending because they expect things to be even cheaper in future. The mechanism of a vicious cycle is here, dragging the economy towards collapse. From these examples, we should be able to see how powerful these positive feedback loops are as they lead to run away effects that are very difficult to break. Once put into motion, they often drive the system into a whole new regime and environment.

**Control**

These examples should also illustrate how positive and negative feedback loops are central to the whole idea of control. As such, they are the foundations of the science of control called cybernetics. Negative feedback is used within centralized control systems of all kinds and it represents goal-orientated behavior; that is to say, the control system has to define firstly what is the desired state to the system. If we want the thermostat to work in our house, we have to set the desired temperature before it will operate. This may be simple when it comes to heating our house. But when we use a negative feedback loop to manage a whole corporation or economy, we are going to have to spend a lot of resources in trying to predict the future and to figure out what are the possible future scenarios, which of those is optimal and then accordingly adjust the mechanisms we have for regulating the system, such as taxation, grants, interest rates and so on.

**Complexity**

Feedback is often removed from standard models within science, engineering, and economics, because it adds significant complexity and limits our capacity to project out into the future, predicting events, as all future states will be contingent upon many feedback loops along the way. This failure to properly incorporate feedback into our analytical models is one reason we are very poor at predicting major nonlinear changes such as economic crisis. Feedback loops are an inherent part of the development of complex systems like the economy and they mean that they are nonergodic. The future is not some simple transformation of the past. The faster the iterations to the system and the more the feedback, the lower the capacity to foresee the future, meaning any centralized, top-down negative feedback form of control has its limitation when dealing with complex organization. It is really best suited for very simple systems, operating in stable and predictable environments, like a thermostat.

**Distributed Feedback**

In complex, volatile and uncertain environments, control needs to be distributed out so that components can readily adapt to local level information. Negative feedback has to be built into the system on the local level through the appropriate connections between components. Top-down centralized control systems are appropriate when there is a lack of connectivity and information. But as we turn up the connectivity and availability of information on the local level, we can create distributed negative feedback loops through peer-to-peer connections and exchange of information, which makes the system greatly more robust, flexible and adaptive. This is of course very much related to the subject of self-organization that we will be discussing in the next module.

**Causal Loop Diagram**

A causal loop diagram is then a map of all the nodes, causal links and feedback loops within a system. Out of this, we can begin to get an understanding of its overall behavior. We can see the stocks and flows of resources within the system and can also begin to generate more quantitative model through computer simulation. These causal loop models have been used for modeling many economic phenomena such as product adoption, industry regulation, and environmental degradation. They are not designed to give us exact predictions to the future but more to understand the key drivers and dynamics behind the systems, thus allowing us to begin to think about what links need to be altered in order for the system to exhibit more of a desired behavior such as stability, robustness, sustainability or a change of some kind.

**Summary**

In this module, we have been looking at how feedback loops drive the dynamics of complex organizations like economies, markets, and businesses. We talked about the two basic types of positive and negative feedback, how positive feedback leads to self-reinforcing behavior over time. As with each iteration to the system, some phenomena get compounded, giving us exponential runaway behavior. In contrast, we looked at negative feedback that works as a balancing mechanism. As with each iteration, the system counterbalanced its previous direction continuously leading back to some equilibrium point of stability. We mentioned how this is often used to design centralized control systems. Finally, we had a quick look at causal loop diagrams that try to capture the full set of causal relations governing the overall dynamics of complex organizations.

**Nonlinear Economic Dynamics**

In this module, we will be talking about the concepts of equilibrium and non-equilibrium. In continuing on with our discussion around feedback loops, we will see how equilibrium is derived from negative feedback and randomness but as soon as we get positive feedback within the system, this will give us nonlinear dynamics and disequilibrium. As we get the emergence of new and distinct patterns of organization on the macro scale, during our discussion you will be introduced to a number of new concepts within complexity theory, such as symmetry breaking, phase transitions, tipping points and path-dependency.

**Positive Feedback**

From chaos theory to network theory, complexity science has taught us that these complex systems that we once thought were random are in fact certainly not. We just didn’t have the tools to model them. We had linear models to describe simple interactions. We thought that if things weren’t governed by simple symmetries, they must be random, for which we used stochastic modeling. In order to get randomness by definition, the variables have to be independent, that is to say, no connection or correlation between them. Complex systems are by all definition highly interconnected. Through these connections, the components synchronize their states and the result of this are correlations between variable, meaning the system is not random.
Non-equilibrium arises out of positive links and feedback between components. Positive feedback loops are reinforcing. They drive the whole system in one direction over time. Local level events can get amplified by positive feedback to give rise to new out of equilibrium patterns on the macro level. Bank runs are a good example of this. Starting from some initial equilibrium state on the micro level, say the bank’s balance sheet where inflow and outflow are being matched, we then get some small event. And this balance is broken through some loss of confidence, which then gets amplified by positive feedback where the more people that lose confidence the more other people are attracted to do likewise, and this may not stop at one bank but in fact, result in the emergence of a system’s level phenomena. Thus, we see a small local phenomenon through nonlinear interactions giving rise to a large global state of disequilibrium. This is the process of emergence and it takes place through what is called symmetry breaking.

**Symmetry Breaking**

Within physics and mathematics, the concept of symmetry has become central and one of the most powerful tools used to describe very fundamental phenomena in terms of symmetric transformations, such as the relationships between matter and anti-matter. The other side of this is another big idea within complex system, that of symmetry breaking. Wikipedia has a good definition here, to I will quote from them: “Symmetry breaking in physics describes a phenomenon where (infinitesimally) small fluctuations acting on a system which is crossing a critical point decide the system's fate, by determining which branch of a bifurcation is taken. To an outside observer unaware of the fluctuations (or "noise"), the choice will appear arbitrary. This process is called symmetry "breaking," because such transitions usually bring the system from a symmetric but disorderly state into one or more definite states. Symmetry breaking is supposed to play a major role in pattern formation.”

**Examples of Symmetry Breaking**

Traffic jams are examples of symmetry breaking. We have some traffic moving smoothly along, all at the same speed and distance, then some small event occurs such as a car needing to slow down as someone crosses the street. This creates a positive feedback loop as this small event gets amplified back. During this process, the system becomes heterogeneous. People are now moving at different speeds and distances between them. The symmetry is broken. It may return to its previous equilibrium or it may move into a whole new regime as a gridlock takes hold.
As an example of symmetry breaking within economics, we might think about the emergence of globalization. On a very high level, the industrial age system of the national economy, because it was a relatively closed system, had symmetry to it. People were producing goods in one part of the system and consuming them in another. With globalization, we get symmetry breaking of the national economy. As components emerge that connect directly into the global economy, a multinational corporation comes in and builds a mine exporting everything back out to the global market, creating a broken symmetry and dis-equilibrium.

**Economic Institutions**

With symmetry breaking, we get some symmetry on the micro level that is violated on the macro level, giving rise to a distinct pattern of organization. Because of the nonlinear interactions of synergies and interference, within an economic system, we get symmetry breaking and the emergence of distinct patterns of organization on different levels within the economy, and this is one way of understanding economic institutions. Within a linear model, there is no symmetry breaking and institutions don’t really exist. In as much as they do exist, they are typically derived from exogenous factors such as transaction costs. But with nonlinear interactions, they can be formalized as an intrinsic part of the system operating on many different levels from households to businesses, cities and whole distinct economies, all of which are non-equilibrium phenomena that have emerged out of some symmetry breaking derived from a non-linear interaction within the system and give rise to a heterogeneous macro system.

**Phase Transition**

Symmetry breaking is part of a broader process of change that is called a phase transition. A phase transition is where some small change to a quantitative control parameter leads to a systemic transformation. So for example, the control parameter might be temperature, and at some critical point when we change it only a small amount, we will get solid ice change to a gas, which is a systemic transformation. Solids and gas have fundamentally different properties. Phase transitions are typically discontinuous. For example, a liquid may become gas upon heating to the boiling point, resulting in an abrupt change in volume. This discontinuous change is because there is a tipping point or threshold that has to be met before the change process will be initiated. It is not a continued change but a nonlinear abrupt change during which the system is in a state of disequilibrium.
So we could take a financial crisis as an example here. There are financial institutions that go under all the time, but there has to be a critical mass of them exhibiting stress before people will start to lose confidence, and once they have, a positive feedback loop will take hold. Every new person withdrawing money will attract others to do so also. What is happening here is that we start with some equilibrium, a stable state held in place by some negative feedback, until we reach the critical point, the tipping point where positive feedback takes over. The equilibrium or symmetry is broken and we get a rapid phase transition, the emergence of some new phenomena on the macro level, a macro level dis- equilibrium that creates some new structure.

**Punctuated Equilibrium**

Whereas negative feedback loops lead to an equilibrium state and a stable linear state of development, where the input and output ratio to the system stays constant leading to an incremental linear progression, real world complex systems like ecosystems and economies are a whole network of both positive and negative feedback loops operating on many different levels from the micro to the macro. The overall state that the system exhibits is a product of the balance between these two. Negative feedback is holding it in its current configuration. Positive feedback is always trying to drive it out of this equilibrium.
For example, as long as I stay getting up every day and going to work, I will be able to remain in my current financial state of stable development. But when I don’t go to work and stay at home playing computer games all day, I have broken out of this negative feedback loop. There is now a broken symmetry between what I earn and my expenses, and the longer I stay out of work the farther away I am moving from this equilibrium, possibly resulting in a regime shift as I become permanently unemployed and kicked out of my house. This model to a system’s development is called punctuated equilibrium, where periods of stable development and equilibrium, where the system is dominated by negative feedback are punctuated by periods where positive feedback becomes dominate. We get a symmetry breaking and the system moves far from its equilibrium into a phase transition as it moves into a new regime, with a new attractor and new equilibrium, and once again a new set of negative feedback loops taking over, giving us this punctuated equilibrium that is a product of an interplay between negative and positive feedback development.

**Path Dependency**

Whereas closed linear systems are time reversible and predictable, the development of nonlinear systems is not. Because of nonlinear feedback loops, we get sensitivity to initial conditions. We cannot predict the future and we can not go backward, meaning time only goes in one way and we find ourselves on a particular path because of what happened in the past. The fact that we can’t go back and change it means we get path dependency and history matters. With path dependency, because of choices made in the past we are locked into a particular set of possible states now. An example of path dependency would be a town that is built around a factory. It makes more sense for a factory to be located a distance away from residential areas for various reasons such as pollution. However, it is often the case that the factory was built first, and the workers needed homes and amenities built close by for them. It would be far too costly to move the factory once it has already been established, even though it would better serve the community from the outskirts of town.
The net result of path dependency is that we never get a clean slate on which we can choose the most efficient, optimal solutions. Our economics are instead far from optimal and thus far from equilibrium. Everything doesn’t just smooth out to a homogeneous state, but we go on with heterogeneous state to our economy, small pockets that are different because of the historical events that brought them to this current heterogeneous state.

**Emergence**

All of what we have been discussing is really part of the very bigger idea of emergence, the process through which novel phenomena are created as we go from the micro to the macro or during the process of a system’s development. Emergence is a very abstract and pervasive phenomenon, but all of these models from self-organization to symmetry breaking to phase transitions and punctuated equilibrium – they are all really describing this same phenomenon of emergence in different ways due to its very high level of abstraction.
To quickly summarize then in this section, we have been talking about equilibrium and non-equilibrium, how closed systems, negative feedback or random correlations between components on the micro level will give rise to a tendency towards equilibrium on the macro level. But that as soon as we have an open system or nonlinear positive feedback, this equilibrium will be broken, as we get the emergence of distinct symmetry breaking patterns on different levels.

**Economic Self-Organization**

Our global economy is one of the most extraordinary examples of a complex system built largely through self-organization. Through the local incentives of millions of people and organizations around the world, we can produce something like a car that no individual in isolation could come close to producing and no one really controls or coordinates all of this. This order is an emergent property of millions of interactions around the globe, the same distributed dynamic that governs ant colonies, flocks of birds and the emergence of new cultures.
Self-organization is the emergence of a globally coherent pattern of organization out of the local interactions between initially independent components. It is in many ways very much counter-intuitive to our traditional beliefs about order having to be imposed from some external top-down design. This top-down approach is the default model that we inherit for the industrial age. It is the model to corporations, national economies, and most social organizations. But today, through the rise of information technology we see the emergence of new forms of distributed self-organizing networks that are capable of delivering value at a scale that we previously thought was not possible from this type of alternative organization, from car sharing to filesharing, to open source software. Now that information technology, the internet, and new software platforms have provided the enabling context, we are seeing that self-organization can in fact be and is increasingly becoming a mainstream economic model for production and consumption.

**Process**

But this process of self-organization and emergence is not a mystery. Through researchers having encountered it within many different areas, from chemistry and physics to engineering and sociology, we have pieced together a basic understanding of how it works and what conditions are required for it to take place. Self-organization is not a structure or static model like a hierarchy. It is a dynamic process that plays out over time. It is a process that is driven by an interplay between order and entropy. So unlike our traditional model that is all about maintaining order and stability, in the way that a government tries to regulate an economy so as to achieve some optimal state, self-organization is not like this at all. It inherently requires entropy to take place. By entropy, I mean some form of disorder or randomness.

**Randomness**

Entropy is the first condition in order to achieve self-organization. If we take a communist command and control economy where everything is regulated, with all the products having to be routed to a central authority and redistributed from there, this is a top-down model that is trying to hold the system in a particular configuration. As long as we have this structure, there cannot be self- organization. We have to have an initial state of randomness. When we have many people together in an unregulated environment, they will start to interact as they exchange goods and services between them. These are nonlinear interactions. They are happening in a distributed fashion. No one is coordinating them. They are created and driven by the local incentives of the agents. The process of self-organization is facilitated by dense interactions. This is one reason why information technology is driving the emergence of self-organization systems because it enables a much greater density of distributed peer-to-peer interactions through which people can coordinate their activities. Cities are a good example. If you go to any city in a developing country, you will likely see self-organizing informal markets on many side streets because of the density of interactions that the urban environment enables.

**Positive Feedback**
Positive feedback plays a key role in the process of self-organization. Agents that interact more often and more intensely will come to synchronize their states, enabling more fluid, friction-free transactions. This could be people coordinating their activities to produce a product, or people trading on a regular basis. This coordination and reduction in transaction costs enable this subset of agents to be more productive, attracting others to this particular configuration in a positive feedback loop as we get the emergence of institutions, like a business, market or financial center.

**Attractors**
This positive feedback of economics of scale creates an attractor space, a particular set of states towards which any new component within the system will be drawn as it becomes a default. Cities are good examples of this. By having such a high density of people, they reduce transaction costs, increase economic coordination and leverage economies of scale as they become an attractor for anyone in the locality of the city looking for work, trade or business opportunities. We might cite Singapore as an example. Having offered itself as a center for free trade during the colonial era, it managed to reach a critical mass to become an attractor for trade and finance within Southeast Asia. But without global regulation and coordination, we will typically get a number of different local attractors forming. For example, Singapore is just one attractor within the global financial system. We also have New York, London, Tokyo, Shanghai, etc. Each of these is a different attractor that has emerged from their local context and now has to compete within this global environment.

**Order and Chaos**
Self-organization is a dynamic process. Agents come together in a swarm-like fashion, like in a group of peers sharing files on the Internet, a flock of birds, or in bank syndication. The agents coordinate their activities but the organization that emerges is very much time dependent. There is no centralized force holding them in this configuration. They have to stay regenerating themselves in an evolutionary process that involves some interplay between order and entropy. We are far from properly understanding this dynamic. Thus, there are a number of hypotheses, such as the edge-of-chaos hypothesis, which is a metaphor for how some physical, biological, economic and social systems operate in a region between order and either complete randomness or chaos where the complexity is maximal. Researcher Stuart Kauffman has studied mathematical models of evolving computational systems in which the rate of evolution is maximized near this so-called edge of chaos.

**Creative Destruction**
Put more simply, self-organization emerges out of entropy and randomness. In order for the system to stay regenerating itself over time, it may need a delicate balance between maintaining some coherent and structured patterns while also needing some randomness and entropy in order to say creating new patterns and adapting to changing circumstances. As an example, we might think about Schumpeter’s idea of creative destruction, in which new products, new forms of distribution and organization displace older forms. But in order to get this dynamic evolutionary process, the market needs to be able to both foster new structures emerging from entrepreneurs and disintegrate old structures. This is a very different vision to market than the traditional static equilibrium of supply and demand. It is a dynamic evolutionary one and we will be talking more about evolution in a later section.

**Self-Organizing Criticality**
Self-organization is then both a creative process and a destructive one. Just as positive feedback loops can drive rapid self-organizing growth, they are also a part of disintegration. The sand pile model to self-organizing criticality best describes this phenomenon. In the sand pile model, grains of sand are dropped onto a pile one by one. As the pile starts to build up, some grains will roll off the side one by one or in small groups but some don’t as the side angle to the pile begins to reach a critical angle of repose before a very large avalanche takes place. The avalanche is a product of positive feedback. The more grains that are falling, the more likely they will displace additional grains that will then augment the size of the cascade, and so on. Thus, we get a positive feedback loop leading to a large avalanche.

**Power Law**
The size of the avalanche and the number of times it occurs represents a power law distribution, meaning there will be very many, very small cascades and very few, very large cascades. This power law distribution that is a common feature within nonlinear systems allows for events that are statistically virtually impossible within a linear system. These very large events are called black swan events. Many destructive phenomena exhibit this power law distribution including earthquakes, neuronal avalanches in the cortex, forest fires, landslides, epidemics and stock market crashes. Thus, these self- organizing systems like the sand pile are nonlinear in that a small perturbation to the system can have a very negligible effect or it can have a radically disproportionate one where a single grain inputted can cause a massive avalanche, and we don’t know when this will occur.

**Multiple Levels**
Self-organization gives rise to new levels of organization, what are called integrative levels. It is out of this self-organization that we get the emergence of institutions from the micro level of a small local market to large business organizations, industries, economies and ultimately our whole global economy, which is a complex adaptive self-organizing system that has evolved over thousands of years. By looking at the economy as a self-organizing system, we can begin to recognize these emergent patterns that are not identifiable when we use standard linear systems, models where we simply aggregate up from the micro level. But with self-organization, we can get non-equilibrium and the emergence of attractors on different levels, with these attractors having their own emergent internal dynamics, meaning they can’t just be abstracted away or derived from simple aggregations of lower level phenomena, and they are very important to the behavior of the system.

**Characteristics**
Self-generating systems of organization have a number of common features to them. Firstly, self-organizing systems are of course user generated. Because of this, we typically get much greater user engagement. When someone is self-employed, they will typically be more actively engaged than when they are employed by some centralized organization. We might think of how capitalism is able to harness the entrepreneurial spirit of people in a bottom-up fashion as they feel like they are able to change their lives through private enterprise, which is in contrast to more command and control economic system.

Secondly, self-organizing systems are typically more robust because they are distributed. The system is not dependent upon one agent or a few agents for its future functionality. Many self-organizing systems can maintain themselves without the dependency upon highly specialized components, meaning many of the components can be easily swapped for any other if they fail.

Thirdly, whereas the command and control organizational structures of hierarchies may be well suited to static and stable environments, self-organizing systems are well suited to dynamic, complex and volatile environments where needs are changing. They are inherently dynamic and adaptive because the agents are not held within a specific configuration by top-down administration. They are able to receive and respond immediately to events within their local environment, making them very flexible and adaptive.

Lastly, there is no concept of optimization within self-organizing systems. There is no centralized authority designing or controlling the system in order to achieve an optimal outcome in the way that government typically does with economies. Thus, we will typically get results that are far from optimal.

**Summary**
In this section, we have been taking a brief look at the process of self-organization as it applies to economics. We firstly talked about how in contrast to hierarchical structures, which are static, self-organization is a dynamic process through which patterns of organization emerge out of local level nonlinear interactions. We talked about a number of stages and prerequisites to this process, including an initial unregulated state, dense nonlinear interactions between agents through which positive feedback can amplify some small event into an attractor where agents synchronize their state to reduce transaction costs and leverage economies of scale, creating a stronger feedback mechanism. Out of this emerge distinct local patterns of organization that then have to either cooperate or compete on the global level, with the net result of this emergent process being a multi-level system with distinct irreducible levels of organization; what we might call institutions. We finally talked about self-organizing criticality and some of the key characteristics of self-organizing systems such as robustness, adaptability, and non-optimality.

**Economic Network Theory**

Over the past few decades with the rise of information technology and globalization, we have networked our global economy like never before. Both its technological infrastructure and its institutional superstructure have become increasingly integrated into dense, multimodal networks, from the micro level of individual organizations all the way up to the global level through global cities and the global supply chains that they enable. We have increasingly interconnected our economies, bringing in frontier zones like the copper mines in Mongolia or small rural villages in Norway as they connect into the ever-denser set of connections between the global cities.

On top of all of this, we have built a global financial system of extraordinary complexity – financial networks that represent cross linkages between assets and liabilities all over the planet, risk, and returns that are sliced and diced and distributed out into the future through all sorts of derivatives, contracts, and exotic instruments. Making all this happen are of course telecommunication networks on all levels. Previously well-bounded organizations like national economies and corporations are scrambling to adapt to a massive wave of hyper-connectivity, as we see new IT-enabled network organizations emerge and thrive in this connected economy of the 21st century. Suffice it to say, networks are emerging as a fundamental organizational structure within post-industrial economies and understanding them is more relevant than ever.

**Components & Connections**
Linear system theory is a component-based theory, meaning it is primarily concerned with the properties of the components in the system, and this will be the same for any science that is using this framework such as standard economics. When we look at a typical map of the world economy, it will show us lots of countries and their GDP. When analyzing a corporation, we describe it by itemizing its gross revenue, number of employees, who the CEO is, and so on. All of these are descriptions of the system through reference to the properties of its components.
This is a very valid and important approach to economic analysis, but it is only really relevant when we are dealing with a linear system that has a low level of connectivity. When we turn up the connectivity, the relations between the components start to become the primary factor in determining the system’s overall dynamics. In such a case we need to use an alternative modeling framework that is better able to capture these relations and their structure; this is exactly what network theory does.

**Network Theory**
Network theory, also called graph theory, is one of the very few major modeling frameworks within complexity theory. It is an abstract formal language which deals with the big idea of connectivity, which is a whole paradigm shift because we are naturally adapted to see things and not so much connections. Thus, this world of connectivity is very different to the one we are used to. It is all about access, where you are in the network, what is the overall structure of that network and what is flowing through it. As is always the case, it is important to understand what the modeling framework is designed to do before you start to use it. Network theory is designed to let us focus on the relations between components and the structure of those relations in both a qualitative and quantitative fashion. As such, we will very rarely be talking about the components themselves. So it offers us just one perspective on the whole system. It is an abstract modeling framework and things can get complex very quickly. So like all models it should only be used when relevant.

**Graphs**
A network in mathematical terms is called a graph. A graph is made of nodes and edges. A node is a thing, like a bank, business or country. An edge is a connection between two things, like the trade of oil between two countries, an investment between a bank and business, or purchase between a retailer and a customer. Both nodes and edges can have values associated with them that denote the size of the node or the volume of exchange within an edge. Edges can be directed or undirected, indicating the net flow of resources along the edge. In a multi-graph, we can have many different edges between any two nodes. For example, each edge might represent the trade of a different good between two nations. This is the very basics of the language of graph theory.
Because network science is all about connectivity, when we are analyzing a particular node in a network, such as a corporation within a supply chain network, our first question will often be how connected is that node, that is to say, how many links does it have with other nodes in the network? This is called its degree of connectivity. The node’s degree of connectivity will define how likely it is to receive whatever is flowing within that network. If the corporation was part of a supply chain network for the production of tractors, its number of links might define how many of the parts for that tractor flow in or out of the organization. Degree distribution will not be the only factor determining its significance within the network but it will be a primary one and the most straightforward one for us to measure.

**Importance**
How important a node is within a network is a function of both how much of the network's resources are flowing through it and how critical that node is to the network. So the Pearl Delta Economic Zone in Southern China, although only about 3 percent of the nation’s population, represents about 35 percent of the country’s total international trade. Thus, this node plays a very significant role within the economic network due to the sheer volume of resources that flow through it. Panama also plays a critical role in the global supply chain but this time it is because it is the only viable sea route between the Pacific and Atlantic. Thus, it is what is called a bridging link. It performs a differentiated function that the rest of the network requires, giving it significance within the entire network.

**Centrality**
A node’s real significance within a network, what is called its centrality, is quite a complex feature to analyze. Added to these two factors previously mentioned, we need to also take account of its location within the overall network, asking how close it is to all the other nodes, thus how quickly it could affect them and also how connected the nodes that this node connects to are.
As an example of centrality analysis, we might think about government bailouts during a financial crisis. As the government is interested in maintaining the functionality of the entire network, it needs to ask these questions that we have mentioned: How many links does this bank node have and what volume are those links? Does the node play some critical role within the financial network that no other institution could perform? How closely connected is it to all the other nodes and how important are the other nodes that it is directly connected to? By answering all these questions, they would be able to get some understanding to its importance in maintaining the entire network.

**Density**
When we are looking at the whole of a network, probably the single most important parameter is the system’s overall density. The density of a network is defined as a ratio of the number of edges to the number of possible edges. As we turn up the probability of there being a link between any two nodes, we will get a more dense network, starting from zero density where no nodes are connected to complete density where all nodes are interconnected.
We can then define a parameter for adding links, which is really capturing how easy it is for a node in the network to make a connection with another. We might call this transaction cost. When the expense of making a transaction is high, there will be few connections. As we turn it down, we will get the emergence of a denser network. For example, these transaction costs might represent trade barriers placing a greater transaction cost on international exchange. As we have reduced these trade barriers through liberalization, we have seen the emergence of globally integrated supply chains.

**Connectivity**
Network density is an important parameter in that it will define the difference between a component-based system at a low level of density, where the value of an element in the system is really in that node; such as a business or some technology, while it is relatively isolated, the value of it is bound within the organization. When we turn up the density and number of connections, this is no longer so. The component’s value is increasingly outside of it in the network of connections it has with other nodes, in the way that a smartphone has value because you can connect to many different services via the Internet, or a business has value derived from its place within a supply chain network.
Networks do not always grow in an even linear fashion. Due to the positive feedback of the network effect, we can get nonlinear exponential growth, as we have witnessed with the rise of the Internet, which stayed relatively dormant for a number of decades before reaching a critical mass and then growing rapidly. Now there is a huge amount of value not in any one organization but in the network of connections that gives one access to them. Thus, by reducing transaction costs low enough this can lead to a powerful network effect taking hold.

**Average Path Length**
A second key factor we will be interested in when analyzing an entire network is in asking how close are any two nodes in the network on average - what is called the average path length. This will be a function of both the number of nodes in the network, how interconnected they are and the overall structure of the network. Average path length is important because it defines how close agents are to each other. Agents operating in a system where they are very far from others will create different behaviors to when they have the appearance of being very close to everyone else. Here we might think about globalization, through increased connectivity that has reduced the path length, we suddenly start to feel much closer to everyone else, creating a much greater sense of interdependence. Because of these shorter path lengths, externalities become much more important and immediately perceptive.

**Multiplex Networks**
So far we have been talking about monoplex networks, meaning that with these relatively simple graphs we are looking at just one type of network; each node and edge in it only serve one type of function. But the real world is typically a lot more complex than this. When analyzing a large system like a metropolitan economy, a corporation or the global commodities market, what we are dealing with is a network that is embedded within many other networks. For example, a metropolitan area would be a complex system where economic interactions are embedded within socio-political networks, transportation, and geospatial networks, financial networks; all of which will strongly influence the flow and distribution of economic resources. This is clearly going to add a whole new level of complexity to our representation. But in order to do this, researchers have developed what are called multiplex networks. In a multiplex network, each type of interaction between the nodes is described by a single layer network and the different layers of networks describe the different modes of interaction. Multiplex networks are clearly much more advanced representations of how these systems really operate through the interaction of many different functional domains. They lay at the forefront of contemporary research in network science with a vast amount of untapped potential.

**Interventions**
Lastly, as we have tried to illustrate here, connectivity fundamentally changes the dynamics of an economic system. As such, it also alters how we should go about designing and managing them. At a low level of connectivity in a component-based regime, we traditionally try to intervene by directly altering the components in the system. For example, a government tries to improve its economy by starting a big infrastructure project; or we try to get people to buy things by bombarding them with advertisements. But with networks, it is all about designing and managing the connections. You get a person to buy a product by influencing their social network. Your country’s economy grows by connecting it to the global supply chain network. This is economic and financial systems design and management by connecting or disconnecting things. The wealth is in the network. If you want more of something, you restructure its connections and position within the network to make it more receptive to that flow of resources; if you want to diminish it, you disconnect it.

**Summary**
In this section, we have been looking at the basics of network theory as applied to economics. We talked about how connectivity is a very fundamental feature of a system, and once we reach a certain critical level of connectivity, things get flipped around and the focus becomes the structure and nature of this network of connections. We start to form a description of the nodes not in terms of their properties in isolation, but instead start asking questions like how connected is any node? How important is it to the whole network due to the volume of resources that flow through it, or its irreplaceability as it serves some differentiated function? We talked about the density of connections within a network being a primary factor when looking at the whole system, how this density is influenced by the cost of transaction. And when we reduce these transaction costs low enough, this can lead to a powerful network effect taking hold. Finally, we talked about multiplex networks that give us a representation of an entire complex economic system as a set of many interconnecting networks and talked about how our design and management approach will change given heightened connectivity.

**Economic Network Topology**

In the previous module, we talked about how the density of connections within a system is a key metric in understanding its behavior and overall make-up. Going from low connectivity to high connectivity really involves a regime shift within the system. One way of understanding this process of change is through what is called unbundling. When we get a reduction in transaction costs, a homogenous monolithic system can be broken up into small parts that are distributed out and then re-coordinated through this network of connections. This is a very deep and fundamental transformation to the system’s entire architecture. But during the process, it goes from being a bounded system to becoming a more complex distributed network.
For example, up until a few hundred years ago universities used to teach each individual almost all the technical knowledge that we had within just a few years. Students would then go out and apply this knowledge in some working environment. With the rise of modern science and engineering, this body of knowledge has become far too large and complex for any single person to learn. So we don’t go on trying to teach everything to everyone. At some stage, universities started to break all this knowledge up, that is to say unbundle it into different departments. Students now learn within specific domains of expertise. They then go out into the workplace and join businesses that function as the mechanism for re-integrating all this different knowledge and applying it to some set of tasks.

**Distributed Systems**
With the rise of information technology, the reduction in trade tariffs and proliferation of the free market ideology, this unbundling process is essentially what has happened to our economies over the past few decades. Factories, production process, services, national infrastructure systems, and even whole national economies, have through privatization and globalization become unbounded. Components are no longer bound within centralized structures, but are increasingly distributed out and coordinated through multinational corporations, global markets and the Internet. This is only set to continue as the Internet becomes an ever more important platform for production. We can outsource tasks and bring together teams from the other side of the planet in a few a few clicks. Today small businesses can build and orchestrate global supply networks online. This unbundling process is an important mechanism for dealing with a high level of complexity that monolithic systems are not designed for. It is central to dealing with the kind of volatile, uncertain and complex environments that large organizations find themselves within in the 21st century. This unbundling process is part of the significance of networks within post-industrial economics.

**Network Topology**
Networks are a very informal system of organization, which is in contrast to our more traditional formal organizations like hierarchies whose structure has to be predefined, and then the components fit into it. For example, we have different job roles in our business and employees have to fit into them. In these formal organizations, we would typically define the whole structure to the business before it starts operating. And once defined, it is temporarily closed, meaning anyone can’t just walk in off the street and take up a job in the business. We have to first decide that we need a new position, define how this position will relate to all the other positions, and then go through the process of finding and onboarding a new employee. This is the same for all of our industrial age economic institutions and systems of organization, from production processes to governments to banks. They are all well-defined formal closed systems with a top-down chain of command that are optimized for relatively static and stable environments.

**Informal**
Although this formal design may sometimes be the case with networks such as corporate IT networks, networks are typically not like this. They are typically informal. They are often user-generated, without a predefined formal structure. People, businesses, traders and other institutions just make connections whenever the marginal benefit is greater than the marginal cost. If we give people mobile phones, they will start talking to their friends. If we reduce trade barriers, companies will start trading across borders. If financial institutions can invest in high growth emerging markets with good return, then they will create these financial connections. This is the nature to networks. They just grow in an organic fashion wherever the transaction costs are low enough and payoffs are high enough. No one planned or designed or even really managed the networks that run our global economy on its many different levels.

**Sub Systems**
The density of connections within a network is rarely evenly distributed out. Whether we are talking about a social network or transportation network, some parts of the network will face higher transaction costs and will have a lower density of connections compared to other sub-systems that have a higher density of connections. For example, the transportation network of Nepal has a low density due to high costs of making transport connections within the Himalayas, while other parts of the global logistic network like the Netherlands will be densely interconnected. This will give us a heterogeneous topology to the network that will significantly influence how something will flow across it and how quickly or slowly resources in the global network will permeate into any specific subset.

**Clustering**
Key to modeling all of this is the idea of network clustering, which is an important factor in the overall topology to a network. When an agent comes to make a connection, the cost and benefits of connecting to different nodes will typically not be evenly distributed. For example, because of the regulatory framework, trading within Europe is easier between entities inside the EU than trading with a country outside of Europe. Due to this, the European economy forms a cluster within the global economic network, where the nodes in this sub-network interact more often and more intensely between each other than with other nodes outside of this sub-system and this is an example of cluster. This clustering will again give the network a heterogonous topology. And it is this topology that influences the flow of resources across the network, which is really the big question that we are interested in because it is going to define who gets what, that is to say the macro resource distribution pattern. If we remember the wealth is in the network, every component slice of the pie is in their access to the network.

**Market Clearance**
This is a very different vision to resource allocation. In our traditional paradigm, recourse allocation is all about equilibrium, the efficient market hypothesis. Markets always reach an equilibrium and clear. From the network perspective an equilibrium where all prices across the market equalize would be a perfectly homogeneous network, which might exist in very simple environments. But heterogeneity across the network is much more likely, particularly when we use multiplex network models to capture how markets can be affected by heterogeneity within other socio-cultural networks.
Going back to our previous example of the European economy, when the union was economy-integrated, people thought that the higher wages in Germany would reach equilibrium with low wages in the southern European countries. This hasn’t really happened though. The network has remained heterogeneous most likely due to its interaction with other socio-political and cultural clusters within the multi graph. This is a good example of the kind of complex multi-dimensional analysis that needs to be done in order to get a real picture for what complex economic systems actually look like. Saying that things will equilibrate is nice in theory and may work in practice if we are dealing with very simple systems, but often the reality of these global systems is one of a much more messy complex heterogeneous network.

**Informal Systems**
Lastly, as somewhat of a side note we will discuss informal economic systems. In economic analysis, we typically spend a lot of time focused on formal economic systems such as large corporations or national economics. What typically goes relatively unnoticed is the informal economy. For example in India, 84 percent of employment comes from the informal economy. There are 11.7 million undocumented immigrants in the USA all working in some capacity in the informal economy. AirBnB and car sharing services like Uber – all of these are still very much outside of our traditional systems of formal economic organization.
These informal network structures have developed in an organic fashion, wherever there was a need for an economic function to be performed that lay outside of traditional institutions, whether that be Mexican cartels supplying drugs to the US market or cheap counterfeit goods to Chinese. Network theory is a very appropriate tool to help us reason about these informal systems, how they develop, grow and interact with formal economic systems. And as we get this unbundling process of formal organizations that we discussed and the rise of networked organizations, the boundary between these two will likely become somewhat blurred.

**Summary**
In this section, we have been taking a look at network topology and how it relates to economic systems. We firstly talked about the process of unbundling, where heightened connectivity disintegrates homogeneous formal organizations as they become distributed out and re-coordinated through network. We talked about clustering as a key factor in overall network topology and how it gives rise to network heterogeneity, distinct subsystems within the network that will likely maintain it out of equilibrium. We finally mentioned how network analysis is an important tool for understanding and modeling informal economies.

**Economic Degree Distribution**

Degree distribution is one of the defining parameters in the makeup to any network. It is really a variable that is trying to capture the disparity between nodes that have a very high degree of connections and those that have a very low degree of connections. As such, it is really a measurement of inequality; looking at how equal or unequal the distribution of connections is within the whole network. This parameter is important because it is a key contributor to one of the major topological transformations within a network, a transformation that takes us from distributed networks that have a small degree distribution to centralized networks that have a very large degree distribution that is characterized by a power law.
One way to understand this degree distribution is that connections are rarely made at random. As with many other types of networks, agents within an economic or financial network will typically make connections based upon transaction cost; they will connect to other nodes that are easier to connect to and provide them with a high marginal return for the cost of making the interaction.

**Distributed Networks**
We will start by talking about a network with a low degree distribution, what we call a distributed network where the connections are distributed out evenly across all the nodes in the graph. Everyone has more or less the same amount of connections. Peer-to-peer markets are a good example of distributed networks. In finance, peer-to-peer finance matches many small lenders with many small borrowers. Car sharing services and peer-to-peer renting are other examples of peer markets that connect people directly, meaning everyone has a similar degree of connectivity although it may vary somewhat. Without any form of centralized hubs, distributed networks are typically user-generated. Nodes often have a high degree of autonomy and there is an overall low level of specialization. Everyone is doing largely the same thing, meaning it does not matter too much who you connect to. This low level of specialization also often makes distributed networks robust to attack. With low overhead cost and the capacity to couple or decouple from any other node in the network, they can be highly dynamic and flexible. However, without centralized coordination, they may not be able to operate as a coherent whole, putting them at a disadvantage to more centralized systems.

**Small World**
Most economic networks are not distributed like this though. Networks typically contain some nodes that are significantly more connected than others. One type of this kind of network is called a decentralized network, as we now have the emergence of local hubs. This means that many more nodes have, for some reason, decided to connect to one of these regional hubs. There are many reasons why this might be, but within economics one of them is economies of scale. By a number of agents or organizations combining their resources, they can obtain diminishing marginal cost through performing batch processing. Also related to this is specialization. By leveraging centralization, components can specialize in particular functions that can only be performed given a large enough demand. For example, we need to have a city of a large enough size before we are going to get a shop selling pianos.
Another benefit to these decentralized networks is what is called the small world phenomena. A small-world network is a type of graph in which most nodes are not neighbors of one another, but most nodes can be reached from any other by a small number of connections. For example, if one wants to transfer money to someone on the other side of the planet, one might go to their local Western Union center and they would send it to one of their other centers near to the person who is receiving the money. In a distributed network, this would have taken many links. If this was a large network it might have had to traverse thousands of links, but due to these local hubs, we get the small world phenomenon where we can easily reach any other node.

**Scale-Free Networks**
Although decentralized networks are ubiquitous in our world, even more centralized networks are just as common. Highly centralized networks represent a radically unequal level of connectivity to the nodes. Many nodes have very few connections and some have very many. These centralized networks are also called scale-free networks as their degree distribution follows a power law, meaning, unlike our distributed and random networks that had a normal distribution with most nodes tending towards the average degree, in scale-free networks, there are very many nodes with very few connections, very few with very many. Thus, the vast majority link into just one or few centralized mega hubs.
This power law relation is a more exact description of the Pareto principle, which has been identified in many areas, from the distribution of land ownership to that of wealth; where the richest 20% of the world's population control approximately 80% of the world's income. Or for example, in a financial context, power laws are also seen within stock market pricing and the interbank network, where the fat tail indicates that there exist few banks interacting with many others, giving us banks that are too big to fail.

**Preferential Attachment**
One plausible explanation to the dynamics causing the formation of these highly centralized networks is that of preferential attachment. A preferential attachment process is any of a class of processes in which some quantity, typically some form of wealth or credit, is distributed among a number of individuals or objects according to how much they already have so that those who are already wealthy receive more than those who are not. For example, these major hubs in scale-free networks can leverage significant economies of scale to reduce marginal cost of interaction and work to make them a default attractor for the formation of new connections.
These different network structures that we have outlined - distributed, decentralized and centralized networks - will all fundamentally alter the flow of resources through the network. In a distributed network, anything entering the system will be relatively slow to flow through it, given the high number of linkages needed to be traversed in order to get across it. Whereas in a centralized hub and spoke system, where every node can be reached in just one or two links, something can flow through it much quicker and more efficiently, but it will be dependent upon these major centralized nodes. With everything being routed through them this will create systemic risks; a few nodes that are capable of affecting the whole network.

**Summary**
In this Section, we have been taking a quick look as some of the major topological structures that we might get within an economic or financial network. We firstly talked about distributed networks like peer-to-peer markets that have a low degree distribution, making all nodes relatively equal with a Gaussian distribution to their degree of connectivity. We discussed decentralized networks where local hubs appear giving them the small world property. We finally looked at centralized networks that have a few major nodes that significantly alter the topology due to their very high level of connectivity that derives from a power law relationship behind these networked systems.

**Economic Network Dynamics**

Today in advanced economies, how to develop networks is of great interest to many, both in business management - as they try to develop new business models and products built upon connecting people and goods - and also very important for research economists and policy makers in order to try and understand how networks affect economic growth within post-industrial economies that are increasingly fueled by the networking of information and knowledge activities. Whereas much economic growth in the industrial age was driven by economies of scale that reduced the marginal cost of producing goods, in a network economy growth is driven more by the network effect. This is a very different model and it requires us to understand the dynamics of networks, that is, how they develop, which can be quite counter-intuitive.

**Network Dynamics**
The study of how networks form, grow and eventually disintegrate is a relatively new area of research, but it is, of course, critical to understanding how to foster the development of some types of networks and reduce the development of others. For example, researchers have studied innovation as a process of diffusion across a network. Research like this helps us to better understand how innovative clusters like Silicon Valley can be fostered in other locations, or inversely law enforcement agencies have studied the dynamics of terrorist networks in order to better understand how to disintegrate them. Thus, we are interested in both network growth and decay.

**Network Formation**
As we have previously noted, most real-world networks are not random. During their formation, they were subjected to certain environmental and resource constraints that shaped their formation as they developed in a particular non-random fashion. Added to this, most economic networks are user-generated. They have been formed out of local nodes choosing to make connections. Thus, both the local rules under which agents are making these connections and the environmental constraints they are under are both defining factors in the network’s formation. So if this is, for example, a trade network, we need to know what are the physical constraints and the socio-political constraints that are inhibiting the formation of the network, and inversely, what are the set of rules under which agents are choosing to make connections. So this can be modeled in game theoretical terms.

**Nonlinearity**
The growth of a network may be nonlinear, meaning there will likely be sub-linear growth up to a certain tipping point, and then positive feedback will kick in to give us super-linear exponential growth. In this way, something like the Internet can lay relatively dormant for a long time and then take off rapidly.
An important thing to recognize in the growth of a network is the fact that whereas the number of nodes in the network may grow in a linear fashion, as in one, two, three etc, the number of edges can grow in a super-linear fashion. With 1 node, we have 0 links. With 2 nodes, we have 1 link. With 3, we have 3 links. With 4 nodes, we can now have 6 links. With 5, there can be 10. With 6 nodes, we can have 15 possible links.
So whereas the number of edges started off lower than the number of nodes, it will likely sooner or later catch up with it and then outgrow it rapidly. In this example, the number of edges caught up with the number of nodes very quickly because we were talking about the maximum possible number of links, but typically in reality not every node will be fully connected, and thus it may often take a lot longer for it to catch up. But once it does, we will start to move from a component-based regime to a relational regime and the connections will add significant value to the system. We will get a positive feedback loop and the system may then grow exponentially. This is called the network effect. For example, the network effect can be seen in stock markets and derivatives exchanges. Market liquidity is a major determinant of transaction cost in the sale or purchase of a security. As the number of buyers and sellers on an exchange increases, liquidity increases and transaction costs decrease. This then attracts a larger number of buyers and sellers to the exchange. Thus, we get a positive feedback loop that is behind the network effect. In the remainder of this article, we will go over each stage in this network development process to try and understand it a bit better.

**Sub-Linear Growth**
In the initial phase of a network’s formation, due to the limited number of nodes and connections in the network, the value of joining that network may, in fact, be negative because of the opportunity cost. Joining this network may well exclude you from joining another more mature network that already has a lot of network value. For example, if you choose to adopt a Linux operating system, you will be limiting your capacity to interoperate with over one billion users of Windows. Thus, in terms of opportunity cost, you are actually having to pay to be part of this burgeoning Linux network, and the same would be true for a social network, digital currencies and many other types of networks that have not reached a critical mass. These early adopters are typically special interest users, what we might call "geeks" that particularly care about this service and are prepared to pay the opportunity cost. Thus, it is these early enthusiasts that really matter because with them the network may be able to reach the critical mass; without them, it may not. And reaching this critical mass beyond which the network effect will take hold is the key factor in the early formation of the network. A key parameter here is how much of the value of using this system is in the components vs. the connections. So if there is value inherent to the product without connecting it, such as would be the case for a washing machine, then early adoption is not very difficult. But other things are very much dependent upon their connections such as the telephone, where it will be very difficult to get the original users because there is no value in the system without the existence of others to connect to. The role of expectations is very important here, as if people don’t expect the network to grow they will not join and it will not reach the critical mass. If their expectations are positive then it may well reach this threshold.

**Power Law**
One thing to note here is that within the industrial model of economies of scale it is all about the mean, average user. Because people were not connected, there was no value in the network. There was only value in the individual. In order to scale, you had to focus on the mass of individuals, that is to say, the normal average person. The geeks and outliers were of no interest. We produced products, services, and advertisements for the average people in the middle. Everyone on the fringes just had to try and fit in. It was the dog that wagged the tail.
When we switch from the industrial model of economies of scale with isolated consumers to the post-industrial model of the network effect with connected users, this changes, as it is now the geeks and outliers that matter. Because of the thresholds and feedback loops, they are the ones driving the process of change. Thus, in networked economic systems, the tail is wagging the dog. Behind this is the power law distribution which is common to all kinds of complex systems because of nonlinear feedback that is able to amplify some small phenomenon on the fringes and turn it into a macro mainstream phenomenon.

**Tipping Points**
If enough nodes join the network, then we may reach the critical mass and get a tipping point. The tipping point is the critical point in the system’s development as it defines where positive feedback will gain traction leading to rapid and irreversible state change. The term critical mass is said to have originated in the field of epidemiology; where the spreading of an infectious disease reaches a point beyond any local ability to control it from spreading more widely. The term is in many ways analogous to a phase transition. Marketers use the term to denote a threshold that, once reached, will result in additional sales.
At the point of critical mass, the value obtained from the good or service is greater than or equal to the price paid for it. Beyond this, it becomes much more attractive for people to join as the value is continually going up as each new user joining creates a higher surplus value for the next prospective user. With this positive feedback loop, we can get the bandwagon effect where agents couple to the network without any intrinsic evaluation for, or knowledge of the actual phenomena, but simply join to gain the benefit of the network effect in the way that someone might adopt a certain ideology or fashion without knowledge of it, simply to be socially accepted.

**Peek**
The bandwagon effect can lead to over capacity, as the increasing number of users generally cannot continue indefinitely. After a certain point, many networks become either congested or saturated, stopping future uptake. Congestion occurs due to overuse. As an example, we might think about the telephone network. While the number of users is below the congestion point, each additional user adds additional value to every other customer. However, at some point, the addition of an extra user exceeds the capacity of the existing system. After this point, each additional user decreases the value obtained by every other user.
If this is the case, then the next critical point is where the value obtained goes back down to where it approximates the price paid. The network will cease to grow at this point, and the system must be enlarged to enable future growth. This is the case for centralized systems, but may not be the case for distributed networks. New peer-to-peer network models such as Bitcoin may always defy congestion. True peer-to-peer networks are designed to distribute out the network’s load amongst their users. This theoretically allows peer-to-peer networks to scale somewhat indefinitely, at least until market saturation.

**Negative Externalities**
But there is also a flip side to the network effect and network development, which is crowding out and the lock-in effects. Due to the importance of interoperability within network economies, there is a strong attractor toward everything converging onto the same network, the same set of standards or protocols resulting in lock-in. Network effects are notorious for causing lock-in with the most-cited examples being Microsoft products and the QWERTY keyboard. Going back to our previous example where the network effect created liquidity in a market, it is also apparent in the difficulty that startup exchanges have in dislodging a dominant exchange. For example, the Chicago Board of Trade has retained overwhelming dominance of trading in US Treasury bond futures despite the startup of Eurex US trading of identical futures contracts. Mitigating these negative externalities mean maintaining an open vendor-neutral network within which new standards and protocols can be incorporated. The success of the Internet is in many ways in its openness, net neutrality and the fact that no one owns it.

**Diffusion**
The rules under which a network was created and developed will play a large role in how something will spread across it and ultimately how robust it is to failure. The first thing to note with respect to network diffusion and robustness is that connectivity can both add and reduce to the system’s robustness. It works both ways. Connectivity is important for integrating the system and it is this integration that gives the system its overall robustness, but connectivity is also a potential pathway for disaster spreading. For example, in a recent paper entitled Systemic Risk and Stability in Financial Networks, one of their authors summarizes their findings as such: “We show that financial contagion exhibits a form of phase transition as interbank connections increase. As long as the magnitude and the number of negative shocks affecting financial institutions are sufficiently small, more ‘complete’ interbank claims enhance the stability of the system. However, beyond a certain point, such interconnections start to serve as a mechanism for propagation of shocks and lead to a more fragile financial system.”

**Failure Propagation**
Failure propagation within these complex economic networks might be financial as in this example or it might be within a logistic and supply network. Either way, there are a few key parameters that will greatly affect this process of spreading. Firstly, how contagious is the phenomenon that is spreading? An important consideration here is whether this is being powered by some negative feedback loop as is typically the case within financial markets where loss of confidence begets more loss of confidence. Secondly, how resistant are the nodes in the network to this phenomenon? So for a financial institution facing a mass of defaults, this resistance might represent how much capital they are holding. Thirdly, we need to consider the topology to the network; is it centralized or decentralized? Centralized networks are more susceptible to certain kinds of attack. This is one of the great benefits of distributed ledger technology. It reduces the current cybersecurity vulnerability of having large amounts of financial data within centralized repositories. Lastly, we need to also take account of whether this failure is being spread strategically or at random, as different network topologies exhibit different vulnerability characteristics depending on how random the failure is.
The study of network diffusion and robustness has become a hot topic of research since the previous financial crisis, as it has become clear that it was the network of connections between assets and liabilities on different balance sheets that caused the breakdown of the whole system and there is a strong correlation between deregulation of cross-border capital flows and financial instability. It has thus been recognized by many that trying to understand this opaque and dense set of connections is important to identify the system’s future robustness and failure tolerance.

**Summary**
In summary, we have been talking about network dynamics that look at how networks are formed and develop over their life cycle. We firstly noted that the formation of economic markets and institutions that are networked is very different in nature to our traditional industrial age model that is focused on economics of scale, the mass production of products that is focused on the average mean user in the market. In contrary, we talked about how connections can grow at an exponential rate, giving rise to a nonlinear pattern of development that requires a certain threshold to be overcome before the positive feedback loop of the network effect takes hold as the system can grow very rapidly. We talked about how this can lead to negative externalities of crowding out and a lock-in effect due to convergence. Finally, we touched upon the subject of failure propagation and looked at some of the factors involved in analyzing a network’s resilience.

**Economic Regulatory Systems**

In this module, we will be covering the topic of economic systems regulation, as we talk about two very different paradigms with respect to macroeconomic management. We will firstly outline the basic workings to our standard linear mechanisms of economic regulatory used within virtually all industrial age economic institutions such as the modern nation state. We will discuss how this hierarchical model is optimized for relatively simple environments and go on to look at the significant constraints encountered when implemented within more complex organizations. We will then go on to talk about an alternative model based on complex adaptive systems theory that involves distributed local level adaptation and self-organization.

Of course, this debate surrounding how to manage complex economics systems is not just an academic one. It is of great relevance to our world today. As we increasingly develop an integrated global economy, our traditional centralized linear approach to macroeconomic regulation – the bureaucratic state – is coming under increasing stress and showing its limitation in the face of these global networks, like the financial system, multinational corporations, all of which remain relatively unregulated on the global level. The recent financial crisis has shown how a simple free market approach to this may not be sufficient, and thus a key consideration going forward is how to regulate this global economic network in a more sustainable and secure fashion that limits their current negative externalities on society and the environment.

**Regulation Approaches**
There are essentially just two different paradigms in system regulation and management, a top-down method whereby we implement a centralized control system that constrains and coordinates the components towards some predefined objective, or we use a bottom-up approach where individual components are enabled to adapt to their environment locally and interact to enable global emergent coordination.

**Regulatory Systems**
A regulatory or control system within system theory and cybernetics is a specialized subsystem that is designed to regulate the operations of the broader system it is a part of in order to maintain homeostasis. Homeostasis means maintaining the system within a given set of environmental conditions that are best suited to its preservation and functioning. This form of centralized regulatory system should be very familiar to us as it is the default model to the industrial age management paradigm. It is used in all forms of economic systems in the shape of a hierarchy that is used to regulate most types of economic activity from a business to whole economies.
In order to do this, the regulatory system needs a few key components, firstly, some way of sensing and receiving information about the system it is regulating and the environment it is operating in. Secondly, it needs some model of the system and its environment and the capacity to use that model to generate new decisions based upon a variety of inputted information. Lastly, the regulatory system needs some mechanism for acting out those instructions. It needs what is called an actuator that will alter the state of the system in order that it conforms to the set of instructions.
A national government is a classical example of a centralized regulatory system within economics. It gathers a massive amount of data and statistics about the nation’s economy. It employs linear models derived from economic theory, forecasting and policy making to define the desired future state to the system, and then from this generates an output that is acted upon by a number of actuators, namely central interest rates, taxes, tariffs, subsidies etc. An extreme example of this centralized regulatory model would be a communist state like post-war China or Russia, where everything was controlled centrally and regulated through a top-down system. Policymakers made 5 year and 10-year plans, production and consumption quotas were set centrally and everything was expected to be aligned towards that same objective.

Centralized control systems have advantages and disadvantages, but essentially they are a linear model to regulation and they will thus be best suited to regulating simple linear systems within stable environments, meaning there needs to be a finite limited amount of elements in the system that have a low level of interconnectivity and limited capacity for adaptation, and ideally the system will be operating in a stable, predictable and routine environment. Under these conditions, centralized regulatory systems can be very effective due to their centralized nature. They are able to leverage batch processing and their inherent simplicity is also another very desirable feature. With these centralized regulatory systems, we can achieve very powerful coordination between the components that otherwise may be very difficult to achieve. But being designed to regulate simple linear systems, they will, of course, have their limitations. Not all organizations are simple linear systems.

**Limitations**
When we turn up any of the factors that generate complexity, this top-down model will start to become less effective. Centralized models are limited in their scaling, meaning they do not scale infinitely and will work best with a limited amount of elements. As we turn the number of elements up, we will have to develop more and more layers of the hierarchy as it becomes more and more abstract and removed from the actual system that it is designed to regulate. Information and instructions have to be routed farther and farther up and down the system through many layers of command and interpretation. This all places heavy administration costs on the lower levels and reduces the system’s capacity to respond quickly.
If we turn up the interconnectivity between the elements in the system, it becomes more difficult to control them through top-down channels. The hierarchical model is predicated on being able to control the components in the system. This will be most effective when the components are isolated and dependent upon the centralized system for instructions. If the agents are interconnected and able to receive information about each other and their environment, this gives them a much greater capacity to act autonomously. If we also give the agents the capacity to adapt, then this again will make them less dependent upon the centralized regulatory system for processing information, and again make it more difficult to control them.
Lastly, these large centralized organizations can only deal with a finite amount of volatility within their environment. New information typically has to be routed to some centralized unit before it can be acted upon and their static structure is not designed for change. Although these large centralized organizations may be good at dealing with small shocks, they may also be very vulnerable to systemic shocks or changes within the whole environment.

We should note that we do in fact often use this centralized regulatory system within complex organizations and environments, in the same way, that engineers use linear models to describe nonlinear phenomena through what is called linearization. We also do this with respect to economic management. We linearize the system or environment that we are trying to regulate in order for it to fit this model.
As the famous social scientist Herbert Simon once said: “If we want an organism or mechanism to behave effectively in a complex and changing environment, we can design into it adaptive mechanisms that allow it to respond flexibly to the demands the environment places on it. Alternatively, we can try to simplify and stabilize the environment. We can adapt organism to environment or environment to organism.”

Many of these economic systems are specifically designed and thus we can try and build them so that they fit in with our linear model even though they may be part of broader nonlinear complex systems. For example, when it comes to forest management we will typically plant all the same trees at the same time in straight rows. We do this in an effort to design a system that is manageable through linear methods.
This also aids in our capacity to model the system. Within a centralized regulatory system, someone needs to understand the whole system. The control is only ever going to be as good as our model, but for many of these complex economic systems like national economies or the global economy, we do not really have any models for them, so we create simplified models and then make the system fit into that model so that we can have some chance of regulating it.

But of course, simply linearizing a complex system doesn’t do away with its nonlinear dimension. All we are doing is shifting it outside the system, which means that whereas the system may become more linear, knowable and controllable, its environment may become more nonlinear and uncontrollable. Within these centralize regulatory systems that are driven to optimize, there will inevitably be a drive towards reducing the complexity within the system, that is, to continuously linearize the system in order to be more effective at managing it and directing it towards the perceived desired outcomes.
The result is that everything that is nonlinear and thus does not fit into the model is pushed outside of the system’s immediate context, meaning the system becomes more disconnected from its overall environment. As we continue to try and maintain the system within certain parameters through negative feedback, nonlinear positive feedback phenomena become externalized to the system’s environment. Thus, as the system becomes more linear and controllable, the environment becomes more nonlinear and uncontrollable.
The so-called Minsky cycle is an example of this in economics. The economic ‘Great Moderation’ that the developed economies enjoyed since the 80’s turned out to be the prelude to one of the largest nonlinear shocks to the system with the Great Recession. By using negative feedback to keep the system within certain parameters - and thus moderate it - we also externalized the nonlinear factors that eventually led to a massive collapse.

**Adaptation**
Although the linear model to regulation has in many ways proven successful in achieving short-term optimization, it is clearly not designed to deal with complex environments in a sustained fashion. In such circumstances, we need an alternative paradigm. The same factors of complexity that take us beyond the traditional model also enable a new method to economic management.
Effectively managed complex adaptive systems, like the Internet’s routing system, ant colonies or mature ecosystems, are regulated through the distributed interactions between adaptive agents. All of these features need to be present. Firstly, control needs to be distributed out to the local level. This means the components are given autonomy to act according to local information. We then have to invest in the component’s capacity for adaptation and information processing and we have to develop the protocols that facilitate interaction and communications between the agents so that they are able to synchronize their states and we get global patterns of organization. This is before anything about information, communication, and knowledge. Agents have the information about their environment. They have the knowledge they need to process that information appropriately and the method of communication so that they can coordinate with others and stay responsive to the environmental context. Interaction is an inherent organization mechanism. The more people interact and communicate, the more opportunity there it for them to differentiate their states with respect to each other, with the result being self-organization.
For example, in an ant colony, the queen ant does not tell all the other ants what to do, but instead, each ant responds and adapts its behavior to local information. Ants communicate with their peers through their exchange pheromones, and out of that exchange, we get self-organization, load balancing and the regulation of the whole complex system of differentiated parts.

**Capabilities & Limitations**
This regulatory paradigm will have its capabilities and limitations. On the positive side. Peer-to-peer networked systems like this are scalable to very many or possibly an infinite amount of components. As we do not have many tiers of hierarchy building up or bottlenecks around centralized components, interactions are happening in a distributed fashion and the agents are managing those interactions locally. Thus, we are not getting diminishing returns on scale. It is theoretically infinitely scalable. These networked organizations are normalized for complex nonlinear and volatile environments. Agents can respond immediately to local information. There is no master plan, no projection of what the future will be like. This is beneficial because in complex environments the future is fundamentally uncertain and the whole environment unknowable. The system is inherently nonlinear. There is no inherent drive towards linearization and it may be able to sustain high levels of diversity over time, which will add to its sustainability.

**Limitations**
On the other side, nonlinear organizations are not optimized for global coordination and throughput. Global coordination may well be very difficult to optimize, they will typically be far from optimal on the global level. Thus, these systems will typically - but not always - be outperformed within simpler environments. Nonlinear networked guerilla warfare is very effective within the complex environment of a jungle but in a battle that takes place in a very simple environment like a desert, command and control armies will be much more effective.
As always, complexity lies somewhere in between the two models of centralized top-down regulation and pure bottom-up distributed regulation. Linear regulatory systems are much better at exploiting known opportunities in simple environments. Nonlinear organizations are much better at exploring and surviving sustainably in volatile changing environments. An efficient and sustainable economic regulatory system would likely involve elements of both and solutions for integrating them.

**Context**
In this module, we have been talking about the difference between centralized linear regulatory systems and distributed nonlinear regulatory systems within economics. We firstly talked about the key components to a centralized regulatory system and looked at some of their competencies and limitations. How they are most effective within simple environments, involving a finite amount of elements with a low level of connectivity and limited change, and how they have a tendency to linearize the system and externalize complexity, limiting their long-term sustainability. Next, we talked about nonlinear forms of regulation, a bottom-up approach that invests in the agent’s capacity to adapt locally, thereby providing them with information, and communication with which to interact. They are able to self-organize and better respond in volatile and complex environments.

**Economic Resilience**

Economic resiliency is the capacity for an economic organization to recover from, adjust to, or maintain functionality in the face of negative internal or external impacts. The idea of economic and financial resilience has become a hot topic since the recent financial crisis. Research into the network analysis of financial systems has since shown a very high concentration and centralization of resources within a few core financial institutions, but the vulnerabilities go far beyond the financial system. There is a strong correlation between increases in capital flows across borders and economic volatility. As our global economy becomes more integrated with a freer flow of goods, people, capital, and services, small movements within global networks like commodity and money markets can have major implications for national economies. There remains an open question as to how do national economies integrate into these often-volatile global networks while ensuring their resilience?
In this article, we will be trying to identify some of the key factors involved in the resilience of an economic or financial network and we will talk about two very different strategies that can be taken when it comes to dealing with change effectively.

**Definition**
We will define resilience as the capacity of a system to maintain critical structure or functionality in the face of perturbation. This perturbation may be internally or externally derived. It may be small or large. It may be a short shock to the system or a prolonged incremental effect.
Economic resiliency would then be the capacity of an economy to stay functioning given some internal or external alteration. These critical functions might include such things as basic supply chain operations like delivering food, but also institutional functions, such as maintaining a stable liquid currency. Perturbations to an economic system might include such events as major internal social instability, external political or military conflict, natural disasters, or major alterations within the supply of critical commodities such as oil.
An economy is vulnerable to both internal and external factors. When we are looking at external factors, we are asking: What is the system dependent upon within its environment? How many different input types does it require, such as social capital, political regulation, natural resources, external financial services etc? The system’s robustness will be contingent upon how many input types there are, how volatile these inputs are, and finally, we also need to ask, what is the critical range of these input values? Is it very narrow, reducing the system’s robustness or very broad increasing the system's robustness. For example, how much can the price of oil change before it will significantly alter the state of the economy?

**Network Theory**
An economic system will only have very limited capacity to alter these external factors. Some it will be able to influence, many it will not. No one country can stop a global financial crisis. No one country can stop climate change. What an economy can do though is alter its internal configuration to make it less dependent on these external factors.
Internal to the economy, we need to consider both the structure to the network of interrelations and the properties of the components within that system. The structure to the interconnections and interdependencies can be modeled through network theory. The first factor we will want to analyze is the overall density of connections. At a low level of link density shocks will propagate slowly, cause and effect will have a more linear proportionality as limited connectivity reduces the capacity for positive feedback to take hold. The higher the density, the faster something can propagate across the system and the stronger the influence from positive feedback; meaning we can get the butterfly effect of a nonlinear disproportionality between cause and effect. Rapid failure propagation and the butterfly effect are the reality of heightened interconnectivity.

**Network Structure**
Another key metric to the internal network structure is its degree distribution and centralization. The economies of scale that has been a key driver in the development of industrial economies has created fragile networks that are dependent upon critical centralized nodes. This makes these centralized nodes “too big to fail” as their loss can potentially disintegrate the entire network. Just as these local and global hubs facilitate connectivity, they also facilitate failure spreading.
Within the industrial economic model these hierarchical centralized systems are the only real mechanisms we have for any form of advanced specialized organization, and thus whether we are talking about global cities or large corporations these large centralized systems typically correlate with a high level of specialization. Which is again another important parameter to the networks internal resilience. The criticality of a node is not just a function of its size but also how irreplaceable that node is, in more specialized networks where components are monofunctional - meaning we have more irreplaceable nodes - that will lead to a higher degree of overall network criticality. Distributed networks without centralized coordination mechanisms typically have to maintain themselves, components are often multi-functional, they often have a lower level of specialization giving the network a greater capacity to swap out any degraded components, small players can adapt and pick up the slack when the system receives a shock. There are many examples of this from peer-to-peer finance to community alert schemes and mesh networks of all kind.

**Strategies**
Next, we will talk about the strategies that a network can adopt in order to achieve robustness or resilience. In terms of resilience strategies that we may adopt, there is fundamentally just two: resistance or adaptation. Resistance is a strategy that involves aligning all elements in the system towards preventing change. Here we are aiming to build up a store of resources, such as liquidity, fixed capital or any form of redundancy, so that we can weather out some perturbation or any failures can be identified at their source and quickly removed by superior force, typically through a centralized regulatory system that is monitoring the whole operation. Walter Bagehot in his book ‘Lombard Street’ put it like this: “In wild periods of alarm, one failure makes many, and the best way to prevent the derivative failure is to arrest the primary failure which causes them.”

**Environment**
This resistance approach is aligned with optimization in that by becoming more efficient we can gain more resources and develop a greater capacity to resist change. Within such a strategy diversity is seen as a weakness. It reduces the system’s capacity to act in a coordinated fashion in removing any possible failures at their source. In such an approach, there is no distinction between the system and its parts. As the saying goes: “What is good for General Motors is good for America.” In such a model, major components such as corporations or financial institutions are the system and we simply can’t let them fail.
This strategy of resistance will be most effective within relatively simple environments. The aim is to become the biggest fish in the pond so that nothing will affect you. This will work in both quite simple and complicated environments as long as the whole environment is relatively stable.
In order to be able to resist change, the system needs to be in control all the time. As we previously mentioned in order for a centralized linear regulatory system to be in control it must remove disorder from the system. If it has a linear model of the system and environment it is regulating, it will try to linearize the system in order to have greater control and robustness. To the extent that the control process and the model that guides this process is accurate and reliable, control itself delivers stability, robustness and the capacity to resist change, which is one method of ensuring critical functionality and the system’s preservation.

**Adaptation**
In more complex environments, where any one component is just a small fish in a big pond, this strategy will have its limitations. In such a context the whole landscape may change and no component within it will be able to resist a systemic shock. Here we are going to need a different strategy, that of adaptation.
Adaptation is the capacity of a system to change its state in response to some change within its environment. Resilience through adaptation means being able to generate a variety of states depending on the context. Because the system needs to exhibit different states at different times, there needs to be some differentiation between the system’s core function - that will remain invariant - and the different states that it will generate depending on the context - which will have to change. This is different to our previous model where the system was simply the set of components, in particular, the large dominant nodes that were too big to fail, because they ran the organization. With adaptation in contrary, because the system has to change and adopt new states depending on the context, any component in the system has to be disposable. In this model, the system cannot be dependent upon any instance of its states but is capable of letting them go and generating new ones as the context changes.

**Disposability**
As such, this adaptive approach to resilience is concerned with the maintenance of core functionality rather than the preservation of specific system’s components. Unlike in our previous model where we were trying to stamp out any small disturbance at its source, with adaptive resilience we are saying quite the contrary, that the system needs disturbances in order to maintain and develop its adaptive capabilities, which is ultimately the only thing that is going to ensure its long-term survival within a complex environment. Without disturbance, components become fixed into a specific configuration that will reduce the system’s capacity to let them go and generate different configurations as needed to adapt. A corollary to this is that when the system is left static or without significant perturbation for a prolonged period, components will become increasingly tightly coupled in order to reduce friction and cost of transactions. As the network becomes more tightly coupled, the important buffers that mitigate failure propagation are reduced. This is all summarized in Hyman Minsky’s main insight that “stability is destabilizing.”

**Disturbances**
Because of all of this, the adaptive approach focuses its interventions more on adapting to major disturbances, whilst allowing small and moderate disturbances to run their course. This approach would avoid stamping out the disturbance at its origin and focuses its attention on reducing the wider impact of the disturbance on the macro economy. But equally, the system can only deal with so many shocks of such a large magnitude. If they become too great, they will damage the network’s critical functionality and its capacity for sustainable development.
This is most clearly expressed within ecology by what is called the intermediate disturbance hypothesis, IDH for short. IDH is a non-equilibrium model used to describe the relationship between disturbances and species diversity within an ecosystem where diversity is correlated to the system’s long-term resilience. IDH posits that local species ‘diversity is maximized when ecological disturbance is neither too rare nor too frequent. At high levels of disturbance, due to for example frequent forest fires or human impact, all species are at risk of going extinct. At low levels of disturbance, competitive exclusion increases leading to a decrease in species diversity. Thus, at intermediate levels of disturbance, diversity is maximized.'

**Order & Chaos**
Adaptive resilience is seen to exist at an interplay between order and chaos, what is called the edge of chaos. Whereas the resistance strategy will work best in orderly and stable environments, adaptive systems are normalized for operating within volatile and semi-chaotic environments, what business management calls VUCA environments, standing for volatility, uncertainty, complexity, and ambiguity. VUCA is a key characteristic of the 21st-century economic environment due to a number of factors, such as technology disruption and environmental change.

**Diversity**
An adaptive strategy also comes with the cost of maintaining diversity. There is a core tradeoff between diversity and efficiency. Diversity requires components that occupy heterogeneous states. Efficiency requires synchronization and coordination between components. This is most easily achieved by homogenizing the states of the components. Thus, a resistance strategy will aim to reduce diversity and linearize the system, which may be a good strategy if it works. However, it also makes the system brittle, as we are creating a strong impermeable boundary condition to the system that once broken means the lack of diversity within the system will allow for some failure to easily propagate, making it more susceptible to positive feedback loops and systemic shocks.
An adaptive strategy is predicated upon diversity because with diversity components are occupying heterogeneous states, meaning we will get negative feedback as different states balance each other out. This negative feedback makes the system less vulnerable to rapid failure propagation driven by positive feedback.

**Degeneracy**
The effectiveness of diversity as a strategy for resilience and long-term sustainability is not always a function of the sheer scale of diversity - that is to say the number of different states that the components occupy - but also a function of maintaining weak ties and suboptimal marginal components. For example, species within ecosystems that often have only a weak role to play on average, tend to have a strong and important function in maintaining resilience during times of stress. Thus, we need to focus not just on the keystone components which are important during normal functioning, but also on those components at the fringes of the system, and this may be even more the case when these perturbations are large nonlinear black swan events. Adaptive resilient systems then need to maintain what engineers would call degenerate components, components that are lacking some property, order, or distinctness of structure that is usually present. These degenerate components are typically the ones that are first removed when optimizing a system through linearization because they are very clearly suboptimal when the system is operating at its normal equilibrium state, but only become relevant during non-normal states when the system is being tested by a perturbation.

**Opacity**
Within complex networks where agents have the capabilities to create connections at their own discretion, we do not always know all of the linkages. If the system is configured in such a fashion that it is in the agent's interests to conceal their interactions - as is often the case with financial networks and particularly the case with hedge funds and other forms of shadow banking that are not formally regulated - then this opacity can be a major issue in terms of managing resilience. Complex networks like our global financial system and global supply networks have many interdependencies that we are not aware of. These hidden interdependencies typically only get revealed by shocks and failures. The more opaque the system, the lower our capacity to receive critical information about it, thus debilitating our capacity to use a centralized regulatory system in order to manage it. At some critical level of opacity the system becomes unmanageable through a centralized regulatory mechanism because we can no longer sense it properly and receive the critical information required to manage it in a top-down fashion.
Information is central to enabling distributed adaptive regulation. An information and networked economy is one built on data and open platforms. This means developing technical solutions for scrambling and anonymizing sensitive data into aggregate volumes that can be mined through advanced analytics to identify and preempt critical patterns. This is essentially part of the success of the Internet as an open platform where transparency and sharing of information are an attractor.

**Summary**
In this section, we have just touched upon the important subject of resilience within economic and financial systems, a topic that would appear of great relevance to our world today. We firstly talked about some of the internal and external factors affecting an economic system’s robustness including its dependency upon some set of input values from its environment, how dense, centralized and specialized its internal network structure is. We went on to identify two different paradigms when it comes to dealing with change – resistance and adaptation. With resistance, we use a centralized regulatory system to optimize the organization towards its maximum capacity in removing all potential failures and resisting change. An adaptive strategy in contrary involves maintaining diversity within the system so as to be able to generate an appropriate response to any given change, this approach being best suited to dynamic and volatile environments.

**Economic Fitness Landscape**

In this section, we will be looking through the lens of complex adaptive systems theory. In order to try and interpret the macro dynamics within an economic system, we will firstly introduce you to the idea of a complex adaptive system before going on to build up a model to their dynamics, what is called a fitness landscape, a three-dimensional state space for representing the whole system’s macro topology. We will talk about how this topology changes depending on the complexity of the environment and some of the strategies that agents use within these different environments.

**Complex Adaptive Systems**
From the perspective of complexity economics, a macro economy is a complex adaptive system, that is to say, that it is composed of many interconnected autonomous parts that are capable of adaptation. Other examples of complex adaptive systems include flocks of birds, ant colonies, the human immune system, the Internet’s routing system, cities and all forms of social organization, from financial markets to political regimes.
Complex adaptive systems are highly dynamic. They are typically high-energy systems. They import a lot of energy in order to maintain a dynamic state far- from-equilibrium. In physics, this is what is called a dissipative system. They import energy and dissipate it in order to maintain this dynamic non-equilibrium state. A flock of birds would be an example of this. Because the components have a high degree of autonomy and are capable of adaptation, this means that control is primarily distributed out to the local level. The overall state of the system is a product of the interactions between the agents. Agents are acting and reacting to each other’s behavior, like businesses competing in a market or traders buying and selling in a financial network. Out of all these actions and reactions, we get the overall state of the system.

**Fitness Function**
We can model these interactions in game theoretical terms. An agent is involved in interactions of both competition and cooperation with other agents typically within its local vicinity, but also possibly globally throughout the system. Thus, an agent is involved in both zero-sum games of competition and some positive-sum games of cooperation, and may be involved in both at the same time, what is call Coopetition. For example, some companies share and collaborate in research and development projects but then compete in the market. Within this environment, agents are trying to improve their functionality or payoff according to some set of metrics. This may be called the fitness function; a simple parameter that defines how efficient that agent is at intercepting and transforming the resources available within the system. For example, this might be how much work does a company get and how good is it at turning it into net revenue, or how competitive is a country within the global economy, or a trader’s strategy within a market, or the risk-return ratio on a portfolio. All of these could be defined according to a single metric and compared across the different elements in the system, this single metric we would call the fitness function. Likewise, we might model the system according to a second set of parameters as to what function an agent within the system performs. For example, we would model economies according to industrial sectors where companies that perform similar functions are grouped into the same industry.

**Adaptive Landscape**
Once we have this set of parameters, we can use them to create a 3-dimensional model, a kind of state space, that is to say, any single point in this 3-dimensional space will be defined as a state to one of the agents. The two axis that define the horizontal plane will capture the agent’s function. Agents that are in proximity on this plane will then perform similar functions. This might be businesses in a similar industry or countries with similar economic profiles or financial institutions that operate in similar markets. The agent’s elevation within the space will then be defined by the fitness parameter. The higher they are up on the vertical axis the more effective they are, and thus the higher their payoff.

**Explore and Exploit**
Thus we have a full landscape and agents are now placed in this landscape; they are able to adapt and they are trying to move up to higher elevations with higher payoffs. On the most basic level, agents face a dichotomy in their choices. They can either exploit their current position or they can invest resources in order to try and find some more optimal payoff, that is to say, a higher elevation. For example, a person can stay in their current job, with all of its security of salary, or invest their time and resources in finding a new one that might be better, or a business can stay exploiting its core competencies giving out high dividends to shareholders or invest in moving into new markets. Of course, agents may do the two in parallel but if we want to come up with a single value we can simply subtract the resources used for consumption versus those used for investment to get a gross positive or negative value.

**Linear Systems**
The strategies and choices that agents make will be dependent upon the type of landscape they are acting upon. Different economic environments will represent fundamentally different topologies and thus different strategies. The topology to the landscape will be defined by the type of system we are dealing with; starting with a very simple linear system and going to a very complex dynamic system. In an isolated linear system - without interconnections and interdependency between components - the topology will be very simple, a single dominant peak in the center of the topology representing the fact that there is one single optimal equilibrium. An example of this might be a hierarchical organization where there is one clear optimal position within the entire organization. A monopolistic market might be another example. There is one clear well-defined optimal position within the landscape. As long as we are dealing with a closed system and there are no interdependencies, it means that the landscape is not going to change. Given the example of a hierarchical organization, an agent can then adopt a very simple rule – stay trying to get promoted upwards until you get to the top and then stay there.

**Complexity**
Now we can turn up the complexity by allowing for many agents with many interactions and interdependencies between them. When we have many different interdependencies, an agent’s payoff will be dependent upon the interactions between a number of different parts. Take for example a competitive market. How well a given organization performs in the market will be dependent upon many other actors. Because there are many interacting parts, there will be many different optimal solutions giving our topology a rough form with many different peaks, with any one of these many peaks representing a particular combination of all the organizations in the market. Some will be better than others but there will always be many different local peaks representing all the different combinations we might have.

**Adaptation**
If we go a step further and allow the agents in the market to adapt, then as the agents adapt and change their state, this will change the payoffs for other agents, with the net result being that the whole landscape will start to move up and down. This is a lot more representative of a real-world complex adaptive system, like a competitive market, where a business faces a number of different competitors who are all altering their behavior and strategies over time.

**Open Systems**
Lastly, if we want to try and capture the true complexity of a market we would have to recognize that this whole macro system does not exist in isolation. It is, of course, embedded within a particular social, environmental, technological context, all of which are providing the system with a set of input values that define the overall landscape. When one of these input values changes, for example when a new technology comes along or a change within the political regulatory environment, then the whole landscape will change. This can, of course, be minor changes that are happening on a continuous basis, or major and abrupt transformations. It might be a major transformation in the political environment, such as that experienced by the Russian economy with the fall of the communist regime, or the current major technological disruption brought about by the rise of the Internet.
During such a time it is no longer so much the interactions between the agents that define the topology, but now these input values to the system, as the agents become subject to the process of evolution that is acting on all the agents in the system as the whole environment changes.

**Strategies**
The strategy that agents adopt will depend fundamentally on the environment they are acting within. As mentioned, within a very simple environment that is closed, static without interdependencies, the agents only need a very simple rule telling them to stay going upwards. As an example, we might think about the former communist economy of Russia where the government would tell a company to simply produce as much of a product as possible with as little resources as possible. Within such a context you do not have to worry about competitors or the landscape changing, and thus there is no need for adaptation. All that is needed is a very simple optimization algorithm with a single equilibrium.

**Environment Complexity**
If the environment involves many interdependent parts - such as companies trying to optimize the stock and transportation routes within its supply chain - then the problem becomes more complex. It requires significant investment of intelligence and computation. The agents need to stay trying different solutions, that is to say exploring the landscape going up and down on different local peaks, but gradually over time reducing the number of resources spent exploring - this is a very simplified explanation of what is called a simulated annealing algorithm. Because everything is held static, an agent can afford to make this long-term investment of resources trying to find one of the optimal solutions as it will be able to, then exploit this for some time in the future due to the static nature of the problem.

**Adaptation**
Within topologies that are moving up and down due to different agents acting, reacting and adapting to each others behavior, agents have to stay constantly balancing exploration with exploitation. That is to say, unlike our previous example where after some time the agents settled into a stable state, within these more complex environments agents have to stay adapting indefinitely. If they stop exploring, they will slowly fall behind as others exploit the new opportunities. Likewise, the landscape will never really settle down because as soon as it does approach stasis, this will create an opportunity for some agent to act and then again some other agent to act as the whole topology becomes re-animated.

**Evolution**
Lastly, when the change is systemic and coming from outside of the system - with little that agents can do to affect this environment - then the agents are no longer competing with each other but this is now a form of evolution. The whole environment is changing and performing selection on them. They have to be able to adapt to that environmental change. This requires a whole different level of adaptation. It is no longer a question of just responding to immediate changes, but the agents may need to change their whole functionality in order to maintain their fitness. For example, the advent of the Internet has brought systemic change to the publishing industry. Newspapers are now less competing with each other and are more competing to maintain relevance within this new environment. In order to do this, they need to be able to reinvent themselves on a whole new platform, under a whole new set of rules, as the whole environment has changed. This does not just test their capacity to adapt to a normal market environment because this will not be sufficient to reinvent the whole organization, instead, this evolution in the industry tests their degree of diversity. It is only out of maintaining some pool of diversity that an organization is best suited to developing new solutions in response to systemic changes within its environment.

**Trade Off**
From this, we should note that the transition from an agent or organization operating in a simple environment to a complex environment should map onto this parameter of exploring and exploiting. In simple environments, agents are primarily exploiting through optimization. In complex environments, they are spending more time investing and survival is always some interplay between both. Exploring and exploiting are very different activities that require a very different type of regulation and management.
As the venture capitalist and writer Peter Cohan puts it: “The exploit business focuses on cost and profit, spurs efficiency improvement and incremental innovation, is strong at operations, has a formal structure, controls for margin improvement and productivity, values efficiency, quality, and customers, and leads in a top-down manner. By contrast, the explore unit focuses on innovation and growth, spurs new products and breakthrough innovation, is strong at entrepreneurship, has a loose, adaptive structure, controls for milestones and growth, values risk-taking, speed, and experimentation, and leads in a visionary and involved manner.”

**Regulation**
From this it should be clear also that how we try to regulate an economic system will change fundamentally depending on the complexity of the system and environment we are dealing with. Within a very simple context, we can use simple top-down regulatory systems with basic linear optimization algorithms. However, when the environment becomes more complex, these top-down regulatory systems may not be the best solution, as components need autonomy to stay adapting locally and we increasingly need to maintain and develop diversity in order to ensure sustainability. In such a context, more distributed forms of regulation are better suited. A core challenge for a large organization like a macro economy or corporation will be in how to integrate these very different paradigms in regulation and be able to switch between them.

**Summary**
In this section, we have been talking about complex adaptive systems as a framework for modeling economic organizations. We have tried to show how complex adaptive systems can be mapped into this more formal model of a state space, that is used in mathematics to describe dynamical systems. We looked at the different types of topologies to this adaptive landscape, going from simple linear systems with a single equilibrium and single optimal peak, to more complex environments involving many interacting variables creating a rough topology. When we added adaptation to this, we got a landscape that was moving around in response to local interactions. We talked about how when we allowed for the system to be open we can get systemic transformations as the whole topology changes due to new input values from its environment. Finally, we talked about the different optimal strategies given these different environments, going from simple optimization algorithms to more complex strategies requiring continuous adaptation and maintenance of diversity.

**Evolutionary Economics**

In this module, we will be covering the topic of evolutionary economics, a paradigm in economic development that interprets the growth of economies through the model of evolution. We will be firstly talking about our traditional approach to economic development before going on to give an outline to this process of evolution as it acts on economies through the production of variety, adaptation, and selection. Finally, we will discuss how this gives rise to economic systems of greater differentiation and integration as they develop over time. Evolution is a major theme within complexity theory, having just one lecture on its application to economic theory means we will only get to touch upon some of the most important factors of consideration.

**Context**
Ever since the end of the colonial era and the birth of many new developing nations around the world, the question of how economies develop has been of major interest to both policymakers and economists. Since that time, we have seen some countries like Mali make little economic development while others such as South Korea have grown rapidly to become advanced economies. During such time we have also been through many different theories surrounding how economies grow and how best to manage their development. Today with the integration of our global economy this question of why some countries develop rapidly while others remain stagnant has moved to the forefront and it remains very much an open debate within economics.

The first thing that we should recognize is that the question of economic development is, of course, a very complex one in that it involves many factors that are traditionally outside of the domain of economics, socio-political, environmental, historical, cultural and so on. This is even more so than in any other area of economics. As we cover in a related article, there is really just two fundamentally different paradigms to economic management; top-down centralized regulatory systems and distributed adaptive networks. Each of these very different paradigms to economic management is going to give us a very different vision of what economic development is and how it should be conducted. We will firstly talk about our standard approach to make it explicit, before going on to talk about the evolutionary approach.

**Linear Model**
Within the centrally regulated paradigm to economic development, a model of the system and its future environment is created - we define a future desired state and directly coordinate the components within the system towards achieving this end typically through some set of incentive systems. The aim is to maximize throughput. Within a macroeconomy, this gross throughput is captured by the metric of gross domestic product, which is seen to be the primary metric to an economy’s state of development and the key parameter that we are trying to optimize for.
This paradigm to economic development found its most clear theoretical expression in the so-called linear-stages-of-growth model, which posits that there are a series of five consecutive stages of development which all countries must go through during the process of economic development. The primary objective of developing nations was then seen to be in controlling and guiding nations through these successive stages. This model has had both its successes and failures, even within the same country. For example, China’s great leap forward project was one of its greatest disasters, but China has also used the same centralized regulatory model over the past 20 or 30 years to what might be described as a success.

**Post-Industrial Economies**
This centralized model is of course in its basic structure a simple linear model to economic development, and linear models work best in simple environments, meaning it may be relevant to the earlier stages of economic development - that is to say when the economy is going through agrarianisation and industrialization - but whether it is an applicable model for the development of post-industrial, information and knowledge economies is an open question. The end of industrialization within advanced economies is witnessing the rise of a new form of networked IT enable economy. People and small organizations now have powerful tools for information processing in their hands. They are connected like never before into global networks that often bypass centralized regulatory systems either partially or fully, and they increasingly have unfiltered access to the world’s store of information and knowledge.

**Evolutionary Development**
It is only really within this context where we have an absence of top-down centralized regulation and agents with the capacity to interact and adapt locally that the process of evolution can play out. Without a centralized regulatory system, the components are not held in some predefined configuration. There is no one overseeing the whole system, no predefined trajectory and most importantly there is no goal to the whole enterprise; there is nowhere to get to, and this is a very radical idea because we are very much grounded in a linear conception of economic progress. Evolution is not like this at all though, it is very simply about adapting to the environment and with complex systems that are operating in volatile and uncertain environments, this is the best that we can hope for. The idea that we can know and control the whole system, know the environment, know the future state to that environment and align the whole system towards reaching some optimal state is a virtual impossibility. It is a legacy of having previously operated within a much simpler environment. It does not really work in complex systems, and evolution, although far from optimal is the appropriate paradigm.

Whereas adaptation is a micro level phenomenon - in that it describes how an individual agent can change in response to some change within its environment - evolution is essentially the same process of adaptation but it plays out on the macro level; describing how a whole population of agents manages to adapt to their environment. It is not an immediate process. It plays out over the course of many life cycles to the system. These life cycles can be quickly iterated upon to get a rapid pace of development but it is more often associated with a long-term process of change within large complex adaptive systems such as ecosystems, technology infrastructure, cultures, all kinds of social institutions and of course, economics.
With an evolutionary process information is being received continuously by the agents and strategies are being updated in a distributed fashion all the time. During this process of change, we get coevolution and novel niches emerge. These niches might be new markets, new technologies, new behaviors or new institutions. The very act of filling a niche may provide new niches with the result being ongoing change and constant disequilibrium. Just as the process of adaptation requires a dynamic between order and chaos, so does evolution. As Schumpeter illustrated it is a process of creative destruction. We are trying to maintain the function and pattern to the overall system, but any component or set of components are equally composable and decomposable.

**Stages of Evolution**
There are a number of key elements that are required to be present before the process of evolution can act on a system. Firstly, the system must be able to generate some form of variety between its constituent elements, which is typically done through some form of cross mixing between elements. Secondly, components must be exposed to the operating environment and capable of acting autonomously in order to express their distinct properties or functionality. Lastly, there must be some form of selection mechanism that is able to act objectively in evaluating the effectiveness of the different elements within that particular context; retaining those that have been effective while disposing of those that have not. This process then has to be iterated upon over the course of a number of life cycles before change appears. But through this process of evolution, systems develop to become both more differentiated and integrated, which allows them to operate in a broader, more complex environment in a more sustainable fashion. By altering the mechanism through which this process of evolution operates on a system, we can speed it up or slow it down, perform it effectively or ineffectively. We will go over each of these stages to the process of evolution within economic systems as it acts both on the real economy of products and services but also on the institutional level of businesses, financial organizations etc.

**Variety**
The initial stage in the process is about producing variety. Within biology, this is achieved through the deformation of DNA and cross mixing of genes, illustrating that the creation of new variants can be both random as well as intentional. Of course, producing new products and services at random would give us a combinatory large number, that would be unfeasible. Through our capacity for imagination and design, we are able to reduce this number down to a small subset, and of course, most novel innovations are not novel at all, they are simply remixing pre-existing solutions. The paradigm of economic evolution is focused on the non-equilibrium processes that transform the economy from within as an ongoing continuous process; like with natural evolution, it is very difficult to make major leaps. Although whole paradigm shifts may occur, they are rare. We are typically drawing upon some preexisting set of solutions and remixing them in new ways. Evolution is typically a slow step by step process.

Enabling this process means developing open platforms that enable diverse variants to interact and cross mix. For example, the rise of the Internet and YouTube has put all our music on the same platform right next to each other, the result being a great acceleration in the production of mash-up mixes between all types of very disparate music; many of which do not work but some do. Co-working and business incubators are based on the same idea of having an open space for the interaction between disparate activities, ideas, and expertise, to enable cross-pollination.
For this reason, it is important to maintain a stock of diversity within the system for the sake of innovation, but this is not the only factor. We also need to create and foster weak links between disparate domains so that we can get greater diversity of cross-mixed variants, and the diversity between these variants will be less superficial. Inside the box innovation happens by getting lots of intelligent people to focus on a problem in a lab. Real outside the box innovation happens in the real world where there are lots of weak links between disparate domains. This is less the source of innovation and more the source of innovability, which refers to the system’s ability to generate disruptive, qualitative and fundamental improvements, which enables it to undergo transformational change.

**Adaptation**
Next, these variants need to be put into their operating environment. In order to adapt, they need to be fully exposed to that environment but given sufficient time and space to develop and exhibit all of their capabilities - this may take time. It takes time to develop a new product in a market or a new industry within an economy. If we think about evolution within ecosystems, new creatures are typically fostered for a prolonged period before being exposed to the full requirements of survival. A new agile approach to product development called MVP, standing for minimum viable product, is one approach to this process whereby new very basic solutions are rapidly developed and are deployed as soon as they have the minimum requirements to function within their operating environment. In this way, we can start to receive immediate feedback as to the system’s viability and possible future trajectory without the need for significant investment or foresight.
But all variants ultimately must be exposed to the same environment in order to see how well they perform, although the traditional narrative surrounding evolution is one of competition, a vision of everyone against everyone else, but this is only really true in very simple relatively isolated environments. Most products, services, business or individuals within advanced economies fail or succeed within that environment, based not only on their own capabilities but also on their capacity to interoperate and coordinate with other systems. Within environments of heightened interconnectivity, this capacity for interoperability is very important.

**Selection**
Lastly, selection has to be performed on the set of elements based on their functionality. Ultimately, all products, services, and economic institutions have to serve some function for someone who is prepared to pay for it. In that act of paying for it, they make a vote within the process of selection and that process really plays out on millions of different balance sheets across the economy. Every time we cast our vote for a product or service, we are tipping the balance in favor of its continuing to exist, while the balance of all the other products on the shelf that we did not select is very gradually tipping in the other direction. In that simple act of choosing, some product or business has lived on to become more prevalent within the next life cycle to the system while others have come closer to being discontinued and thus becoming less prevalent in the future. In such a way the whole system adapts to its environment, without anyone saying that we should switch from typewriters to computers because they believe there is an Information Age around the corner. The whole system has still managed to figure that out in a distributed fashion without anyone predicting the future or guiding the whole process.

**Differentiation and Integration**
Although the evolutionary method of development may not have some fixed goal, that is not to say that it does not result in long-term systemic transformations - quite the contrary, in fact. It is through evolution that a system goes from being simple to becoming complex. Simple systems can just pop in and out of existence, but complex systems like our global economy are built through a prolonged process of evolution. During that process, they become both more differentiated and integrated, and this is essentially what complexity is, a system that is both differentiated and integrated. This complexity then enables the system to operate in a more advanced, broader environment. This process within economic development is best illustrated with reference to the theory of economic complexity.

**Theory of Economic Complexity**
The theory of economic complexity postulates that the key to prosperity is in both accumulating individual capabilities and the capacity to aggregate those capabilities through networks to create complex products within a diversity of industries.
It starts with a recognition that underdeveloped economies know how to make only a few things while developed economies know how to make many. "Know how" is defined as an individual’s competency to perform a task. Collective know how is the capacity to perform tasks that cannot be performed by an individual. They are team efforts. No individual can play a symphony, produce a laptop or make the trains run on time. In pre-agrarian societies, an individual knows almost as much as the whole organization knows. But in advanced economies, we are able to make more things that are more complex because we all have different knowledge and we are able to create networks for integrating them into coherent functional organizations. The more individual differentiated capabilities we have and the greater our institutional capabilities to integrate them, the more complex the products and services we can make and thus the more advanced our economy is.

**Summary**
In this module, we have been talking about evolutionary economics as an alternative paradigm to economic development that is focused on the internal dynamics through which the macroeconomy generates novel phenomena and changes over time without the guidance of some centralized regulatory mechanism. We talked about this process as a product of a number of key stages, including: Firstly, the generation of variety through cross mixing and invention; secondly, adaptation, whereby products and services are exposed to their operating environment in order to reveal their functionality; and finally, selection whereby functional variants are selected to become more prevalent within the economy’s future life cycle. Evolution is ultimately a search mechanism, the means through which a complex adaptive system searches for the appropriate solution to the challenges of operating within a given environment. Through this process, the whole system develops to exhibit greater complexity and becomes capable of operating in a broader environment.

A Complexity Labs Publication
Curated by Joss Colchester
info@complexitylabs.io